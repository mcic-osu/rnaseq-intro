[
  {
    "objectID": "modules/04_shell.html#the-unix-shellcommand-line-computing",
    "href": "modules/04_shell.html#the-unix-shellcommand-line-computing",
    "title": "The Unix Shell",
    "section": "1 The Unix Shell/Command Line Computing",
    "text": "1 The Unix Shell/Command Line Computing\nMany of the things you typically do by pointing and clicking can alternatively be done with command line approaches. The Unix shell allows you to interact with the supercomputer in a command-line environment. The Code Server/VS Code software Jelmer just introduced is one of several methods available for accessing the Unix shell, and the one we’ll use through the workshop. Now that we have the platform for interacting with the supercomputer, we’ll dive into command line computing."
  },
  {
    "objectID": "modules/04_shell.html#overview",
    "href": "modules/04_shell.html#overview",
    "title": "The Unix Shell",
    "section": "2 Overview",
    "text": "2 Overview\nWorking effectively on a remote supercomputer requires doing command-line computing. But there are more advantages to doing command line computing than just allowing you to work on a supercomputer.\n\n2.1 Some Terminology\nWe’re going to focus on the practice of doing command line computing here, and not get too bogged down in to details of terminology, but let’s highlight a few terms you’re likely to run across (and hear during the workshop).\n\nCommand Line\nShell\nTerminal\nConsole\nBash\n\nWhile it might not fly for a computer science class, for day-to-day bioinformatics, you’ll probably hear all these terms used somewhat interchangably. Basically, we’re talking about the process of interacting with your computer by giving it commands as opposed to the point-and-click way you’re likely more familiar with.\n\n\n2.2 Advantages to Command Line Computing\n\nInteract with a remote computer\nWork efficiently with large files\nAchieve reproducibility in research\nPerform general computing tasks more efficiently\n\n\n\n2.3 Structure Of Command Line Expressions\nWe’ll think of command line expressions as having 3 main parts. Don’t worry about following along here - there will be plenty of chances to try this out shortly. For now, just treat this as a demonstration and focus on these 3 components…\n\nCommands\nOptions or Arguments\nOutput\n\n\n2.3.1 Command Line Commands\nThe prompt indicates the shell is ready for a command.\n\n\n\nLet’s start with the ls command.\n\n\n\n\n\n\nHere, we’ve given a command, ls, and the shell has returned some output – in this case, listing the contents of the current directory. It has also returned another prompt, meaning it’s ready for another command.\nNow we’ll run the same command again, but this time we’ll add in an option -l (a dash followed by a lowercase L). Options allow you to modify the behavior of a command.\n\n\n\n\n\n\nNotice that the same four items are returned, but this time, they’re printed in a different format, and additional information is included.\nLet’s try adding one more option/argument – -h.\n\n\n\n\n\n\nCan you pick out what -h did to modify the output? Note the difference in the format of the column reporting the sizes of the items listed.\n\n\n\n2.4 Commonly-Used Commands\nBelow are some commands I find myself using quite a bit, grouped into some general categories based on their primary function…\n\nGetting Info About a Command\n\nman: get help (manual) for a command\n\nNavigating in the Terminal\n\npwd: returns (prints) your working directory\ncd: change working directory\n\nViewing Files\n\nless: view contents of a file\nhead: preview contents of a file\ntail: print the last lines of a file\ncat: print contents of file to screen\n\nManaging/Organizing Files\n\nls: list contents of directory\nmkdir: create a new directory\nrm: remove/delete a file or directory\ncp: copy files/directories to a new location\nmv: move files/directories to a new location\n\nWorking With Compressed Files\n\ngzip: compress a file with gzip compression\ngunzip: uncompress a gzip file\nzcat/gzcat: print the uncompressed contents of a compressed file to the screen\nunzip: uncompress a zip file\n\nAssessing Files\n\ndiff: print differences in two text files\nmd5: get and md5 checksum for a file\ngrep: search a text file for lines containing a pattern of text\nwc: return number of lines, words, characters in a file\n\nEditing Files\n\nsed\nawk\nsort\ntr\nuniq\n\nObtaining/Sharing Files\n\ncurl: download a file from online\nsftp: transfer files between a local and remote computer\nwget: download a file from online\n\nFeatures\n\nTab completion\nCommand History (up arrow)\nCtrl+r\nCtrl+c\n\nSpecial Notation\n\n|\n~\n.\n..\n$PATH\n$HOME\n\nWildcards\n\n*\n?\n[]\n^\n\n\nWhile it’s not an exhaustive list, getting a grasp on some of the commands and features above will go a long way in allowing you to start to work at command line. We won’t get to all of them in this session, but we’ll explore quite a few on this list."
  },
  {
    "objectID": "modules/04_shell.html#practice-with-common-commands",
    "href": "modules/04_shell.html#practice-with-common-commands",
    "title": "The Unix Shell",
    "section": "3 Practice with Common Commands",
    "text": "3 Practice with Common Commands\nHere we’ll start practicing with some common command-line commands.\n\n\n\n\n\n\nWorking Directories\n\n\n\nBefore we start with our first command, we should talk about directory paths and working directories. All the files on a computer exist within a hierarchical system of directories (folders). When working at command line, you are always “in” one of these directories. The directory you’re “in” at any given time is referred to as your working directory.\nIt’s useful to know what this is at any given time, and there’s a command that tells you: pwd. This brings us to our first command.\n\n\n\n3.1 pwd\nThe pwd command prints the absolute path of your current working directory.\n\n\n\n\n\n\nThe default working directory when you log on to OSC is your HOME directory. You’ll likely make lots of use of this directory if you work at OSC, but for the workshop, we’re all going to work in the scratch directory associated with the project set up for the workshop. So we’ll move to that directory next.\n\n\n3.2 cd\ncd allows you to change your working directory to any directory you have permission to access on the computer you’re working on. And this is a great place to introduce Tab Completion, which you really should get in the habit of using…\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbsolute Paths vs Relative Paths\n\n\n\nWhat we’ve used here is an absolute (full) path. If you want to change directories, the cd command needs to know where you want to move to. As we just saw, we can give it that information by providing the absolute path to the directory on the computer we want to move to (starting with the root directory, which is indicated by the first / in the path /fs/ess/scratch/PAS2250 above).\nProviding absolute paths will always work, but it’s often a bit more typing than we need (or want) to do. An alternative is to work with relative paths. These work by assuming you’re staring in your current working directory, and then, by default, looking forward in the directory structure (or down if you like to think from top to bottom). We’ll come back to relative paths shortly.\n\n\nOK, we made it to a directory created specifically for this workshop. Let’s see what’s in there.\n\n\n3.3 ls\nThe ls command lists everything inside the current directory.\n\n\n\n\n\n\nHere we see 3 directories – data, jelmer, and participants.\nLet’s see what’s inside the data directory (and another good chance to try Tab Completion)…\n\n\n\n\n\n\n\n\n\nTwo more directories this time. Try viewing the contents of the fastq directory yourself…\n\nOn Your Own: list the contents of a directory\nTry to list the contents of the fastq directory we just saw.\n\n\nSolutions (click here)\n\n\nls data/fastq/\n\nOR\n\ncd data/fastq/\nls\n\n\n\nLet’s check to make sure we’re still in the /fs/ess/scratch/PAS2250 directory, and also remind ourselves exactly what’s in there…\n\n\n\nIf you’re not in the PAS2250 directory for some reason, you can use cd to get back there. You should see data, jelmer, and participants when listing the contents of your current directory.\nNow let’s move our working directory again – this time we’ll go in to participants. We could use cd with the absolute path – similar to what we did before. However, we’ll save ourselves some typing and use a relative path. Keep using Tab Completion.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4 mkdir\nThe mkdir command allows you to create a new directory. Create one for yourself in the current directory (participants) according to this example (replace mikes_dir with a name for your folder – avoid spaces and special characters in the name)…\n\n\n\n\n\n\n\n\n3.5 Summary Thus Far\nSo far, we’ve used…\n\npwd (print working directory)\ncd (change directory)\nls (list)\nmkdir (make new directory)\nTab Completion (not really a command, but a useful feature)\n\nWe also have a directory structure that looks like…\n\n\n\nThe data files in the data/fastq directory are FASTQ formatted files from an RNA experiment, and are what we’ll be analyzing as we go through the workshop. We’ll talk more about them soon, but for now, let’s make sure everyone has a copy of the data. We’ll copy the data directory and its contents into the new directory you just made.\n\n\n\n\n\n3.6 cp\nThe cp command allows you to copy files or directories from one location to another. It has 2 required arguments – what you want to copy, and where you want to copy it to.\nLet’s start with what we want to copy. It’s the data directory and all of its contents. Notice in the diagram above that data is at the same level in the directory structure as our current working directory, participants. This means using data as a relative path won’t work, because the computer looks down the directory structure (it will see the contents of ‘participants’). But there’s a way to deal with that. We can use .. to move us up a level in the directory structure.\n\n\n\n\n\n\nNotice we get a message that it omitted copying the directory data (which is what we wanted to copy). Indeed, the copy didn’t work (you can ls the contents of the target directory to check – it will still be empty). cp works in this simplest form with individual files, but not with directories that have contents inside them. If you want to copy a directory and all of its contents, we need one of those options that modify the behavior of the cp command. In this case, -r, which tells it to copy in a recursive manner.\nAnd this is a good spot to introduce the Command History. At the prompt, try hitting the up arrow. A record of all your previous commands is kept, so you can scroll back through them. Use this to get the previous cp command, and then add the -r argument.\n\n\n\n\n\n\nAnd we can check to make sure the copy worked…\n\n\n\n\n\n3.7 man\nWe haven’t talked about man yet. This stands for manual, and is a great way to get details on any command. For example, we can check out the man page for cp…\n\n\n\n\n\n\nIf you scroll down, you’ll see information on the -r option we just used (among others). As it says at the bottom of the page, type q to quit and get back to your command line prompt."
  },
  {
    "objectID": "modules/04_shell.html#working-with-text-files",
    "href": "modules/04_shell.html#working-with-text-files",
    "title": "The Unix Shell",
    "section": "4 Working With Text Files",
    "text": "4 Working With Text Files\nNow let’s start to explore our FASTQ files a bit. In preparation, it’s a good chance to practice a few of the commands we’ve seen so far.\n\nOn Your Own: Explore the Files\nSet your working directory to the data/fastq directory inside the folder you created for yourself. Then list the contents of that fastq directory. How many files are in there? See if you can get the sizes of each file.\n\n\nHint (click here)\n\nUse cd and a relative path (&lt;your_dir&gt;/data/fastq/) to change you working directory.\nOnce you’re there, use ls to list the contents of the current directory. Recall the option that we used above to give more detailed information about each file, or check out the man page for ls.\n\n\n\nSolutions (click here)\n\n\ncd &lt;your_dir&gt;/data\n\nls\n\nls -l\n\n\n\n\n4.1 Compressed Files\nYou might have noticed these files all have a .gz extension, indicating they are ‘gzip-compressed’. This is a common type of compression for large genomic-scale files. The fact that they’re compressed means we can’t just open them up and look inside – we need to uncompress them first. The gunzip command would allow us to do this – it uncompresses the file it’s given and writes the uncompressed version to a new file.\nWe could do this, but there’s another approach. FASTQ files can get big, and sometimes it helps to be able to keep them compressed as much as possible. It’s a good time for us to explore the pipe.\n\n\n4.2 | (pipe)\nWe talked earlier about command line expressions having 3 parts – the command itself, options and arguments, and output. By default, any output is printed to the screen. That’s what we’ve seen so far. But you can also redirect the output, and there are three primary ways to redirect it…\n\nWith &gt;, which is followed by the name of a text file the output will be written to\nWith &gt;&gt;, which is simlar to &gt; but will append the output (that is, it won’t overwrite any existing content like &gt;)\nWith | (pipe), which takes the output of one command and “pipes” it as input for a subsequent command.\n\nLet’s try to preview the contents of one of the compressed files.\n\n\n4.3 head\nThe head command is a great way to preview the contents of a text file. By default, head prints the first 10 lines of a file. Since these are FASTQ files, let’s print 8 lines (a multiple of 4 – it will become clear why shortly). We can use the -n argument to specify the number of lines that will be returned.\n\n\n\n\n\n\nThis isn’t what we want – we’re seeing the first 8 lines of the compressed files - not helpful.\n\n\n4.4 zcat\nThe zcat function prints human-readable contents of a gzip-compressed file to the screen. We can try running it on the file, but remember the file is pretty big – there are lots of lines of text in there that will all get printed to the screen. Instead, we can pipe the output of zcat to the head command.\n\n\n\n\n\n\nMuch better – this is what the raw RNAseq data look like!\n\n\n\n\n\n\nWarning\n\n\n\nTo get the number of lines (= number sequences x 4 – see below) for a gzipped FASTQ file, it’s important to use zcat x.fastq.gz | wc -l instead of wc -l x.fastq.gz, because the compressed file does not have the same number of lines!\n\n\n\n\n4.5 FASTQ Format\nIf you’re not familiar with it, FASTQ is a very common format for genomic data files. The raw data produced by a high-throughput sequencer will almost certainly be returned to you in this format. These are plain text files, and each sequence that is read by the sequencer is represented by 4 lines:\n\na name (header) line\nthe sequence itself\na plus sign\nquality scores corresponding to each base position in the sequence\n\n\n\n4.6 wc\nSince each read in a FASTQ file is represented by 4 lines, we should expect the number of lines in each of the FASTQ files to be a multiple of 4. Let’s check one. The wc command stands for word count, but by default, it returns the number of words, lines, and characters in a file. The -l option tells it to return just the number of lines, so we’ll use it since that’s all we’re interested in right now. And remember, we’ll want to do this on the uncompressed data.\n\n\n\n\n\n\n\n\n4.7 grep\ngrep allows you to search through a file for specific patterns of text and returns the matching lines. For example, let’s say we wanted to see what sequences in sample SRR7609467 contain the sequence “ACCGATACG”:\n\n\n\n\n\n\n\nOn Your Own: Finding a Sequence\nHow many sequences in sample SRR7609467 contain the sequence “CCAGTA”?\n\n\nHint (click here)\n\nPipe the results of the grep to wc -l. Alternatively, check out the -c option to grep in the man page.\n\n\n\nSolutions (click here)\n\n\nzcat SRR7609467.fastq.gz | grep 'CCAGTA' | wc -l\n\nOR\n\nzcat SRR7609467.fastq.gz | grep -c 'CCAGTA'"
  },
  {
    "objectID": "modules/04_shell.html#downloading-files-from-the-web",
    "href": "modules/04_shell.html#downloading-files-from-the-web",
    "title": "The Unix Shell",
    "section": "5 Downloading Files from the Web",
    "text": "5 Downloading Files from the Web\nAt command line, you can’t just open a web browser and download a file you might want. But of course, there are commands to do that. As we move toward starting to analyze our example RNAseq dataset, one thing we’ll need is the reference genome for the species these sequences came from – in this case, Phaseolus vulgaris. Before we get that, it’s another good time to practice some of those common commands…\n\nOn Your Own: Create a Directory\nCreate a new (empty) directory named reference that will later store the reference genome for our analyses. Put it in your own directory inside participants. Then make this reference directory your working directory.\n\n\nHint (click here)\n\nUse the mkdir command (and cd as necessary). Remember that .. moves you up/back one directory, and these can be combined. For example, ../../../ would move you up/back 3 directories.\n\n\n\nSolution (click here)\n\n\nmkdir ../../reference\n  \ncd ../../reference\n\nOR\n\ncd ../../\n  \nmkdir reference\n   \ncd reference\n\n\n\n\n5.1 curl\ncurl is one command that allows you to download files from online (wget is another). Technically, all you need for curl is the name of the command and the web address for what you want to download.\nHowever, the default for curl is to print the downloaded contents to the screen. This usually isn’t what we want. Instead, we want to save them to a file. One option would be to redirect the output to a text file with &gt;. But curl also has a built-in option to write the contents to a file: -o, so we’ll use that.\nSince the file that gets downloaded is a gzip-compressed, FASTA-formatted text file, we’ll give the name of the file a .fa.gz extension. The reference genome for Phaseolus vulgaris is available at:\n\nhttps://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/499/845/GCF_000499845.1_PhaVulg1_0/GCF_000499845.1_PhaVulg1_0_genomic.fna.gz\n\n\n\n\n\n\n\n\nOn Your Own: Preview a FASTA file\nTry previewing the contents of the reference genome file you just downloaded.\n\n\nHint (click here)\n\nRemember the file is gzip-compressed. Use zcat and pipe the results to head.\n\n\n\nSolution (click here)\n\n\nzcat Pvulg.fa.gz | head\n\n\n\nOK, now we’ve got our raw data (FASTQ) and our reference genome (FASTA). This is a good start in terms of getting ready to start analyzing the data. One more thing we can do now is try to understand a little bit about the samples themselves. There is a tab-separated text file named meta.tsv in the data/meta directory. Let’s take a look at its contents…\n\n\n5.2 less\nless is a command that opens up a text file within your shell. Once you’re finished viewing the file, type q to quit and return to your prompt."
  },
  {
    "objectID": "modules/04_shell.html#further-resources",
    "href": "modules/04_shell.html#further-resources",
    "title": "The Unix Shell",
    "section": "6 Further resources",
    "text": "6 Further resources\n\nhttps://www.learnenough.com/command-line-tutorial\nhttps://cvw.cac.cornell.edu/Linux/\nhttp://www.ee.surrey.ac.uk/Teaching/Unix/\nhttps://www.udacity.com/course/linux-command-line-basics–ud595\nhttp://moo.nac.uci.edu/~hjm/How_Programs_Work_On_Linux.html\nOSC’s UNIX Basics"
  },
  {
    "objectID": "modules/03_vscode.html",
    "href": "modules/03_vscode.html",
    "title": "The VS Code Text Editor",
    "section": "",
    "text": "In this module, we will learn the basics of a fancy text editor called VS Code (in full, Visual Studio Code). Conveniently, we can use a version of this editor (sometimes referred to as Code Server) in our browser via the OSC OnDemand website.\nWe will use VS Code throughout the workshop as practically a one-stop solution for our computing activities at OSC. This is also how I use this editor in my daily work.\nTo emphasize the additional functionality relative to basic text editors like Notepad and TextEdit, editors like VS Code are also referred to as “IDEs”: Integrated Development Environments. If you’ve ever worked with R, the RStudio program is another good example of an IDE."
  },
  {
    "objectID": "modules/03_vscode.html#starting-vs-code-at-osc",
    "href": "modules/03_vscode.html#starting-vs-code-at-osc",
    "title": "The VS Code Text Editor",
    "section": "1 Starting VS Code at OSC",
    "text": "1 Starting VS Code at OSC\nIn the previous module, Mike already guided us through starting a VS Code session via OnDemand, but for the sake of completeness, instructions to do so are also shown below.\n\n\n\n\n\n\nStarting VS Code at OSC\n\n\n\n\n\n\nLog in to OSC’s OnDemand portal at https://ondemand.osc.edu.\nIn the blue top bar, select Interactive Apps and then near the bottom of the dropdown menu, click Code Server.\nIn the form that appears on a new page:\n\nMake sure that Number of hours is at least 4\nClick Launch.\n\nOn the next page, once the top bar of the box has turned green and says Runnning, click Connect to VS Code."
  },
  {
    "objectID": "modules/03_vscode.html#getting-started-with-vs-code",
    "href": "modules/03_vscode.html#getting-started-with-vs-code",
    "title": "The VS Code Text Editor",
    "section": "2 Getting started with VS Code",
    "text": "2 Getting started with VS Code\n\n\n\n\n2.1 Side bars\nThe Activity Bar (narrow side bar) on the far left has:\n\nA      (“hamburger menu” icon) in the top, which has most of the standard menu items that you often find in a top bar, like File.\nA      (cog wheel icon) in the bottom, through which you can mainly access settings.\nA bunch of icons in the middle that serve to switch between different options for the (wide) Side Bar, which can show one of the following:\n\nExplorer: File browser (and, e.g., an outline for the active file)\nSearch: To search recursively across all files in the active folder\nSource Control: To work with version control systems like Git (not used in this workshop)\nRun and Debug: For debugging your code (not used in this workshop)\nExtensions: To install extensions (we’ll install one later)\n\n\n\n\n2.2 Editor pane and Welcome document\nThe main part of the VS Code is the editor pane. Whenever you open VS Code, a tab with a Welcome document is automatically opened. This provides some help for beginners, but also, for example, a handy overview of recently opened folders.\nWe can also use the Welcome document to open a new text file by clicking New file below Start (alternatively, click      =&gt;   File   =&gt;   New File), which open as a second “tab” in the editor pane. We’ll work with our own text files (scripts) starting tomorrow.\n\n\n\n\n\n\nRe-open the Welcome document\n\n\n\nIf you’ve closed the Welcome document but want it back, click      =&gt;   Help   =&gt;   Welcome.\n\n\n\n\n2.3 Terminal (with a Unix shell)\n By default, no terminal is open in VS Code – open one by clicking      =&gt; Terminal =&gt; New Terminal.\nIn the terminal, the prompt says Singularity&gt;. This is because in OSC OnDemand, VS Code runs inside a Singularity container (for our purposes, it is not important what that means, exactly).\n Break out of the Singularity shell to get a regular Bash Unix shell: type bash and press Enter.\nIn the next module, Mike will teach us how to use the Unix shell."
  },
  {
    "objectID": "modules/03_vscode.html#a-folder-as-a-starting-point",
    "href": "modules/03_vscode.html#a-folder-as-a-starting-point",
    "title": "The VS Code Text Editor",
    "section": "3 A folder as a starting point",
    "text": "3 A folder as a starting point\nConveniently, VS Code takes a specific folder (directory) as a starting point in all parts of the program:\n\nIn the file explorer in the side bar\nIn the terminal\nWhen saving files in the editor pane.\n\nBy default, VS Code via OnDemand will open your Home directory. But in this workshop, we’ll work within the scratch directory for the PAS2250 project, to which you have all been added, which is /fs/ess/scratch/PAS2250.\n Let’s open that folder. Click Open folder... in the Welcome tab (or      =&gt;   File   =&gt;   Open Folder).\nYou’ll notice that the program completely reloads.\n\n\n\n\n\n\nTaking off where you were\n\n\n\nAdditionally, when you reopen a folder later, VS Code will to some extent resume where you were before!\nIt will reopen any files you had open, and if you had an active terminal, it will re-open a terminal. This is very convenient, especially when you start working on multiple projects (different folders) in VS Code and frequently switch between those."
  },
  {
    "objectID": "modules/03_vscode.html#some-vs-code-tips-and-tricks",
    "href": "modules/03_vscode.html#some-vs-code-tips-and-tricks",
    "title": "The VS Code Text Editor",
    "section": "4 Some VS Code tips and tricks",
    "text": "4 Some VS Code tips and tricks\n\n4.1 Making use of your screen’s real estate\nSince we are using VS Code inside a browser window, we are unfortunately losing some screen space. Make sure to maximize the browser window and if you have a bookmarks bar, try to hide it (for Chrome: Ctrl/⌘+Shift+B).\nYou may also opt to hide the side bars using the    =&gt;   View   =&gt;   Appearance menu (or Ctrl/⌘+B for the (wide) Side Bar).\n\n\n4.2 Resizing panes\nYou can resize panes (the terminal, editor, and side bar) by hovering your cursor over the borders and then dragging it.\n\n\n4.3 The Command Palette / Color themes\nTo access all the menu options that are available in VS Code, the so-called “Command Palette” can be handy, especially if you know what you are looking for.\nTo access the Command Palette, click      and then Command Palette (or press F1 or Ctrl/⌘+Shift+P).\n\nOn Your Own: Try a few color themes\nOpen the Command Palette and start typing “color theme”, and you’ll see the relevant option pop up.\nThen, try out a few themes and see what you like!\n(You can also access the Color Themes option via      =&gt; Color Theme.)\n\n\n\n\n\n\n“Solution” (click here)\n\n\n\n\n\n“Quiet Light” is the best one"
  },
  {
    "objectID": "modules/03_vscode.html#addendum-keyboard-shortcuts",
    "href": "modules/03_vscode.html#addendum-keyboard-shortcuts",
    "title": "The VS Code Text Editor",
    "section": "Addendum: keyboard shortcuts",
    "text": "Addendum: keyboard shortcuts\nWorking with keyboard shortcuts (also called “keybindings”) for common operations can be a lot faster than using your mouse. Below are some useful ones for VS Code (for Mac, replace Ctrl with ⌘).\n\n\n\n\n\n\nKeyboard shortcut cheatsheet\n\n\n\nFor a single-page PDF overview of keyboard shortcuts for your operating system:      =&gt;   Help   =&gt;   Keyboard Shortcut Reference. (Or for direct links to these PDFs: Windows / Mac / Linux.)\n\n\n\nOpen a terminal: Ctrl+` or Ctrl+Shift+C.\nToggle between the terminal and the editor pane: Ctrl+` and Ctrl+1.\nToggle the (wide) Side Bar: Ctrl+B\nLine actions:\n\nCtrl+X / C will cut/copy the entire line where the cursor is, when nothing is selected (!)\nCtrl+Shift+K will delete a line\nAlt+⬆/⬇ will move lines up or down.\n\nMultiple cursors: Press & hold Ctrl+Shift, then ⬆/⬇ arrows to add cursors upwards or downwards.\nToggle line comment (“comment out” code, and removing those comment signs): Ctrl+/\nSplit the editor window vertically: Ctrl+\\ (See also the options in      View =&gt; Editor Layout)\n\n\n\n\n\n\n\nBrowser interference\n\n\n\nUnfortunately, some VS Code and terminal keyboard shortcuts don’t work in this setting where we are using VS Code inside a browser, because existing browser keyboard shortcuts take precedence.\nIf you end up using VS Code a lot in your work, it is therefore worth switching to your own installation of the program (see At-home bonus: local installation)"
  },
  {
    "objectID": "modules/03_vscode.html#at-home-bonus-local-installation",
    "href": "modules/03_vscode.html#at-home-bonus-local-installation",
    "title": "The VS Code Text Editor",
    "section": "At-home bonus: local installation",
    "text": "At-home bonus: local installation\nAnother nice feature of VS Code is that it is freely available for all operating systems (and even though it is made by Microsoft, it is also open source).\nTherefore, if you like the program, you can also install it on your own computer and do your local text editing / script writing in the same environment at OSC (it is also easy to install on OSU-managed computers, because it is available in the Self Service software installer).\nEven better, the program can be “tunneled into” OSC, so that your working directory for the entire program can be at OSC rather than on your local computer. This gives the same experience as using VS Code through OSC OnDemand, except that you’re not working witin a browser window, which has some advantages (also: no need to fill out a form, or to break out of the Singularity shell).\nTo install VS Code on your own machine, follow these instructions: Windows / Mac / Linux.\nTo SSH-tunnel VS Code into OSC, see these instructions (they are a bit rudimentary, ask Jelmer if you get stuck)."
  },
  {
    "objectID": "modules/05_vars-loops.html",
    "href": "modules/05_vars-loops.html",
    "title": "Variables, Globbing, and Loops",
    "section": "",
    "text": "In this module, we will cover a few topics that are good to know about before you start writing and running shell scripts:\nThese are valuable skills in general — globbing is an essential technique in the Unix shell, and variables and for loops ubiquitous programming concepts."
  },
  {
    "objectID": "modules/05_vars-loops.html#setup",
    "href": "modules/05_vars-loops.html#setup",
    "title": "Variables, Globbing, and Loops",
    "section": "1 Setup",
    "text": "1 Setup\nStarting a VS Code session with an active terminal:\n\nLog in to OSC at https://ondemand.osc.edu.\nIn the blue top bar, select Interactive Apps and then Code Server.\nIn the form that appears:\n\nEnter 4 or more in the box Number of hours\nTo avoid having to switch folders within VS Code, enter /fs/ess/scratch/PAS2250/participants/&lt;your-folder&gt; in the box Working Directory (replace &lt;your-folder&gt; by the actual name of your folder).\nClick Launch.\n\nOn the next page, once the top bar of the box is green and says Runnning, click Connect to VS Code.\nOpen a terminal:   =&gt; Terminal =&gt; New Terminal.\nIn the terminal, type bash and press Enter.\nType pwd in the termain to check you are in /fs/ess/scratch/PAS2250.\nIf not, click   =&gt;   File   =&gt;   Open Folder and enter /fs/ess/scratch/PAS2250/&lt;your-folder&gt;."
  },
  {
    "objectID": "modules/05_vars-loops.html#variables",
    "href": "modules/05_vars-loops.html#variables",
    "title": "Variables, Globbing, and Loops",
    "section": "2 Variables",
    "text": "2 Variables\nIn programming, we use variables for things that:\n\nWe refer to repeatedly and/or\nAre subject to change.\n\nThese tend to be settings like the paths to input and output files, and parameter values for programs.\nUsing variables makes it easier to change such settings. We also need to understand variables to work with loops and with scripts.\n\n2.1 Assigning and referencing variables\nTo assign a value to a variable in Bash (in short: to assign a variable), use the syntax variable=value:\n\n# Assign the value \"beach\" to the variable \"location\":\nlocation=beach\n\n# Assign the value \"200\" to the variable \"nlines\":\nnlines=200\n\n\n\n\n\n\n\nBe aware: don’t put spaces around the equals sign (=)!\n\n\n\n\n\n\nTo reference a variable (i.e., to access its value), you need to put a dollar sign $ in front of its name. We’ll use the echo command to review the values that our variables contain:\n\n\n\n\n\n\necho simply prints back (“echoes”) whatever you tell it to\n\n\n\n\necho Hello!\n\nHello!\n\n\n\n\n\necho $location\n\n\n\nbeach\n\n\n\necho $nlines\n\n\n\n200\n\n\nConveniently, we can directly use variables in lots of contexts, as if we had instead typed their values:\n\ninput_file=data/fastq/SRR7609467.fastq.gz\n\nls -lh $input_file \n\n-rw-r--r--@ 1 poelstra.1  staff   8.3M Jul 16 16:12 data/fastq/SRR7609467.fastq.gz\n\n\n\nls_options=\"-lh\"            # (We'll talk about the quotes that are used here later)\n\nls $ls_options data/meta\n\ntotal 8\n-rw-r--r--@ 1 poelstra.1  staff   583B Jul 16 16:12 meta.tsv\n\n\n\n\n\n2.2 Rules and tips for naming variables\nVariable names:\n\nCan contain letters, numbers, and underscores\nCannot contain spaces, periods, or other special symbols\nCannot start with a number\n\nTry to make your variable names descriptive, like $input_file and $ls_options above, as opposed to say $x and $bla.\nThere are multiple ways of distinguishing words in the absence of spaces, such as $inputFile and $input_file: I prefer the latter, which is called “snake case”, and I always use lowercase.\n\n\n\n2.3 Quoting variables\nAbove, we learned that a variable name cannot contain spaces. But what happens if our variable’s value contains spaces? First off, when we try to assign the variable without using quotes, we get an error:\n\ntoday=Thu, Aug 18\n\n\nAug: command not found\n\n\n\n\n\n\n\nWhy do you think we got this error?\n\n\n\n\n\nBash tried assign everything up to the first space (i.e., Thu,) to today. After that, since we used a space, it assumed the next word (Aug) was something else: specifically, another command.\n\n\n\nBut it works when we quote (with double quotes, \"...\") the entire string that makes up the value:\n\ntoday=\"Thu, Aug 18\"\necho $today\n\nThu, Aug 18\n\n\n\nNow, let’s try to reference this variable in another context. Note that the touch command can create new files, e.g. touch a.txt creates the file a.txt. So let’s try make a new file with today’s date:\n\ntouch README_$today.txt\nls\n\n\n18.txt\nAug\nREADME_Thu,\n\n\n\n\n\n\n\nWhat went wrong here?\n\n\n\n\n\nThe shell performed so-called field splitting using spaces as a separator, splitting the value into three separate units – as a result, three files were created.\n\n\n\nLike with assignment, our problems can be avoided by quoting a variable when we reference it:\n\ntouch README_\"$today\".txt\n\n# This will list the most recently modified file (ls -t sorts by last modified date):\nls -t | head -n 1\n\n\n\nREADME_Thu, Aug 18.txt\n\n\nIt is good practice to quote variables when you reference them: it never hurts, and avoids unexpected surprises.\n\n\n\n\n\n\nAt-home reading: Where does a variable name end?\n\n\n\n\n\nAnother issue we can run into when we don’t quote variables is that we can’t explicitly define where a variable name ends within a longer string of text:\n\necho README_$today_final.txt\n\n\n\nREADME_.txt\n\n\n\n\n\n\n\n\nWhat went wrong here? (Hint: check the coloring highlighting above)\n\n\n\n\n\n\nFollowing a $, the shell will stop interpreting characters as being part of the variable name only when it encounters a character that cannot be part of a variable name, such as a space or a period.\nSince variable names can contain underscores, it will look for the variable $today_final, which does not exist.\nImportantly, the shell does not error out when you reference a non-existing variable – it basically ignores it, such that README_$today_final.txt becomes README_.txt, as if we hadn’t referenced any variable.\n\n\n\n\nQuoting solves this issue, too:\n\necho README_\"$today\"_final.txt\n\n\n\nREADME_Thu, Aug 18_final.txt\n\n\n\n\n\n\n\n\n\n\n\nAt-home reading: Quoting as “escaping” special meaning – and double vs. single quotes\n\n\n\n\n\nBy double-quoting a variable, we are essentially escaping (or “turning off”) the default special meaning of the space as a separator, and are asking the shell to interpret it as a literal space.\nSimilarly, we are escaping other “special characters”, such as globbing wildcards, with double quotes. Compare:\n\necho *     # This will echo/list all files in the current working dir (!)\n\n18.txt Aug README_Thu, README_Thu, Aug 18.txt data sandbox scripts\n\n\n\necho \"*\"   # This will simply print the \"*\" character \n\n*\n\n\nHowever, as we saw above, double quotes do not turn off the special meaning of $ (denoting a string as a variable):\n\necho \"$today\"\n\n\n\nThu, Aug 18\n\n\n…but single quotes will:\n\necho '$today'\n\n$today\n\n\n\n\n\n\n\n\n2.4 Command substitution\nIf you want to store the result of a command in a variable, you can use a construct called “command substitution” by wrapping the command inside $().\nLet’s see an example. The date command will print the current date and time:\n\ndate\n\nSun Jul 16 16:14:00 EDT 2023\n\n\nIf we try to store the date in a variable directly, it doesn’t work: the literal string “date” is stored, not the output of the command:\n\ntoday=date\necho \"$today\"\n\ndate\n\n\nThat’s why we need command substitution with $():\n\ntoday=$(date)\necho \"$today\"\n\nSun Jul 16 16:14:00 EDT 2023\n\n\n\nIn practice, you might use command substitution with date to include the current date in files. To do so, first, note that we can use date +%F to print the date in YYYY-MM-DD format, and omit the time:\n\ndate +%F\n\n2023-07-16\n\n\nLet’s use that in a command substitution — but a bit differently than before: we use the command substitution $(date +%F) directly in our touch command, rather than first assigning it to a variable:\n\n# Create a file with our $today variable:\ntouch README_\"$(date +%F)\".txt\n\n# Check the name of our newly created file:\nls -t | head -n 1\n\n\n\nREADME_2023-07-16.txt\n\n\nAmong many other uses, command substitution is handy when you want your script to report some results, or when a next step in the script depends on a previous result.\n\n\nOn Your Own: Command substitution\nSay we wanted to store and report the number of lines in a file, which can be a good QC measure for FASTQ and other genomic data files.\nwc -l gets you the number of lines, and you can use a trick to omit the filename:\n\nwc -l data/fastq/SRR7609472.fastq.gz\n\n   30387 data/fastq/SRR7609472.fastq.gz\n\n\n\n# Use `&lt;` (input redirection) to omit the filename:\nwc -l &lt; data/fastq/SRR7609472.fastq.gz\n\n   30387\n\n\nUse command substitution to store the output of the last command in a variable, and then use an echo command to print:\nThe file has 30387 lines\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nnlines=$(wc -l &lt; data/fastq/SRR7609472.fastq.gz)\n\necho \"The file $nlines lines\"\n\nThe file    30387 lines\n\n\nNote: You don’t have to quote variables inside a quoted echo call, since it’s, well, already quoted. If you also quote the variables, you will in fact unquote it, although that shouldn’t pose a problem inside echo statements.\n\n\n\n\n\n\n2.5 At-home reading: Environment variables\n\n\n\n\n\n\nEnvironment variable basics\n\n\n\n\n\nThere are also predefined variables in the Unix shell: that is, variables that exist in your environment by default. These so-called “environment variables” are always spelled in all-caps:\n\n# Environment variable $USER contains your user name \necho $USER\n\npoelstra.1\n\n\n\n# Environment variable $HOME contains the path to your home directory\necho $HOME\n\n\n/users/PAS0471/jelmer\n\nEnvironment variables can provide useful information. They can especially come in handy in in scripts submitted to the Slurm compute job scheduler."
  },
  {
    "objectID": "modules/05_vars-loops.html#globbing-with-shell-wildcard-expansion",
    "href": "modules/05_vars-loops.html#globbing-with-shell-wildcard-expansion",
    "title": "Variables, Globbing, and Loops",
    "section": "3 Globbing with Shell wildcard expansion",
    "text": "3 Globbing with Shell wildcard expansion\nShell wildcard expansion is a very useful technique to select files. Selecting files with wildcard expansion is called globbing.\n\n3.1 Shell wildcards\nIn the term “wildcard expansion”, wildcard refers to a few symbols that have a special meaning: specifically, they match certain characters in file names. We’ll see below what expansion refers to.\nHere, we’ll only talk about the most-used wildcard, *, in detail. But for the sake of completeness, I list them all below:\n\n\n\n\n\n\n\nWildcard\nMatches\n\n\n\n\n*\nAny number of any character, including nothing\n\n\n?\nAny single character\n\n\n[] and [^]\nOne [] or everything except one ([^]) of the “character set” within brackets\n\n\n\n\n\n\n3.2 The * wildcard and wildcard expansion\nA a first example of using *, to match all files in a directory:\n\nls data/fastq/*\n\ndata/fastq/SRR7609467.fastq.gz\ndata/fastq/SRR7609468.fastq.gz\ndata/fastq/SRR7609469.fastq.gz\ndata/fastq/SRR7609470.fastq.gz\ndata/fastq/SRR7609471.fastq.gz\ndata/fastq/SRR7609472.fastq.gz\ndata/fastq/SRR7609473.fastq.gz\ndata/fastq/SRR7609474.fastq.gz\ndata/fastq/SRR7609475.fastq.gz\ndata/fastq/SRR7609476.fastq.gz\ndata/fastq/SRR7609477.fastq.gz\ndata/fastq/SRR7609478.fastq.gz\n\n\nOf course ls data/fastq would have shown the same files, but what happens under the hood is different:\n\nls data/fastq — The ls command detects and lists all files in the directory\nls data/fastq/* — The wildcard * is expanded to all matching files, (in this case, all the files in this directory), and then that list of files is passed to ls. This command is therefore equivalent to running:\n\nls data/fastq/SRR7609467.fastq.gz data/fastq/SRR7609468.fastq.gz data/fastq/SRR7609469.fastq.gz data/fastq/SRR7609470.fastq.gz data/fastq/SRR7609471.fastq.gz data/fastq/SRR7609472.fastq.gz data/fastq/SRR7609473.fastq.gz data/fastq/SRR7609474.fastq.gz data/fastq/SRR7609475.fastq.gz data/fastq/SRR7609476.fastq.gz data/fastq/SRR7609477.fastq.gz data/fastq/SRR7609478.fastq.gz\n\n\nTo see this, note that we don’t need to use ls at all to get a listing of these files!\n\necho data/fastq/*\n\ndata/fastq/SRR7609467.fastq.gz data/fastq/SRR7609468.fastq.gz data/fastq/SRR7609469.fastq.gz data/fastq/SRR7609470.fastq.gz data/fastq/SRR7609471.fastq.gz data/fastq/SRR7609472.fastq.gz data/fastq/SRR7609473.fastq.gz data/fastq/SRR7609474.fastq.gz data/fastq/SRR7609475.fastq.gz data/fastq/SRR7609476.fastq.gz data/fastq/SRR7609477.fastq.gz data/fastq/SRR7609478.fastq.gz\n\n\n\nA few more examples:\n\n# This will still list all 12 FASTQ files --\n# can be a good pattern to use to make sure you're not selecting other types of files \nls data/fastq/*fastq.gz\n\ndata/fastq/SRR7609467.fastq.gz\ndata/fastq/SRR7609468.fastq.gz\ndata/fastq/SRR7609469.fastq.gz\ndata/fastq/SRR7609470.fastq.gz\ndata/fastq/SRR7609471.fastq.gz\ndata/fastq/SRR7609472.fastq.gz\ndata/fastq/SRR7609473.fastq.gz\ndata/fastq/SRR7609474.fastq.gz\ndata/fastq/SRR7609475.fastq.gz\ndata/fastq/SRR7609476.fastq.gz\ndata/fastq/SRR7609477.fastq.gz\ndata/fastq/SRR7609478.fastq.gz\n\n\n\n# Only select the ...67.fastq.gz, ...68.fastq.gz, and ...69.fastq.gz files \nls data/fastq/SRR760946*fastq.gz\n\ndata/fastq/SRR7609467.fastq.gz\ndata/fastq/SRR7609468.fastq.gz\ndata/fastq/SRR7609469.fastq.gz\n\n\n\n\n\n\n\n\nWhat pattern would you use if you wanted to select all gzipped (.fastq.gz) and plain FASTQ files (.fastq) at the same time?\n\n\n\n\n\n\nls data/fastq/SRR760946*.fastq*\n\nThe second * will match filenames with nothing after .fastq as well as file names with characters after .fastq, such as .gz.\n\n\n\n\n\n\n3.3 Common uses of globbing\nWhat can we use this for, other than listing matching files? Below, we’ll use globbing to select files to loop over. Even more commonly, we can use this to move (mv), copy (cp), or remove (rm) multiple files at once. For example:\n\ncp data/fastq/SRR760946* .     # Copy 3 FASTQ files to your working dir \nls *fastq.gz                   # Check if they're here\n\nSRR7609467.fastq.gz\nSRR7609468.fastq.gz\nSRR7609469.fastq.gz\n\n\n\nrm *fastq.gz                  # Remove all FASTQ files in your working dir\nls *fastq.gz                  # Check if they're here\n\n\nls: cannot access ’*fastq.gz’: No such file or directory\n\nFinally, let’s use globbing to remove the mess of files we made when learning about variables:\n\nrm README_*\nrm Aug 18.txt\n\n\n\n\n\n\n\nDon’t confuse shell wildcards with regular expressions!\n\n\n\n\n\nFor those of you who know some regular expressions: these are conceptually similar to wildcards, but the * and ? symbols don’t have the same meaning, and there are way fewer shell wildcards than regular expression symbols.\nIn particular, note that . is not a shell wildcard and thus represents a literal period."
  },
  {
    "objectID": "modules/05_vars-loops.html#for-loops",
    "href": "modules/05_vars-loops.html#for-loops",
    "title": "Variables, Globbing, and Loops",
    "section": "4 For loops",
    "text": "4 For loops\nLoops are a universal element of programming languages, and are used to repeat operations, such as when you want to run the same script or command for multiple files.\nHere, we’ll only cover what is by far the most common type of loop: the for loop.\nfor loops iterate over a collection, such as a list of files: that is, they allow you to perform one or more actions for each element in the collection, one element at a time.\n\n4.1 for loop syntax and mechanics\nLet’s see a first example, where our “collection” is just a very short list of numbers (1, 2, and 3):\n\nfor a_number in 1 2 3; do\n    echo \"In this iteration of the loop, the number is $a_number\"\n    echo \"--------\"\ndone\n\nIn this iteration of the loop, the number is 1\n--------\nIn this iteration of the loop, the number is 2\n--------\nIn this iteration of the loop, the number is 3\n--------\n\n\nfor loops contain the following mandatory keywords:\n\n\n\n\n\n\n\nKeyword\nPurpose\n\n\n\n\nfor\nAfter for, we set the variable name\n\n\nin\nAfter in, we specify the collection we are looping over\n\n\ndo\nAfter do, we have one ore more lines specifying what to do with each item\n\n\ndone\nTells the shell we are done with the loop\n\n\n\n\n\n\n\n\n\nA semicolon ; (as used before do) separates two commands on a single line\n\n\n\n\n\nA semicolon separates two commands written on a single line – for instance, instead of:\n\nmkdir results\ncd results\n\n…you could equivalently type:\n\nmkdir results; cd results\n\nThe ; in the for loop syntax has the same function, and as such, an alternative way to format a for loop is:\n\nfor a_number in 1 2 3\ndo\n    echo \"In this iteration of the loop, the number is $a_number\"\ndone\n\nBut that’s one line longer and a bit awkwardly asymmetric.\n\n\n\nThe aspect that is perhaps most difficult to understand is that in each iteration of the loop, one element in the collection (in the example above, either 1, 2, or 3) is being assigned to the variable specified after for (in the example above, a_number).\n\nIt is also important to realize that the loop runs sequentially for each item in the collection, and will run exactly as many times as there are items in the collection.\nThe following example, where we let the computer sleep for 1 second before printing the date and time with the date command, demonstrates that the loop is being executed sequentially:\n\nfor a_number in 1 2 3; do\n    echo \"In this iteration of the loop, the number is $a_number\"\n    sleep 1s          # Let the computer sleep for 1 second\n    date              # Print the date and time\n    echo \"--------\"\ndone\n\nIn this iteration of the loop, the number is 1\nusage: sleep seconds\nSun Jul 16 16:14:01 EDT 2023\n--------\nIn this iteration of the loop, the number is 2\nusage: sleep seconds\nSun Jul 16 16:14:01 EDT 2023\n--------\nIn this iteration of the loop, the number is 3\nusage: sleep seconds\nSun Jul 16 16:14:01 EDT 2023\n--------\n\n\n\n\nOn Your Own: A simple loop\nCreate a loop that will print:\nmorel is an Ohio mushroom  \ndestroying_angel is an Ohio mushroom  \neyelash_cup is an Ohio mushroom\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nJust like we looped over 3 numbers above (1, 2, and 3), you want to loop over the three mushroom names, morel, destroying_angel, and eyelash_cup.\nNotice that when we specify the collection “manually”, like we did above with numbers, the elements are simply separated by a space.\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nfor mushroom in morel destroying_angel eyelash_cup; do\n    echo \"$mushroom is an Ohio mushroom\"\ndone\n\nmorel is an Ohio mushroom\ndestroying_angel is an Ohio mushroom\neyelash_cup is an Ohio mushroom\n\n\n\n\n\n\n\n\n4.2 Looping over files with globbing\nIn practice, we rarely manually list the collection of items we want to loop over. Instead, we commonly loop over files directly using globbing:\n\n# We make sure we only select gzipped FASTQ files using the `*fastq.gz` glob\nfor fastq_file in data/raw/*fastq.gz; do\n    echo \"File $fastq_file has $(wc -l &lt; $fastq_file) lines.\"\n    # More processing...\ndone\n\nThis technique is extremely useful, and I use it all the time. Take a moment to realize that we’re not doing a separate ls and storing the results: as mentioned, we can directly use a globbing pattern to select our files.\nIf needed, you can use your globbing / wild card skills to narrow down the file selection:\n\n# Perhaps we only want to select R1 files (forward reads): \nfor fastq_file in data/raw/*R1*fastq.gz; do\n    # Some file processing...\ndone\n\n# Or only filenames starting with A or B:\nfor fastq_file in data/raw/[AB]*fastq.gz; do\n    # Some file processing...\ndone\n\n\n\n\n\n\n\nAt-home reading: Alternatives to looping with a glob\n\n\n\n\n\nWith genomics data, the routine of looping over an entire directory of files, or selections made with simple globbing patterns, should serve you very well.\nBut in some cases, you may want to iterate only over a specific list of filenames (or partial filenames such as sample IDs) that represent a complex selection.\n\nIf this is a short list, you could directly specify it in the loop:\n\nfor sample in A1 B6 D3; do\n    R1=data/fastq/\"$sample\"_R1.fastq.gz\n    R2=data/fastq/\"$sample\"_R2.fastq.gz\n    # Some file processing...\ndone\n\nIf it is a longer list, you could create a simple text file with one line per sample ID / filename, and use command substitution as follows:\n\nfor fastq_file in $(cat file_of_filenames.txt); do\n    # Some file processing...\ndone\n\n\nIn cases like this, Bash arrays (basically, variables that consist of multiple values, like a vector in R) or while loops may provide more elegant solutions, but those are outside the scope of this introduction."
  },
  {
    "objectID": "modules/06_scripts.html",
    "href": "modules/06_scripts.html",
    "title": "Shell Scripting",
    "section": "",
    "text": "Shell scripts (or to be slightly more precise, Bash scripts) enable us to run sets of commands non-interactively. This is especially beneficial or necessary when a set of commands:\nScripts form the basis for analysis pipelines and if we code things cleverly, it should be straightforward to rerun much of our project workflow:"
  },
  {
    "objectID": "modules/06_scripts.html#setup",
    "href": "modules/06_scripts.html#setup",
    "title": "Shell Scripting",
    "section": "1 Setup",
    "text": "1 Setup\n\n\n\n\n\n\nStarting a VS Code session with an active terminal (click here)\n\n\n\n\n\n\nLog in to OSC at https://ondemand.osc.edu.\nIn the blue top bar, select Interactive Apps and then Code Server.\nIn the form that appears:\n\nEnter 4 or more in the box Number of hours\nTo avoid having to switch folders within VS Code, enter /fs/ess/scratch/PAS2250/participants/&lt;your-folder&gt; in the box Working Directory (replace &lt;your-folder&gt; by the actual name of your folder).\nClick Launch.\n\nOn the next page, once the top bar of the box is green and says Runnning, click Connect to VS Code.\nOpen a terminal:   =&gt; Terminal =&gt; New Terminal.\nIn the terminal, type bash and press Enter.\nType pwd in the termain to check you are in /fs/ess/scratch/PAS2250.\nIf not, click   =&gt;   File   =&gt;   Open Folder and enter /fs/ess/scratch/PAS2250/&lt;your-folder&gt;."
  },
  {
    "objectID": "modules/06_scripts.html#script-header-lines-and-zombie-scripts",
    "href": "modules/06_scripts.html#script-header-lines-and-zombie-scripts",
    "title": "Shell Scripting",
    "section": "2 Script header lines and zombie scripts",
    "text": "2 Script header lines and zombie scripts\n\n2.1 Shebang line\nWe use a so-called “shebang” line as the first line of a script to indicate which language our script uses. More specifically, this line tell the computer where to find the binary (executable) that will run our script.\nSuch a line starts with #!, basically marking it as a special type of comment. After that, we provide the location to the relevant program: in our case Bash, which is located at /bin/bash on Linux and Mac computers.\n#!/bin/bash\nAdding a shebang line is good practice in general, and is necessary when we want to submit our script to OSC’s Slurm queue, which we’ll do tomorrow.\n\n\n\n2.2 Bash script settings\nAnother line that is good practice to add to your Bash scripts changes some default settings to safer alternatives. The following two Bash default settings are bad ideas inside scripts:\nFirst, and as we’ve seen in the previous module, Bash does not complain when you reference a variable that does not exist (in other words, it does not consider that an error).\nIn scripts, this can lead to all sorts of downstream problems, because you very likely tried and failed to do something with an actual variable. Even more problematically, it can lead to potentially very destructive file removal:\n\n# Using a variable, we try to remove some temporary files whose names start with tmp_\ntemp_prefix=\"temp_\"\nrm \"$tmp_prefix\"*     # DON'T TRY THIS!\n\n\n# Using a variable, we try to remove a temporary directory\ntempdir=output/tmp\nrm -rf $tmpdir/*      # DON'T TRY THIS!\n\n\n\n\n\n\n\nThe comments above specified the intent we had. What would have actually happened?\n\n\n\n\n\nIn both examples, there is a similar typo: temp vs. tmp, which means that we are referencing a (likely) non-existent variable.\n\nIn the first example, rm \"$tmp_prefix\"* would have been interpreted as rm *, because the non-existent variable is simply ignored. Therefore, we would have removed all files in the current working directory.\nIn the second example, along similar lines, rm -rf $tmpdir/* would have been interpreted as rm -rf /*. Horrifyingly, this would attempt to remove the entire filesystem (recall that a leading / in a path is a computer’s root directory).1 (-r makes the removal recursive and -f makes forces removal).\n\n\n\n\n\nSecond, a Bash script keeps running after encountering errors. That is, if an error is encountered when running line 2 of a script, any remaining lines in the script will nevertheless be executed.\nIn the best case, this is a waste of computer resources, and in worse cases, it can lead to all kinds of unintended consequences. Additionally, if your script prints a lot of output, you might not notice an error somewhere in the middle if it doesn’t produce more errors downstream. But the downstream results from what we at that point might call a “zombie script” may still be completely wrong.\n\nThe following three settings will make your Bash scripts more robust and safer. With these settings, the script terminates, with an appropriate error message, if:\n\nset -u — An unset (non-existent) variable is referenced.\nset -e — Almost any error occurs.\nset -o pipefail — An error occurs in a shell “pipeline” (e.g., sort | uniq).\n\nWe can change all of these settings in one line in a script:\n\nset -u -e -o pipefail     # (For in a script - don't run in the terminal)\n\nOr even more concisely:\n\nset -ueo pipefail         # (For in a script - don't run in the terminal)\n\n\n\n\n2.3 Our header lines as a rudimentary script\nLet’s go ahead and start a script with the header lines that we have so far discussed.\n\nInside your personal directory within /fs/ess/scratch/PAS2250/participants, make a directory called scripts and one called sandbox (e.g. mkdir scripts sandbox, or use the VS Code menus.\nOpen a new file in the VS Code editor (    =&gt;   File   =&gt;   New File) and save it as printname.sh within the newly created scripts dir.\n\n\n\n\n\n\nShell scripts, including Bash scripts, most commonly have the extension .sh\n\n\n\n\n\n\nType the following lines in that script (not in your terminal!):\n\n#!/bin/bash\nset -ueo pipefail\n\n\nAlready now, we could run (execute) the script. One way of doing this is calling the bash command followed by the name of the script2:\n\nbash scripts/printname.sh\n\nDoing this won’t print anything to screen (or file). Since our script doesn’t have any output, that makes sense — no output can be a good sign, because it means that no errors were encountered."
  },
  {
    "objectID": "modules/06_scripts.html#command-line-arguments-for-scripts",
    "href": "modules/06_scripts.html#command-line-arguments-for-scripts",
    "title": "Shell Scripting",
    "section": "3 Command-line arguments for scripts",
    "text": "3 Command-line arguments for scripts\n\n3.1 Calling a script with arguments\nWhen you call a script, you can pass it command-line arguments, such as a file to operate on.\nThis is much like when you provide a command like ls with arguments:\n\n# Run ls without arguments:\nls\n\n# Pass 1 filename as an argument to ls:\nls data/sampleA.fastq.gz\n\n# Pass 2 filenames as arguments to ls, separated by spaces:\nls data/sampleA.fastq.gz data/sampleB.fastq.gz\n\nLet’s see what this would look like with our printname.sh script and a fictional script fastqc.sh:\n\n# Run scripts without any arguments:\nbash fastqc.sh                            # (Fictional script)\nbash scripts/printname.sh\n\n# Run scripts with 1 or 2 arguments:\nbash fastqc.sh data/sampleA.fastq.gz      # 1 argument, a filename\nbash scripts/printname.sh John Doe        # 2 arguments, strings representing names\n\nIn the next section, we’ll see what happens when we pass arguments to a script on the command line.\n\n\n\n3.2 Placeholder variables\nInside the script, any command-line arguments are automatically available in placeholder variables.\nA first argument will be assigned to the variable $1, any second argument will be assigned to $2, any third argument will be assigned to $3, and so on.\n\n\n\n\n\n\nIn the calls to fastqc.sh and printname.sh above, what are the placeholder variables and their values?\n\n\n\n\n\nIn bash fastqc.sh data/sampleA.fastq.gz, a single argument, data/sampleA.fastq.gz, is passed to the script, and will be assigned to $1.\nIn bash scripts/printname.sh John Doe, two arguments are passed to the script: the first one (John) will be stored in $1, and the second one (Doe) in $2.\n\n\n\n\n\n\n\n\n\nPlaceholder variables are not automagically used\n\n\n\nArguments passed to a script are merely made available in placeholder variables — unless we explicitly include code in the script to do something with those variables, nothing else happens.\n\n\nLet’s add code to our printname.sh script to “process” any first and last name that are passed to the script as command-line arguments. For now, our script will simply echo the placeholder variables, so that we can see what happens:\n\n#!/bin/bash\nset -ueo pipefail\n\necho \"First name: $1\"\necho \"Last name: $2\"\n\n# (Note: this is a script. Don't enter this directly in your terminal.)\n\nNext, we’ll run the script, passing the arguments John and Doe:\n\nbash scripts/printname.sh John Doe\n\nFirst name: John\nLast name: Doe\n\n\n\n\nOn Your Own: Command-line arguments\nIn each case below, think about what might happen before you run the script. Then, run it, and if you didn’t make a successful prediction, try to figure out what happened instead.\n\nRun the script (scripts/printname.sh) without passing arguments to it.\nDeactivate (“comment out”) the line with set settings by inserting a # as the first character. Then, run the script again without passing arguments to it.\nDouble-quote John Doe when you run the script, i.e. run bash scripts/printname.sh \"John Doe\"\n\nTo get back to where we were, remove the # you inserted in the script in step 2 above.\n\n\n\n\n\n\nSolutions\n\n\n\n\n\n\nThe script will error out because we are referencing variables that don’t exist: since we didn’t pass command-line arguments to the script, the $1 and $2 have not been set.\n\n\nbash scripts/printname.sh\n\n\nprintname.sh: line 4: $1: unbound variable\n\n\nThe script will run in its entirety and not throw any errors, because we are now using default Bash settings such that referencing non-existent variables does not throw an error. Of course, no names are printed either, since we didn’t specify any:\n\n\nbash scripts/printname.sh\n\nFirst name: \nLast name: \n\n\nBeing commented out, the set line should read:\n\n#set -ueo pipefail\n\n\nBecause we are quoting \"John Doe\", both names are passed as a single argument and both names end up in $1, the “first name”:\n\n\nbash scripts/printname.sh \"John Doe\"\n\nFirst name: John Doe\nLast name: \n\n\n\n\n\n\n\n\n3.3 Descriptive variable names\nWhile you can use the $1-style placeholder variables throughout your script, I find it very useful to copy them to more descriptively named variables as follows:\n\n#!/bin/bash\nset -ueo pipefail\n\nfirst_name=$1\nlast_name=$2\n  \necho \"First name: $first_name\"\necho \"Last name: $last_name\"\n\n# (Note: this is a script. Don't enter this directly in your terminal.)\n\nUsing descriptively named variables in your scripts has several advantages. It will make your script easier to understand for others and for yourself. It will also make it less likely that you make errors in your script in which you use the wrong variable in the wrong place.\n\n\n\n\n\n\nOther variables that are automatically available inside scripts\n\n\n\n\n$0 contains the script’s file name\n$# contains the number of command-line arguments passed\n\n\n\n\n\nOn Your Own: A script to print a specific line\nWrite a script that prints a specific line (identified by line number) from a file.\n\nOpen a new file and save it as scripts/printline.sh\nStart with the shebang and set lines\nYour script takes two arguments: a file name ($1) and a line number ($2)\nCopy the $1 and $2 variables to descriptively named variables\nTo print a specific line, think how you might combine head and tail to do this. If you’re at a loss, feel free to check out the top solution box.\nTest the script by printing line 4 from data/meta/meta.tsv.\n\n\n\n\n\n\n\nSolution: how to print a specific line number\n\n\n\n\n\nFor example, to print line 4 of data/meta/meta.tsv directly:\n\nhead -n 4 data/meta/meta.tsv | tail -n 1\n\nJust note that in the script, you’ll be using variables instead of the “hardcode values” 4 and data/meta/meta.tsv.\nHow this command works:\n\nhead -n 4 data/meta/meta.tsv will print the first 4 lines of data/meta/meta.tsv\nWe pipe those 4 lines into the tail command\nWe ask tail to just print the last line of its input, which will in this case be line 4 of the original input file.\n\n\n\n\n\n\n\n\n\n\nFull solution\n\n\n\n\n\n\n#!/bin/bash\nset -ueo pipefail\n  \ninput_file=$1\nline_nr=$2\n\nhead -n \"$line_nr\" \"$input_file\" | tail -n 1\n\nTo run the script and make it print the 4th line of meta.tsv:\n\nbash scripts/printline.sh data/meta/meta.tsv 4\n\nSRR7609471  beach   control 3   40982374    78.70"
  },
  {
    "objectID": "modules/06_scripts.html#script-variations-and-improvements",
    "href": "modules/06_scripts.html#script-variations-and-improvements",
    "title": "Shell Scripting",
    "section": "4 Script variations and improvements",
    "text": "4 Script variations and improvements\n\n4.1 A script to serve as a starting point\nWe’ve learned that the head command prints the first lines of a file, whereas the tail command prints the last lines. Sometimes it’s nice to be able to quickly see both ends of a file, so let’s write a little script that can do that for us, as a starting point for the next few modifications.\nOpen a new file, save it as scripts/headtail.sh, and add the following code to it:\n\n#!/bin/bash\nset -ueo pipefail\n\ninput_file=$1\n\nhead -n 2 \"$input_file\"\necho \"---\"\ntail -n 2 \"$input_file\"\n\n# (Note: this is a script. Don't enter this directly in your terminal.)\n\nNext, let’s run our headtail.sh script:\n\nbash scripts/headtail.sh data/meta/meta.tsv\n\naccession   location    treatment   replicate   nreads_raw  pct_mapped\nSRR7609473  beach   control 1   45285752    76.01\n---\nSRR7609467  inland  treatment   2   47303936    79.25\nSRR7609474  inland  treatment   3   55728624    78.80\n\n\n\n\n\n4.2 Redirecting output to a file\nSo far, the output of our scripts was printed to screen, e.g.:\n\nIn printnames.sh, we simply echo’d, inside sentences, the arguments passed to the script.\nIn headtail.sh, we printed the first and last few lines of a file.\n\nAll this output was printed to screen because that is the default output mode of Unix commands, and this works the same way regardless of whether those commands are run directly on the command line, or are run inside a script.\nAlong those same lines, we have already learned that we can “redirect” output to a file using &gt; (write/overwrite) and &gt;&gt; (append) when we run shell commands — and this, too, works exactly the same way inside a script.\n\nWhen working with genomics data, we commonly have files as input, and new/modified files as output. Let’s practice with this and modify our headtail.sh script so that it writes output to a file.\nWe’ll make the following changes:\n\nWe will have the script accept a second argument: the output file name3.\nWe will redirect the output of our head, echo, and tail commands to the output file. We’ll have to append (using &gt;&gt;) in the last two commands.\n\n\n#!/bin/bash\nset -ueo pipefail\n\ninput_file=$1\noutput_file=$2\n\nhead -n 2 \"$input_file\" &gt; \"$output_file\"\necho \"---\" &gt;&gt; \"$output_file\"\ntail -n 2 \"$input_file\" &gt;&gt; \"$output_file\"\n\n# (Note: this is a script. Don't enter this directly in your terminal.)\n\nNow we run the script again, this time also passing the name of an output file:\n\nbash scripts/headtail.sh data/meta/meta.tsv sandbox/samples_headtail.txt\n\nThe script will no longer print any output to screen, and our output should instead be in sandbox/samples_headtail.txt:\n\n# Check that the file exists and was just modified:\nls -lh sandbox/samples_headtail.txt\n\n-rw-r--r--@ 1 poelstra.1  staff   197B Jul 16 16:12 sandbox/samples_headtail.txt\n\n\n\n# Print the contents of the file to screen\ncat sandbox/samples_headtail.txt\n\naccession   location    treatment   replicate   nreads_raw  pct_mapped\nSRR7609473  beach   control 1   45285752    76.01\n---\nSRR7609467  inland  treatment   2   47303936    79.25\nSRR7609474  inland  treatment   3   55728624    78.80\n\n\n\n\n\n4.3 Report what’s happening\nIt is often useful to have your scripts “report” or “log” what is going on. Let’s keep thinking about a script that has file(s) as the main output, but instead of having no output printed to screen at all, we’ll print some logging output to screen. For instance:\n\nWhat is the date and time\nWhich arguments were passed to the script\nWhat are the output files\nPerhaps even summaries of the output.\n\nAll of this can help with troubleshooting and record-keeping.4 Let’s try this with our headtail.sh script.\n\n#!/bin/bash\nset -ueo pipefail\n\n## Copy placeholder variables\ninput_file=$1\noutput_file=$2\n\n## Initial logging \necho \"Starting script $0\"           # Print name of script\ndate                                # Print date & time\necho \"Input file:   $input_file\"\necho \"Output file:  $output_file\" \necho                                # Print empty line to separate initial & final logging\n\n## Print the first and last two lines to a separate file\nhead -n 2 \"$input_file\" &gt; \"$output_file\"\necho \"---\" &gt;&gt; \"$output_file\"\ntail -n 2 \"$input_file\" &gt;&gt; \"$output_file\"\n\n## Final logging\necho \"Listing the output file:\"\nls -lh \"$output_file\"\necho \"Done with script $0\"\ndate\n\n# (Note: this is a script. Don't enter this directly in your terminal.)\n\nA couple of notes about the lines that were added to the script above:\n\nPrinting the date at the end of the script as well will allow you to check for how long the script ran, which can be informative for longer-running scripts.\nPrinting the input and output files (and the command-line arguments more generally) can be particularly useful for troubleshooting\nWe printed a “marker line” like Done with script, indicating that the end of the script was reached. This is handy due to our set settings: seeing this line printed means that no errors were encountered.\nI also added some comment headers like “Initial logging” to make the script easier to read, and such comments can be made more extensive to really explain what is being done.\n\nLet’s run the script again:\n\nbash scripts/headtail.sh data/meta/meta.tsv sandbox/tmp.txt\n\nStarting script scripts/headtail.sh\nSun Jul 16 16:12:57 EDT 2023\nInput file:   data/meta/meta.tsv\nOutput file:  sandbox/tmp.txt\n\nListing the output file:\n-rw-r--r--@ 1 poelstra.1  staff   197B Jul 16 16:12 sandbox/tmp.txt\nDone with script scripts/headtail.sh\nSun Jul 16 16:12:57 EDT 2023\n\n\nThe script printed some details for the output file, but not its contents (that would have worked here, but is usually not sensible when working with genomics data). Let’s take a look, though, to make sure the script worked:\n\ncat sandbox/tmp.txt      # \"cat\" prints all of a file's contents\n\naccession   location    treatment   replicate   nreads_raw  pct_mapped\nSRR7609473  beach   control 1   45285752    76.01\n---\nSRR7609467  inland  treatment   2   47303936    79.25\nSRR7609474  inland  treatment   3   55728624    78.80\n\n\n\n\n\n\n\n\necho, echo\n\n\n\nThe extensive reporting (echo-ing) may have seemed silly for our little script, but fairly extensive reporting (as well as testing, but that’s outside the scope of this workshop) can be very useful — and will be eventually a time-saver.\nThis is especially true for long-running scripts, or scripts that you often reuse and perhaps share with others.\n\n\n\n\nOn Your Own: A fanciful script\nModify your printline.sh script to:\n\nRedirect output to a file\nThis output file should not be “hardcoded” in the script, but its name should be passed as an argument to the script, like we did above with headtail.sh\nAdd a bit of reporting — echo statements, date, etc, along the lines of what we did above with headtail.sh\nAdd some comments to describe what the code in the script is doing\n\n\n\n\n\n\n\nThe original printline.sh script\n\n\n\n\n\n\n\n\n#!/bin/bash\nset -ueo pipefail\n  \ninput_file=$1\nline_nr=$2\n\nhead -n \"$line_nr\" \"$input_file\" | tail -n 1\n\n\n\n\n\n\n\n\n\n\n\n(One possible) solution\n\n\n\n\n\n\n#!/bin/bash\nset -ueo pipefail\n\n## Copy placeholder variables\ninput_file=$1\noutput_file=$2\nline_nr=$3\n\n## Initial logging \necho \"Starting script $0\"           # Print name of script\ndate                                # Print date & time\necho \"Input file:   $input_file\"\necho \"Output file:  $output_file\"\necho \"Line number:  $line_nr\"\necho                                # Print empty line to separate initial & final logging\n\n## Print 1 specific line from the input file and redirect to an output file\nhead -n \"$line_nr\" \"$input_file\" | tail -n 1 &gt; $output_file\n\n## Final logging\necho \"Listing the output file:\"\nls -lh \"$output_file\"\necho \"Done with script $0\"\ndate\n\nTo run the script with the additional argument:\n\nbash scripts/printline.sh data/meta/meta.tsv sandbox/meta_line.tsv 4\n\nStarting script scripts/printline.sh\nSun Jul 16 16:12:57 EDT 2023\nInput file:   data/meta/meta.tsv\nOutput file:  sandbox/meta_line.tsv\nLine number:  4\n\nListing the output file:\n-rw-r--r--@ 1 poelstra.1  staff    42B Jul 16 16:12 sandbox/meta_line.tsv\nDone with script scripts/printline.sh\nSun Jul 16 16:12:57 EDT 2023"
  },
  {
    "objectID": "modules/06_scripts.html#footnotes",
    "href": "modules/06_scripts.html#footnotes",
    "title": "Shell Scripting",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nBut note that at OSC, you would not be able to remove anything you’re not supposed to, since you don’t have the permissions to do so. On your own computer, this could be more genuinely dangerous, though even there, you would not be able to remove the operating system without specifically requesting “admin” rights.↩︎\nBecause our script has a shebang line, we could also execute the script without the bash command using ./printname.sh. However, this would also require us to “make the script executable”, which is beyond the scope of this workshop.↩︎\nOf course, we could also simply write the output to a predefined (“hardcoded”) file name such as out.txt, but in general, it’s better practice to keep this flexible via an argument.↩︎\nWe’ll see in the upcoming SLURM module that we when submit scripts to the OSC queue (rather than running them directly), the output of scripts that is normally printed to screen, will instead go to a sort of “log” file. So, your script’s reporting will end up in this file.↩︎"
  },
  {
    "objectID": "modules/02_osc.html#the-ohio-supercomputer-center-osc",
    "href": "modules/02_osc.html#the-ohio-supercomputer-center-osc",
    "title": "Intro to the Ohio Supercomputer Center (OSC)",
    "section": "1 The Ohio Supercomputer Center (OSC)",
    "text": "1 The Ohio Supercomputer Center (OSC)\n\n1.1 Supercomputers\nA supercomputer (also known as a “cluster”) consists of many computers that are connected by a high-speed network, and that can be accessed remotely by its users. In more general terms, supercomputers provide high-performance computing (HPC) resources.\nHere are some possible reasons to use a supercomputer instead of your own laptop or desktop:\n\nYour analyses take a long time to run.\nYou analyses need large numbers of CPUs or a large amount of memory.\nYou need to run some analyses many times.\nYou need to store tons and tons of data.\nYou need a safe archival site for your data.\nYour analyses require specialized hardware, such as GPUs.\nYour analyses require software available only for the Linux operating system, but you use Windows.\n\nThese kinds of situations can make it hard or simply impossible to solely work on your personal workstation, depending on the exact amount of data, and so on.\nWhen you’re working RNAseq data or other kinds of genomic data, many of these reasons apply.\n\n\n1.2 The Ohio Supercomputer Center (OSC)\nThe Ohio Supercomputer Center (OSC) is a resource provided by the state of Ohio (not The Ohio State University).\nThis session will provide an introduction to supercomputers in general and OSC specifically. In upcoming sessions, we’ll continue to work at OSC, so you will get a fair bit of experience with it. We’ll also have specific sessions dedicated to OSC-related things like loading and installing software at OSC and using the SLURM job scheduler.\n\n\n1.3 OSC websites\n\nhttps://osc.edu: OSC’s general website, with lots of information about the supercomputers, the software that’s installed, and how to use OSC.\nhttps://ondemand.osc.edu: A direct access point to use OSC through your browser (login needed).\nhttps://my.osc.edu: Management of your personal account and any Projects you manage (login needed)."
  },
  {
    "objectID": "modules/02_osc.html#the-structure-of-a-supercomputer-center",
    "href": "modules/02_osc.html#the-structure-of-a-supercomputer-center",
    "title": "Intro to the Ohio Supercomputer Center (OSC)",
    "section": "2 The Structure of a Supercomputer Center",
    "text": "2 The Structure of a Supercomputer Center\nLet’s start with some terminology, going from smaller things to bigger things:\n\nCore / Processor / CPU / Thread — Components of a computer that can each (semi-)indendepently be asked to perform a computing task like running a bioinformatics program. While these terms are not technically all synonyms, we can treat them as such for our purposes.\nNode — A single computer that is a part of a supercomputer and has dozens of cores.\nSupercomputer / Cluster — Many computers connected by a high-speed network. (“Pitzer” and “Owens” are the two currently active ones at OSC.)\nSupercomputer Center — A facility like OSC that has one or more supercomputers.\n\n\n\n\nThis is what the Owens supercomputer at OSC physically looks like:\n\n\n\n\n\n\n\n\n\nLinux and Unix\n\n\n\nLike the vast majority of supercomputers, OSC’s run on the Linux operating system (as opposed to on MacOS or Windows). In turn, Linux is a Unix-based operating system like MacOS (but unlike Windows).\n\n\nWe can think of a supercomputer as having three main parts:\n\nFile Systems: Where files are stored (these are shared between the two clusters!)\nLogin Nodes: The handful of computers everyone shares after logging in\nCompute Nodes: The many computers you can reserve to run your analyses\n\n\n\n\nLet’s take those in order.\n\n\n2.1 File Systems\nThere are 4 main file systems where you can store files at OSC: Home Directories, Project Directories, Scratch Directories, and Compute storage.\n\n\n\n\n\n\n\n\n\n\n\nFile system\nLocated within\nQuota\nBacked up?\nAuto-purged?\nOne for each…\n\n\n\n\nHome\n/users/\n500 GB / 1 M files\nYes\nNo\nUser\n\n\nProject\n/fs/ess/ 1\nFlexible\nYes\nNo\nOSC Project\n\n\nScratch\n/fs/scratch/ 2\n100 TB\nNo\nAfter 90 days\nOSC Project\n\n\nCompute\n$TMPDIR\n1 TB\nNo\nAfter job completes\nCompute job\n\n\n\nYou’ll interact most with the Project directories: this is because for most files, you’ll want a permanent and backed-up location (i.e., not Scratch or Compute storage), and the Home directory offers relatively limited storage as well as challenges with file sharing.\n\n\n\n\n\n\nUnix terminology and environment variables\n\n\n\nWe’ll talk about all of this more in upcoming sessions, but to clarify some of the terms and concepts mentioned here:\n\n“Directory” (or “dir” for short) is a commonly used term in Unix that just means “folder”.\nIn the “Located within” column in the table above, the leading forward slash / signifies the system’s “root” (top-level) directory, and forward slashes are also used to separate directories (unlike in Windows, which uses backslashes).\nFile and directory locations on a computer are often referred to as “paths”\n$TMPDIR is a so-called “environment variable” that contains the actual path to the Compute storage directory (in the Unix shell, all variables are referenced by putting a $ before their name, and environment variables are in all-caps). A variable is useful in this case, because its location will vary depending on the compute node at which it’s located. Along similar lines, your Home directory’s path is stored in $HOME.\n\n\n\n\n2.1.1 Home Directory\nWhen you initially get an account with OSC, a Home directory is created for you, named with your OSC username. This directory will always be within /users/, and then, somewhat strangely, in a directory containing the name of the OSC Project you were first added to (and this will not change even if you’re no longer a member of that project, or if that project ceases to exist). For example, my Home directory is /users/PAS0471/jelmer.\nYou will only ever have one Home directory. You also cannot expand the standard 500 GB of storage — if you need more space, you should turn to your Project directories.\nIf possible, I recommend to use your Home directory only for some general files (like some software, tutorials and practice, general scripts), and to use Project directories for all your research project data and results.\n\n\n2.1.2 Project Directories\nProject directories are linked to OSC projects, which are typically set up by PIs. They offer flexibility in terms of the amount of storage available (requested at the time of set-up, and then easily adjustable after that), and also in terms of who can access files in the directory.\nBy default, all members of a project have “read access” (the ability to see and copy files) for all files in a project directory, which makes it suitable for collaborating on a research project. But rest assured: except for OSC staff, other people can never move, modify, or delete your files (i.e., they don’t have “write access”) — this includes the admins (PIs) for the OSC Project in question.\nLike Home directories, Project directories are backed up daily. You don’t have direct access to the backups, but if you’ve, for example, accidentally deleted some important files (Linux has no thrash bin!), you can request them to be restored to the way they were on a specific date.\n\n\n\n\n\n\nFile Systems are shared among the clusters\n\n\n\nWhile OSC’s current two clusters, Owens and Pitzer, are largely separate, they do share the same File System. This means that you can access your files in the exact same way regardless of which supercomputer you have connected to.\nFor example, your Home directory can be accessed using the same path (in my case, /users/PAS0471/jelmer) on Pitzer and Owens.\n\n\n\n\n2.1.3 Temporary storage: Scratch and Compute\nThe Scratch file system provides temporary storage space, and every Project has a Scratch directory. The two main advantages of Scratch space are that it is effectively unlimited and that it has faster data read and write (“I/O”) speed than Home and Project space. However, it’s not backed up, and files that are unmodified for 90 days are automatically deleted. As such, Scratch storage is mostly useful for intermediate results that are likely not needed again and can be reproduced easily.3\nCompute storage space is even more fleeting: as soon as the compute “job” in question has stopped (e.g. your script has finished), these files will be deleted. We’ll talk a bit more about this type of storage later, as using them can save time for I/O-intensive analyses.\n\n\n\n\n2.2 Login Nodes\nLogin nodes are set aside as an initial landing spot for everyone who logs in to a supercomputer. There are only a handful of them on each supercomputer, and they are shared among everyone and cannot be “reserved”.\nAs such, login nodes are meant only to do things like organizing your files and creating scripts for compute jobs, and are not meant for any serious computing.\nAttempting large computing efforts on these nodes risks taxing the limited resources on these nodes, and bogging things down for everyone. There are checks built in that limit what you are able to do on the login nodes (i.e. jobs running for longer than 20 minutes will be killed), but it’s best to just not push it at all. Any serious computing should be done on the compute nodes.\n\n\n\n2.3 Compute Nodes\nCompute nodes are really the powerhouse of the supercomputer, and this is where you run your data processing and analysis.\nYou can use compute nodes by putting in requests for resources, such as the number of nodes, cores, and for how long you will need them. As many different users are sending such requests (“compute jobs” or just “jobs”) all the time, there is software called a job scheduler (specifically, Slurm in the case of OSC) that considers each request and assigns the necessary resources to the job as they become available.\n\n\n\n\n\n\nInteractive and batch use of compute nodes\n\n\n\nRequests for compute node jobs can be made either through the OnDemand website or with commands like sinteractive and sbatch.\nFor instance, when we start an RStudio session at OSC, we first have to fill out a little form with such a request, and then RStudio will run on a compute node. This is an example of using a compute node interactively — “you” are located on a compute node, and any R command you type will be executed there. Even more commonly for genomics work, you’ll be using compute nodes non-interactively, that is, through “batch jobs”. When doing so, you will write a script in advance and send it to the job scheduler, which will run it on a compute node that “you” don’t go to at all.\nThe session Compute Jobs with Slurm is dedicated to this topic.\n\n\nCompute nodes come in different shapes and sizes. “Standard nodes” are by far the most numerous (e.g., Owens has 648 and Pitzer has 564) and even those vary in size, from 28 cores per node (Owens) to 48 cores per node (the “expansion” part of Pitzer). Some examples of other types of nodes are ones with extra memory (largemem and hugemem) and ones that provide access to GPUs (Graphical Processing Units) rather than CPUs.\nFortunately, you don’t tend to have to think much about node types as you start using OSC, since Standard nodes are automatically picked by default, and those will serve you well for the vast of majority genomics analysis.4\n\n\n\n\n\n\nMemory versus storage\n\n\n\nWhen we talk about “memory”, this refers to RAM: the data that your computer has actively “loaded” or in use. For example, if you play a computer game or have many browser tabs open, your computer’s memory will be heavily used. Genomics programs sometimes load all of the input data from disk to memory for fast access, or hold a huge assembly graph in memory, and as such may need a lot of memory as well.\nDon’t confuse memory with file storage, the data that is on disk.\n\n\n\n\n\n2.4 Putting it together\nAll these parts are connected together to create a supercomputer — for example, let’s take a look at the specs for Owens now that we understand the components a bit better:"
  },
  {
    "objectID": "modules/02_osc.html#file-systems",
    "href": "modules/02_osc.html#file-systems",
    "title": "Intro to the Ohio Supercomputer Center (OSC)",
    "section": "3 File Systems",
    "text": "3 File Systems\nThere are 4 main file systems where you can store files at OSC (note that the leading forward slash / signifies the “root” directory of the file system):\n\nHome Directories: /users/\nProject Directories: /fs/ess/ (or /fs/project)\nScratch Directories: /fs/scratch\nCompute\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFile system\nLocated within\nQuota\nBacked up?\nAuto-purged?\nOne for each…\n\n\n\n\nHome\n/users/ ($HOME)\n500 GB / 1 M files\nYes\nNo\nUser\n\n\nProject\n/fs/ess/ (or /fs/project/)\nFlexible\nYes\nNo\nOSC Project\n\n\nScratch\n/fs/scratch/ (or /fs/ess/scratch)\n100 TB\nNo\nAfter 90 days\nOSC Project\n\n\nCompute Node\n$TMPDIR\n1 TB\nNo\nAfter job completes (!)\nCompute job\n\n\n\nThe type you should interact with the most by far are the Project directories: for most files, you’ll want a permanent and backed-up location (i.e., not scratch or compute storage), and the Home directory offers too limited storage and challenges with file sharing.\nNOTES: - “Directory” (or “dir” for short) is a commonly used term in Unix that just means “folder”. - In the Locations listed above, the leading forward slash / signifies the “root” directory of the file system, and forward slashes are also used to separate directories (unlike in Windows, where backslashed are used)\n\n3.0.1 Home Directory\nWhen you initially get an account with OSC, a Home directory is created for you, named with your OSC username. This directory will always be within /users/. Somewhat strangely, it will be placed in a subfolder containing the name of the OSC Project you had been added to before you created your account (and this will not change even if you’re no longer a member of that project or even if that project ceases to exist). For example, my Home directory is /users/PAS0471/jelmer.\nThis Home directory provides you with up to 500 GB of storage (or up to 1 million files). This is considered permanent storage, so it is well backed-up. OSC does not allow you to request more storage space in your Home directory – if you need more space, you should use your Project directories.\n\n\n3.0.2 Project Directories\nProject directories are linked to OSC project, which are typically set up by PIs.\nProject directories offer flexibility in terms of the amount of storage available (requested at the time of set-up, and then easily adjustable after that), and also in terms of who can access files in the directory.\nUnlike your Home directory, where typically only you will have access to the files it contains, Projects are meant to be available to a specified group of people - say the members of a lab all working on a project.\nLike Home directories, these are also backed up routinely. Project directories are located inside either /fs/project/ or /fs/ess/.\n\n\n3.0.3 Scratch Storage\nThe Scratch file system is meant to provide temporary storage space. Every Project directory has a corresponding Scratch directory. The two main advantages of Scratch space is that it is effectively unlimited and that it has faster data read and write (or: I/O) speed than storage space. However, it’s not backed up, and files that are unmodified for a specific amount of time are automatically deleted."
  },
  {
    "objectID": "modules/02_osc.html#login-nodes",
    "href": "modules/02_osc.html#login-nodes",
    "title": "Intro to the Ohio Supercomputer Center (OSC)",
    "section": "3 Login Nodes",
    "text": "3 Login Nodes\nLogin nodes are set aside as an initial landing spot for everyone who logs in to a supercomputer. There are only a handful of them on each supercomputer, and they are shared among everyone and cannot be “reserved”.\nAs such, login nodes are meant only to do things like organizing your files and creating scripts for compute jobs, and are NOT meant for any serious computing.\nAttempting large computing efforts on these nodes risks taxing the limited resources on these nodes, and bogging things down for everyone. There are checks built in that limit what you are able to do on the login nodes (i.e. jobs running for longer than 20 min will be killed), but it’s best to just not push it at all. Any bigger computing jobs are better sent to the compute nodes."
  },
  {
    "objectID": "modules/02_osc.html#compute-nodes",
    "href": "modules/02_osc.html#compute-nodes",
    "title": "Intro to the Ohio Supercomputer Center (OSC)",
    "section": "3 Compute Nodes",
    "text": "3 Compute Nodes\nCompute nodes are really the powerhouse of the supercomputer, and this is where you run your data processing and analysis.\nTypical OSC nodes … size, and there are different types of compute nodes, such as ones with unusally large amounts of memory (largemem and hugemem) and ones that provide access to GPUs (Graphical Processing Units) rather than CPUs.\nThere are two main ways to get access to a compute node. Interactively… Batch job…\nEach time you send a compute job to the compute cluster, you also make a request for the number of resources the job will need - specifically, the number of nodes, cores, and how long the job will run. As there are jobs being sent by different users all the time, there is software called a job scheduler that considers each request and assigns the necessary resources to the job as they are available. We’ll talk about that more later in the workshop.\nAll these parts are connected together to create a supercomputer — for example, let’s take a look at the specs for Owens now that we understand the components a bit better:"
  },
  {
    "objectID": "modules/02_osc.html#connecting-to-osc",
    "href": "modules/02_osc.html#connecting-to-osc",
    "title": "Intro to the Ohio Supercomputer Center (OSC)",
    "section": "3 Connecting to OSC",
    "text": "3 Connecting to OSC\nTraditionally, people connect to supercomputers using the ssh command in a Unix shell on their own computer. However, OSC has pioneered the use of a web portal called OnDemand, which is now more widely used among supercomputer centers (!).\nThe OSC OnDemand website, https://ondemand.osc.edu, then, allows you to access OSC resources through a web browser. When you go there you first need to log in with your OSC (not OSU!) credentials. After that, you should see a landing page similar to the one below:\n\n\n\nThe main part of the page only contains some general OSC messages and updates — what we will focus on instead are some of the options in the blue bar along the top.\n\n3.1 OnDemand file system access\nLet’s start with Files. Hovering over this gives a list of directories you have access to. If you’re account is new, you might only have one or two. I’m associated with quite a few different projects, so I have a bunch. I’ll select my Home directory.\n\n\n\nHere I can see a list of directories and files that are in my Home directory.\n\n\n\nThere are also a series of useful buttons across the top. One note about the Upload/Download buttons here - these are great in many cases, but likely won’t be a good option for especially large files. Other options, such as Globus, are available for these (more info on Globus here).\n\n\n3.2 OnDemand System Status\n\n\n\n\n\n3.3 OnDemand Unix shell access\nInteracting with a supercomputer in a point-and-click manner only goes so far. Using a supercomputer effectively requires interacting with the system using a command-line (CLI) rather than a graphical user (GUI) interface.\nOne option available for doing that is under the Clusters option in the blue top bar:\n\n\n\nHere I’m selecting access to a Unix shell on the Pitzer supercomputer, which will open a new browser tab looking like this:\n\n\n\nWe most commonly interact with a supercomputer using a Unix shell, where we can type commands for the computer to execute, all the way from a basic command to list files, to running programs with command-line interfaces to process our sequence data. However, we’ll be accessing a Unix shell via the VS Code text editor, which also gives us some additional functionality in a user-friendly way.\n\n\n3.4 OnDemand Interactive Apps\nHowever, we’re going to check out one more option - a program called VS Code, which gives us the same basic shell access, but also includes some additional features that we might find useful later on. We can access VS Code by selecting Code Server under the Interactive Apps option on the OnDemand homepage (near the bottom of the list).\n\n\n\nIn this case, we need to provide a maximum time to keep the App open. The default is 6 hours. That will be fine for our purposes - you could even go a bit less, but remember that if you select 2 hours, you’ll be kicked off at the 2-hour mark, so usually better to err on the side of overestimating here.\n\n\n\nClick on Launch at the bottom and this will send your request to run the App for a maximum of the number of hours you chose. Once it’s ready, you’ll get a screen that looks like…\n\n\n\nWhen it’s available, click on the blue Connect to VS Code button and you should see the following Welcome screen…\n\n\n\n\n\n3.5 Connecting through SSH\nTo connect to OSC or other remote computers without using a webportal like OnDemand, you can use SSH. You can do so via the ssh command if you have a Linux or, more likely, a Mac computer, since these two operating systems are both Unix-based and have built-in terminals with Unix shells. If you have a Windows computer, you can instead use a GUI-based SSH client like PuTTY. Alternatively, for an experience more similar to that if you did have a Unix-based operating system, you can install Windows Subsystem for Linux (WSL) or Git Bash — these will allow you to open a terminal program that does run a Unix shell.\nHere, I’ll briefly show how to use the ssh command. Open your terminal, and input the command ssh &lt;username&gt;@&lt;hostname&gt;, where: - &lt;username&gt; should be replaced by your OSC username, and - &lt;hostname&gt; should be replaced by the name of the computer you want to connect to: - pitzer.osc.edu to connect to the Pitzer cluster - owens.osc.edu to connect to the Owens cluster\nFor example, if I (username jelmer) wanted to log in to the Pitzer cluster, I would use:\nssh jelmer@pitzer.osc.edu\nIf you’ve never connected to this particular server before, you’ll encounter a message similar to this:\nThe authenticity of host 'pitzer.osc.edu' can't be established.\nRSA key fingerprint is 2a:b6:f6:8d:9d:c2:f8:2b:8c:c5:03:06:a0:f8:59:12.\nAre you sure you want to continue connecting (yes/no)?\nThis is your computer warning you that you’re about to connect to a computer you haven’t connected to before: type yes to proceed. This will add the HPC to your “known hosts”, and you shouldn’t see the message again in the future.\nWarning: Permanently added 'pitzer.osc.edu' (RSA) to the list of known hosts.\nYou should now be prompted for your password. Type it in carefully (no characters will appear on the screen), then press Enter.\nusername@pitzer.osc.edu's password:\nIf you entered your password appropriately, congratulations, you’re now connected to the HPC! You’ll have shell access very much in the same way as when using the Pitzer Shell Access button on OSC OnDemand. The key difference is that the terminal doesn’t run inside your browser, which can be nice."
  },
  {
    "objectID": "modules/02_osc.html#accounts-osc-projects-and-billing",
    "href": "modules/02_osc.html#accounts-osc-projects-and-billing",
    "title": "Intro to the Ohio Supercomputer Center (OSC)",
    "section": "5 Accounts, OSC Projects, and Billing",
    "text": "5 Accounts, OSC Projects, and Billing"
  },
  {
    "objectID": "modules/02_osc.html#more-resources-to-learn-about-osc-and-hpc-computing",
    "href": "modules/02_osc.html#more-resources-to-learn-about-osc-and-hpc-computing",
    "title": "Intro to the Ohio Supercomputer Center (OSC)",
    "section": "5 More resources to learn about OSC and HPC computing",
    "text": "5 More resources to learn about OSC and HPC computing\n\n5.1 In this series of lessons\nIn separate sessions in this series, we will look at:\n\nUsing “Interactive Apps” (GUI-based programs) such as RStudio and VS Code at OSC\nLoading and installing command-line software at OSC\nSubmitting batch jobs using the SLURM scheduler\n\nFinally, at the bottom of the page, there is an addendum on file transfer from and to OSC.\n\n\n5.2 OSC’s own resources\n\nOSC’s online asynchronous courses\n\nWhen I tried to access these last, it wasn’t always clear where to go after enrolling, and one of the two courses has even diseappeared from the list. But this website https://scarlet.instructure.com listed the courses and provided access.\n\nOSC “events” such as Office Hours and synchronous online introductory sessions\nOSC’s New User Resource Guide\nOSC’s Supercomputing FAQ\nOSC’s HOWTOs for tutorials on specific topics\nOSC’s info on batch (non-interactive) compute jobs (rather technical)"
  },
  {
    "objectID": "modules/02_osc.html#misc.-notes",
    "href": "modules/02_osc.html#misc.-notes",
    "title": "Intro to the Ohio Supercomputer Center (OSC)",
    "section": "5 Misc. notes",
    "text": "5 Misc. notes\n\nIt’s good to acknowledge and cite OSC in your papers, see their citation page.\nFor many questions such as if you have problems with your account, have problems installing or using specific software, or don’t understand why your jobs keep failing, you can email osc at oschelp@osc.edu."
  },
  {
    "objectID": "modules/02_osc.html#acknowledgements",
    "href": "modules/02_osc.html#acknowledgements",
    "title": "Intro to the Ohio Supercomputer Center (OSC)",
    "section": "5 Acknowledgements",
    "text": "5 Acknowledgements\nThis page is based on an OSC Introduction written by Mike Sovic at https://mcic-osu.github.io/cl-workshop-22/modules/02-osc.html. It also uses some text from OSC’s Kate Cahill Software Carpentry introduction to OSC at https://khill42.github.io/OSC_IntroHPC."
  },
  {
    "objectID": "modules/02_osc.html#at-home-reading-transferring-files-to-and-from-osc",
    "href": "modules/02_osc.html#at-home-reading-transferring-files-to-and-from-osc",
    "title": "Intro to the Ohio Supercomputer Center (OSC)",
    "section": "5 At home reading: transferring files to and from OSC",
    "text": "5 At home reading: transferring files to and from OSC\n\nUsing OSC OnDemand (as seen above)\nUsing scp (or similar, more advanced commands like rsync and rclone)\nUsing Globus\nNote that if you need files that are at a publicly accessible location on the internet (for example, NCBI reference genome data), you don’t need to download these to your computer and then upload them to OSC. Instead, you can use commands for downloading files, usually wget or curl. We’ll get to that later on.\n\n\n5.1 Connecting through SSH\nTo connect to OSC or other remote computers without using a webportal like OnDemand, you can use SSH. You can do so via the ssh command if you have a Linux or, more likely, a Mac computer, since these two operating systems are both Unix-based and have built-in terminals with Unix shells. If you have a Windows computer, you can instead use a GUI-based SSH client like PuTTY. Alternatively, for an experience more similar to that if you did have a Unix-based operating system, you can install Windows Subsystem for Linux (WSL) or Git Bash — these will allow you to open a terminal program that does run a Unix shell.\nHere, I’ll briefly show how to use the ssh command. Open your terminal, and input the command ssh &lt;username&gt;@&lt;hostname&gt;, where: - &lt;username&gt; should be replaced by your OSC username, and - &lt;hostname&gt; should be replaced by the name of the computer you want to connect to: - pitzer.osc.edu to connect to the Pitzer cluster - owens.osc.edu to connect to the Owens cluster\nFor example, if I (username jelmer) wanted to log in to the Pitzer cluster, I would use:\nssh jelmer@pitzer.osc.edu\nIf you’ve never connected to this particular server before, you’ll encounter a message similar to this:\nThe authenticity of host 'pitzer.osc.edu' can't be established.\nRSA key fingerprint is 2a:b6:f6:8d:9d:c2:f8:2b:8c:c5:03:06:a0:f8:59:12.\nAre you sure you want to continue connecting (yes/no)?\nThis is your computer warning you that you’re about to connect to a computer you haven’t connected to before: type yes to proceed. This will add the HPC to your “known hosts”, and you shouldn’t see the message again in the future.\nWarning: Permanently added 'pitzer.osc.edu' (RSA) to the list of known hosts.\nYou should now be prompted for your password. Type it in carefully (no characters will appear on the screen), then press Enter.\nusername@pitzer.osc.edu's password:\nIf you entered your password appropriately, congratulations, you’re now connected to the HPC! You’ll have shell access very much in the same way as when using the Pitzer Shell Access button on OSC OnDemand. The key difference is that the terminal doesn’t run inside your browser, which can be nice."
  },
  {
    "objectID": "modules/02_osc.html#introduction",
    "href": "modules/02_osc.html#introduction",
    "title": "Intro to the Ohio Supercomputer Center (OSC)",
    "section": "1 Introduction",
    "text": "1 Introduction\nThis session will provide an introduction to supercomputers in general and to the Ohio Supercomputer Center (OSC) specifically.\n\n1.1 Supercomputers\nA supercomputer (also known as a “compute cluster” or simply a “cluster”) consists of many computers that are connected by a high-speed network, and that can be accessed remotely by its users. In more general terms, supercomputers provide high-performance computing (HPC) resources.\nHere are some possible reasons to use a supercomputer instead of your own laptop or desktop:\n\nYour analyses take a long time to run.\nYou analyses need large numbers of CPUs or a large amount of memory.\nYou need to run some analyses many times.\nYou need to store a lot of data.\nYour analyses require specialized hardware, such as GPUs.\nYour analyses require software available only for the Linux operating system, but you use Windows.\n\nThese kinds of situations can make it hard or simply impossible to solely work on your personal workstation, depending on the exact amount of data, and so on. When you’re working RNAseq data or other kinds of genomic data, many of these reasons apply.\n\n\n1.2 The Ohio Supercomputer Center (OSC)\nThe Ohio Supercomputer Center (OSC) is a facility provided by the state of Ohio (not The Ohio State University). It has two supercomputers, lots of storage space, and an excellent infrastructure for accessing these resources. At least for folks at OSU, using OSC is currently usually free in practice. Having such a good HPC resource available at no cost is not something we should take for granted — at many institutions, academics not only have have to pay for these kinds of resources, but those are often not as good.\nIn upcoming sessions, we’ll continue to work at OSC, so you will get a fair bit of experience with using it. We’ll also have specific sessions dedicated to using VS Code at OSC, loading and installing software at OSC and using the SLURM job scheduler.\nOSC has three main websites:\n\nhttps://osc.edu: OSC’s general website, with lots of information about the supercomputers, the software that’s installed, and how to use OSC.\nhttps://ondemand.osc.edu: A web portal to use OSC through your browser (login needed).\nhttps://my.osc.edu: A site to manage your account and Projects you are an admin for (login needed)."
  },
  {
    "objectID": "modules/02_osc.html#footnotes",
    "href": "modules/02_osc.html#footnotes",
    "title": "Intro to the Ohio Supercomputer Center (OSC)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOr /fs/project/↩︎\nOr /fs/ess/scratch↩︎\nFor example, many genome and transcriptome assemblers output a lot of data, but you will only need a few files (like the assembly) for your next steps.↩︎\nSome examples where you might need a different type of node are genome or transcriptome assembly where you might need nodes with a lot of memory, or Oxford Nanopore sequence data basecalling where you might need GPUs.↩︎"
  },
  {
    "objectID": "modules/02_osc.html#in-closing",
    "href": "modules/02_osc.html#in-closing",
    "title": "Intro to the Ohio Supercomputer Center (OSC)",
    "section": "4 In Closing",
    "text": "4 In Closing\n\n4.1 Administrative miscellaneae\n\nRequesting & managing OSC Projects, and user accounts\nGenerally, only PIs request OSC projects, and they typically manage them as well. OSC has this page with more information on how to do so. Whoever manages an OSC Project can add both existing OSC users and new users to the Project, which will provide these users with access the project’s Project and Scratch directories, and the ability to specify this Project in association with compute node resource requests.\nWhen you get added to an OSC Project and don’t yet have an OSC account, you will automatically receive an email with a link that allows you to create an account. It is not possible to create an account before having been added to an OSC Project.\nBilling\nOSC will bill OSC Projects (not individual users), and only for the following two things:\n\nFile storage in the Project Storage file system\nCompute node usage by “core hour” (e.g. using 2 cores for 2 hours = 4 core hours)\n\nThe prices for academic usage are quite low (see this page for specifics), and importantly, at OSU, they are often covered at the department level such that individual PIs do not have to directly pay for this at all.\nWhen you use OSC, it’s good practice to acknowledge and cite OSC in your papers, see their citation page.\nFor many questions such as if you have problems with your account, have problems installing or using specific software, or don’t understand why your jobs keep failing, you can email OSC at oschelp@osc.edu. They are usually very quick to respond!\n\n\n\n\n4.2 Upcoming sessions on OSC\nToday, we have learned some of the basics of supercomputers and of accessing OSC. In separate sessions in this series, we will look at:\n\nUsing specific “Interactive Apps” (GUI-based programs):\n\nVS Code\nRStudio (TBA)\n\nLoading and installing command-line software at OSC\nSubmitting batch jobs using the SLURM scheduler\n\nAdditionally, there are pages with reference material (see the right side of the top menu bar of this side) on:\n\nFile transfer to and from OSC\nUsing OSC with SSH (rather than through OnDemand)\n\n\n\n\n4.3 OSC’s learning resources\nTo learn more about OSC, I would start with these short courses:\n\nOSC’s online asynchronous courses\n\nThis includes a number of short videos\nWhen I tried to access these last, it wasn’t always clear where to go after enrolling, and one of the two courses had even diseappeared from the list. But the website https://scarlet.instructure.com then listed the courses and provided access.\n\n\nThis series of pages is also useful:\n\nNew User Resource Guide\nSupercomputing FAQ\nHOWTOs (tutorials on specific topics)\nInfo on batch (non-interactive) compute jobs (rather technical)\nOSC “events” such as Office Hours\n\n\n\n\n4.4 Acknowledgements\nThis page uses material from an OSC Introduction written by Mike Sovic and from OSC’s Kate Cahill Software Carpentry introduction to OSC (outdated)."
  },
  {
    "objectID": "modules/02_osc.html#connecting-to-osc-with-ondemand",
    "href": "modules/02_osc.html#connecting-to-osc-with-ondemand",
    "title": "Intro to the Ohio Supercomputer Center (OSC)",
    "section": "3 Connecting to OSC with OnDemand",
    "text": "3 Connecting to OSC with OnDemand\nThe classic way of connecting to supercomputers is using SSH, like with the ssh command in a Unix shell on your computer (see this reference page). However, OSC has pioneered the use of a web portal called OnDemand, which has since become more widely used among supercomputer centers.\nThe OSC OnDemand website, https://ondemand.osc.edu, then, allows you to access OSC resources through a web browser. When you go there, you first need to log in with your OSC (not OSU!) credentials. After that, you should see a landing page similar to the one below:\n\n\n\nThe main part of the page (below the logo) only contains some general OSC messages and updates — what we will focus on instead are some of the options in the blue bar along the top.\n\n\n3.1 File System Access\nLet’s start with Files. Hovering over this dropdown menu gives a list of directories you have access to. If you’re account is new, you might only have three: a Home directory, and a Project and Scratch directory for one OSC Project.\nFor every project you’re associated with, directories are added — I’m associated with quite a few different projects, so I have a long list under Files. I’ll select the Project directory for the MCIC’s main OSC Project, PAS0471, which is /fs/ess/PAS0471:\n\n\n\nOnce there, I can see a list of directories and files inside this Project directory, and I can click on the directories to explore the contents further.\n\n\n\nThis interface is much like the file browser on your own computer, so you can also create, delete, move and copy files and folders: see the buttons across the top.\nAdditionally, there are Upload and Download buttons for uploading files from your computer to OSC, and downloading them from OSC to your computer. These are only suitable for relatively small transfers, say below 1 GB. Other options to transfer files to and from OSC are remote transfer commands like scp (also for smaller transfers), and SFTP or Globus for larger transfers. To learn more about these options, see the reference page on OSC file transfer.\n\n\n\n3.2 System Status (in Clusters)\nWe will skip the “Jobs” dropdown menu in the blue top bar, because in later sessions, we will learn to create, submit, and monitor compute jobs at the command line instead.\nMoving on to “Clusters”, we’ll start with the item at the bottom of that dropdown menu, “System Status”:\n\n\n\nThis page shows an overview of the current usage of the two clusters, which might help to decide which cluster you want to use and set some expectations for compute job waiting times:\n\n\n\n\n\n\n3.3 Unix Shell Access (in Clusters)\nInteracting with a supercomputer in a point-and-click manner only goes so far. Using a supercomputer effectively requires interacting with the system using a command-line (CLI) rather than a graphical user (GUI) interface.\nAgain under the Clusters option in the blue top bar, you can access a Unix shell either on Owens or Pitzer:\n\n\n\nI’m selecting a Unix shell on the Pitzer supercomputer, which will open a new browser tab looking like this:\n\n\n\nWe most commonly interact with a supercomputer using a Unix shell, and we’ll learn about the basics of the Unix shell in an upcoming session. However, we’ll mostly be accessing a Unix shell in a different way, namely inside the VS Code text editor, which also gives us some additional functionality in a user-friendly way.\n\n\n3.4 Interactive Apps\nWe can get access to VS Code, as well as many other programs with GUIs such as RStudio, via the Interactive Apps dropdown menu (and the menu item next to that, My Interactive Sessions, will list the sessions that are currently active as well as finished ones).\n\n\n\n\n\n\n\n\n\n‘VS Code’ versus ‘Code Server’\n\n\n\nIn the list, the “VS Code” program is called “Code Server”, much like “RStudio” is called “RStudio Server”. They are the same programs but with minor edits to allow them to run remotely rather than on your own computer.\n\n\n“Interactive Apps” like VS Code and RStudio run on compute nodes — therefore, we need to fill out a form and specify some details for our interactive compute job request:\n\nThe OSC Project that should be billed for the compute resource usage — a dropdown menu will list all Projects you are a member of.\nThe amount of time we want to make a reservation for — we’ll be kicked off as soon as that amount of time has passed!\nThe “working directory” (starting location in the file system) for the program, which we can type in the box or select with the “Select Path” button (the default is your Home directory, here referred to as $HOME).\nThe software version — the most recent available one should be automatically selected, and that is almost always what you’ll want.\n\n\n\n\nClick on Launch at the bottom and this will send your request to the compute job scheduler. First, your job will be “Queued” — that is, waiting for the job scheduler to allocate resources on the compute nodes to it:\n\n\n\nIn general, it should be granted resources within a few seconds (the card will then say “Starting”), and be ready for usage (“Running”) in another couple of seconds:\n\n\n\nThen, you can click on the blue Connect to VS Code button to open a new browser tab that runs VS Code. We’ll explore VS Code in the next session."
  },
  {
    "objectID": "modules/02_osc.html#at-home-reading",
    "href": "modules/02_osc.html#at-home-reading",
    "title": "Intro to the Ohio Supercomputer Center (OSC)",
    "section": "5 At Home Reading",
    "text": "5 At Home Reading"
  },
  {
    "objectID": "modules/02_osc.html#at-ome-reading",
    "href": "modules/02_osc.html#at-ome-reading",
    "title": "Intro to the Ohio Supercomputer Center (OSC)",
    "section": "5 At ome reading",
    "text": "5 At ome reading\n\n5.1 Transferring files to and from OSC\n\nUsing OSC OnDemand (as seen above)\nUsing scp (or similar, more advanced commands like rsync and rclone)\nUsing Globus\nNote that if you need files that are at a publicly accessible location on the internet (for example, NCBI reference genome data), you don’t need to download these to your computer and then upload them to OSC. Instead, you can use commands for downloading files, usually wget or curl. We’ll get to that later on.\n\n\n\n5.2 Connecting through SSH\nTo connect to OSC or other remote computers without using a webportal like OnDemand, you can use SSH. You can do so via the ssh command if you have a Linux or, more likely, a Mac computer, since these two operating systems are both Unix-based and have built-in terminals with Unix shells. If you have a Windows computer, you can instead use a GUI-based SSH client like PuTTY. Alternatively, for an experience more similar to that if you did have a Unix-based operating system, you can install Windows Subsystem for Linux (WSL) or Git Bash — these will allow you to open a terminal program that does run a Unix shell.\nHere, I’ll briefly show how to use the ssh command. Open your terminal, and input the command ssh &lt;username&gt;@&lt;hostname&gt;, where: - &lt;username&gt; should be replaced by your OSC username, and - &lt;hostname&gt; should be replaced by the name of the computer you want to connect to: - pitzer.osc.edu to connect to the Pitzer cluster - owens.osc.edu to connect to the Owens cluster\nFor example, if I (username jelmer) wanted to log in to the Pitzer cluster, I would use:\nssh jelmer@pitzer.osc.edu\nIf you’ve never connected to this particular server before, you’ll encounter a message similar to this:\nThe authenticity of host 'pitzer.osc.edu' can't be established.\nRSA key fingerprint is 2a:b6:f6:8d:9d:c2:f8:2b:8c:c5:03:06:a0:f8:59:12.\nAre you sure you want to continue connecting (yes/no)?\nThis is your computer warning you that you’re about to connect to a computer you haven’t connected to before: type yes to proceed. This will add the HPC to your “known hosts”, and you shouldn’t see the message again in the future.\nWarning: Permanently added 'pitzer.osc.edu' (RSA) to the list of known hosts.\nYou should now be prompted for your password. Type it in carefully (no characters will appear on the screen), then press Enter.\nusername@pitzer.osc.edu's password:\nIf you entered your password appropriately, congratulations, you’re now connected to the HPC! You’ll have shell access very much in the same way as when using the Pitzer Shell Access button on OSC OnDemand. The key difference is that the terminal doesn’t run inside your browser, which can be nice."
  },
  {
    "objectID": "modules/02_osc.html#at-home-rrading",
    "href": "modules/02_osc.html#at-home-rrading",
    "title": "Intro to the Ohio Supercomputer Center (OSC)",
    "section": "5 At Home rRading",
    "text": "5 At Home rRading\n\n5.1 Transferring files to and from OSC\n\nUsing OSC OnDemand (as seen above)\nUsing scp (or similar, more advanced commands like rsync and rclone)\nUsing Globus\nNote that if you need files that are at a publicly accessible location on the internet (for example, NCBI reference genome data), you don’t need to download these to your computer and then upload them to OSC. Instead, you can use commands for downloading files, usually wget or curl. We’ll get to that later on.\n\n\n\n5.2 Connecting through SSH\nTo connect to OSC or other remote computers without using a webportal like OnDemand, you can use SSH. You can do so via the ssh command if you have a Linux or, more likely, a Mac computer, since these two operating systems are both Unix-based and have built-in terminals with Unix shells. If you have a Windows computer, you can instead use a GUI-based SSH client like PuTTY. Alternatively, for an experience more similar to that if you did have a Unix-based operating system, you can install Windows Subsystem for Linux (WSL) or Git Bash — these will allow you to open a terminal program that does run a Unix shell.\nHere, I’ll briefly show how to use the ssh command. Open your terminal, and input the command ssh &lt;username&gt;@&lt;hostname&gt;, where: - &lt;username&gt; should be replaced by your OSC username, and - &lt;hostname&gt; should be replaced by the name of the computer you want to connect to: - pitzer.osc.edu to connect to the Pitzer cluster - owens.osc.edu to connect to the Owens cluster\nFor example, if I (username jelmer) wanted to log in to the Pitzer cluster, I would use:\nssh jelmer@pitzer.osc.edu\nIf you’ve never connected to this particular server before, you’ll encounter a message similar to this:\nThe authenticity of host 'pitzer.osc.edu' can't be established.\nRSA key fingerprint is 2a:b6:f6:8d:9d:c2:f8:2b:8c:c5:03:06:a0:f8:59:12.\nAre you sure you want to continue connecting (yes/no)?\nThis is your computer warning you that you’re about to connect to a computer you haven’t connected to before: type yes to proceed. This will add the HPC to your “known hosts”, and you shouldn’t see the message again in the future.\nWarning: Permanently added 'pitzer.osc.edu' (RSA) to the list of known hosts.\nYou should now be prompted for your password. Type it in carefully (no characters will appear on the screen), then press Enter.\nusername@pitzer.osc.edu's password:\nIf you entered your password appropriately, congratulations, you’re now connected to the HPC! You’ll have shell access very much in the same way as when using the Pitzer Shell Access button on OSC OnDemand. The key difference is that the terminal doesn’t run inside your browser, which can be nice."
  },
  {
    "objectID": "info/glossary.html",
    "href": "info/glossary.html",
    "title": "Glossary / Abbreviations",
    "section": "",
    "text": "Under construction\n\n\n\nThis page is still under construction."
  },
  {
    "objectID": "info/glossary.html#computing",
    "href": "info/glossary.html#computing",
    "title": "Glossary / Abbreviations",
    "section": "Computing",
    "text": "Computing\n\nOSC\nHPC\nCPU\nGPU\nCLI\nGUI\nShell\nUnix\nLinux"
  },
  {
    "objectID": "info/glossary.html#genomics",
    "href": "info/glossary.html#genomics",
    "title": "Glossary / Abbreviations",
    "section": "Genomics",
    "text": "Genomics\n\nFASTA\nFASTQ\nBAM/SAM\nGFF"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "RNAseq data analysis using the command line and R",
    "section": "",
    "text": "Sessions\n\n\n\nSession nr\nDate\nTopic & link\nPart\n\n\n\n\n1\n2023-07-14\nIntroduction\n1. Computing Skills\n\n\n2\n2023-07-21\nThe Ohio Supercomputer Center (OSC)\n1. Computing Skills\n\n\n3\n2023-07-28\nVS Code & Unix shell\n1. Computing Skills\n\n\n4\n2023-08-04\nUnix shell (cont.)\n1. Computing Skills\n\n\n5\n2023-08-11\nShell scripts\n1. Computing Skills\n\n\n6\n2023-08-18\nShell scripts (cont.)\n1. Computing Skills\n\n\n7\n2023-08-25\nSoftware at OSC\n1. Computing Skills\n\n\n8\n2023-09-01\nSlurm jobs\n1. Computing Skills"
  },
  {
    "objectID": "modules/01_intro.html#rnaseq-data-analysis",
    "href": "modules/01_intro.html#rnaseq-data-analysis",
    "title": "RNAseq data analysis: introduction",
    "section": "RNAseq data analysis",
    "text": "RNAseq data analysis\nRNAseq data analysis can be divided into two main parts:\n\nA bioinformatics-heavy part in which you generate gene counts from the raw reads.\nA more statistical part in which you analyze the count table to create lists of differentially expressed genes and enriched functional categories.\n\n\n\nPart I: From reads to count table\nThis part starts with the raw reads from the (typically Illumina) sequencing machine to eventually generate a table with expression counts for each gene by each sample. This part:\n\nIs usually done by sequentially running a series of programs with a command-line interface (CLI). Therefore, you typically use the Unix shell (command line) and shell scripts to do this.\nProcesses large amounts of data, and is generally not suitable to be run on a laptop or a desktop computer: you should use a high-performance computing (HPC) center or cloud computing. (We will use the Ohio Supercomputer Center, OSC.)\nIs quite standardized and therefore, a “pipeline” written for one dataset can be run for another one with minor changes, even if the datasets are from completely different experiments or different species.\n\n\n\n\n\n\n\n\nNote\n\n\n\nBecause of the required technical skills and computing infrastructure, in combination with the standardized execution, there are some alternatives available to doing this by yourself step-by-step1:\n\nCompanies and university bioinformatics core facilities may be able to simply run this part for you.\nServices with graphical user interfaces (GUIs) are available, such as Galaxy.\nThese run the same command-line programs, but wrap their execution in a more user-friendly way.\n\nSuch options are especially worth considering when you have no plans or ambitions to do much other genomics work in the future – in other words, it may not be worth learning all the required technical skills just for one project.\nWhen you plan to do multiple genomics projects and/or are generally interested in gaining computing skills, it’s better to go ahead and learn to run these command-line programs yourself.\n\n\n\n\n\nPart II: Analyzing the count table\nIn this part, you will analyze the table with gene counts for each sample, for example to test for differential expression among groups (e.g., different treatments) and to test whether certain functional (GO, KEGG) gene categories have distinct expression patterns as a whole.\nThis part:\n\nIs typically run entirely in R, using a number of specialized R “packages”.\nIs not particularly “compute-intensive”: your count table is a text file of typically only a few Mb, and the analyses you’re running do not need much time or computer memory. As such, you can run this on your laptop or desktop computer. (Though we will do it at OSC, mainly for the sake of continuity.)\nIs much less standardized across projects: the details of the analysis depend a lot on your experimental design and what you’re interested in; in addition, initial results may influence your next steps, and so on."
  },
  {
    "objectID": "modules/01_intro.html#what-well-cover",
    "href": "modules/01_intro.html#what-well-cover",
    "title": "RNAseq data analysis: introduction",
    "section": "What we’ll cover",
    "text": "What we’ll cover\n\nComputing skills\nMany of these computing skills are needed only for part I below.\n\nIntroduction to the Ohio Supercomputer Center (OSC)\nThe VS Code (Code Server) text editor / IDE\nIntroduction to the Unix shell (“command line” / “Bash”)\nShell scripts and loops\nThe SLURM compute job scheduler\nUsing and installing software at OSC\n\n\n\n\n\n\n\nNote\n\n\n\n\nAlong the way, we’ll also learn about project organization and ensuring reproducibility.\nI won’t include a full-blown introduction to R, but will provide some learning resources for those of you with little R experience before we get to the relevant part of the RNAseq analysis.\n\n\n\n\n\nAnalysis part I: From sequence reads to gene counts\n\nGenomic file formats relevant to RNAseq: FASTA, FASTQ, BAM/SAM, GFF\n\nRaw read QC with FastQC and MultiQC\nRead pre-processing with TrimGalore and SortMeRNA\nRead alignment to a reference genome with STAR\nAlignment QC with (at least) MultiQC\nGene expression counting with Salmon\n\n\n\nAnalysis part II: Analyzing gene counts in R\n\nGetting an overview of sample/group distinctiveness with a PCA\nDifferential expression analysis with {DESeq2}\nKEGG and GO enrichment analysis with {ClusterProfiler}"
  },
  {
    "objectID": "modules/01_intro.html#workflow-overview",
    "href": "modules/01_intro.html#workflow-overview",
    "title": "RNAseq data analysis: introduction",
    "section": "Workflow overview",
    "text": "Workflow overview"
  },
  {
    "objectID": "modules/01_intro.html#data-source-and-workflow-variations",
    "href": "modules/01_intro.html#data-source-and-workflow-variations",
    "title": "RNAseq data analysis: introduction",
    "section": "Data source and workflow variations",
    "text": "Data source and workflow variations\n\nReference-based versus de novo workflows\nWe will cover a “reference-based” RNAseq workflow: one where your focal organism has a reference genome assembly and annotation. “De novo” RNAseq workflows are necessary when you don’t have a reference genome. They are overall similar, but more time-consuming and bioinformatics-heavy, since you will first have to assemble a transcriptome from the RNAseq data itself.\n\n\nGene-level versus transcript-level counts, and short versus long reads\nWe will focus on generating and analyzing gene-level counts rather than transcript-level counts: that is, for each sample, we will obtain a single count for each gene even if that gene has multiple transcripts (isoforms). However, the program which we’ll use for counting (Salmon) can also generate transcript-level counts, and downstream transcript-level analysis is fairly similar too, though this certainly adds a level of complexity.\nAdditionally, we will use short-read (Illumina) sequencing data, for which transcript-level counts have much greater levels of uncertainty, since most reads cannot directly be assigned to a specific transcript. Consider using long reads, such as PacBio IsoSeq, if you’re interested in transcript-level inferences.\n\n\n“Bulk” versus single-cell RNAseq\nWe will focus on “bulk” RNAseq, where RNA was extracted from a large mixture of cells and possibly cell types. Single-cell RNAseq analysis is similar for the first part (generating counts), but differs more in the second part (count analysis)."
  },
  {
    "objectID": "modules/01_intro.html#footnotes",
    "href": "modules/01_intro.html#footnotes",
    "title": "RNAseq data analysis: introduction",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAdditionally, you can run standardized pipelines yourself, which wrap many individual steps into a single executable workflow. This especially becomes a time-efficient option once you know the computing basics, and also aids with reproducibility and following best-practices. For example, for RNAseq there is a Nextflow nf-core RNAseq pipeline. The steps we will run fill follow this pipeline closely – but in my opinion, for initial learning, it is better to go step-by-step without a formalized pipeline.↩︎"
  },
  {
    "objectID": "info/resources.html",
    "href": "info/resources.html",
    "title": "Further Resources",
    "section": "",
    "text": "Under construction\n\n\n\nThis page is still under construction."
  },
  {
    "objectID": "info/resources.html#unix-shell",
    "href": "info/resources.html#unix-shell",
    "title": "Further Resources",
    "section": "",
    "text": "OSC’s UNIX Basics"
  },
  {
    "objectID": "info/resources.html#general-covering-multiple-topics",
    "href": "info/resources.html#general-covering-multiple-topics",
    "title": "Further Resources",
    "section": "",
    "text": "Buffalo Book\nPractical Computing for Biologists books"
  },
  {
    "objectID": "info/about.html",
    "href": "info/about.html",
    "title": "About",
    "section": "",
    "text": "This website contains the material for a series of teaching sessions for grad students and postdocs of the Cruz-Monserrate lab in the fall of 2023.\nThese sessions focus on hands-on analysis of (short-read, bulk) RNAseq data with command-line tools and R using the computing resources at the Ohio Supercomputer Center (OSC).\nThis website and the teaching materials have been created by Jelmer Poelstra at the Molecular and Cellular Imaging Center (MCIC) of Ohio State University."
  },
  {
    "objectID": "info/resources.html#transcript-level-analysis",
    "href": "info/resources.html#transcript-level-analysis",
    "title": "Further Resources",
    "section": "",
    "text": "TBA"
  },
  {
    "objectID": "info/resources.html#rnaseqtranscript-level-analysis",
    "href": "info/resources.html#rnaseqtranscript-level-analysis",
    "title": "Further Resources",
    "section": "",
    "text": "TBA"
  },
  {
    "objectID": "info/resources.html#rnaseq-btranscript-level-analysis",
    "href": "info/resources.html#rnaseq-btranscript-level-analysis",
    "title": "Further Resources",
    "section": "",
    "text": "TBA"
  },
  {
    "objectID": "info/resources.html#rnaseq-analysis",
    "href": "info/resources.html#rnaseq-analysis",
    "title": "Further Resources",
    "section": "RNAseq analysis",
    "text": "RNAseq analysis\n\nTranscript-level analysis\nTBA"
  },
  {
    "objectID": "info/resources.html#general-bioinformatics",
    "href": "info/resources.html#general-bioinformatics",
    "title": "Further Resources",
    "section": "",
    "text": "Buffalo Book\nPractical Computing for Biologists books"
  },
  {
    "objectID": "info/resources.html#general-applied-bioinformatics",
    "href": "info/resources.html#general-applied-bioinformatics",
    "title": "Further Resources",
    "section": "",
    "text": "Buffalo Book\nPractical Computing for Biologists books"
  },
  {
    "objectID": "info/resources.html#general-applied-bioinformatics-resources",
    "href": "info/resources.html#general-applied-bioinformatics-resources",
    "title": "Further Resources",
    "section": "General applied bioinformatics resources",
    "text": "General applied bioinformatics resources\n\nBuffalo Book\nPractical Computing for Biologists books"
  },
  {
    "objectID": "info/osc_ssh.html",
    "href": "info/osc_ssh.html",
    "title": "Connecting to OSC through SSH",
    "section": "",
    "text": "This page will first go through the basics of connecting to OSC with SSH, using the ssh command.\nIf you use ssh frequently, or plan to do so, the next two sections will show you two shortcuts:\nFinally, something more specific but incredibly useful if you like VS Code, and have it installed locally, is to SSH-tunnel VS Code to OSC*."
  },
  {
    "objectID": "info/osc_transfer.html",
    "href": "info/osc_transfer.html",
    "title": "Transferring files to and from OSC",
    "section": "",
    "text": "Under construction\n\n\n\nThis page is still under construction.\nThere are several ways of transferring files between your computer and OSC:\nI’ll cover each of those in more detail below."
  },
  {
    "objectID": "info/osc_ssh.html#ba",
    "href": "info/osc_ssh.html#ba",
    "title": "Connecting to OSC through SSH",
    "section": "",
    "text": "To connect to OSC or other remote computers without using a webportal like OnDemand, you can use SSH. You can do so via the ssh command if you have a Linux or, more likely, a Mac computer, since these two operating systems are both Unix-based and have built-in terminals with Unix shells.\n\n\n\n\n\n\nSSH on Windows\n\n\n\nIf you have a Windows computer, you can instead use a GUI-based SSH client like PuTTY. Alternatively, for an experience more similar to that if you did have a Unix-based operating system, you can install Windows Subsystem for Linux (WSL) or Git Bash — these will allow you to open a terminal program that does run a Unix shell.\n\n\nHere, I’ll briefly demonstrate how to use the ssh command — again, you’ll need a Unix shell to do so.\nOpen a terminal application on your own computer, and input the command ssh &lt;username&gt;@&lt;hostname&gt;, where:\n\n&lt;username&gt; should be replaced by your OSC username, and\n&lt;hostname&gt; should be replaced by the name of the computer you want to connect to:\n\npitzer.osc.edu to connect to the Pitzer cluster\nowens.osc.edu to connect to the Owens cluster\n\n\nFor example, if I (username jelmer) wanted to log in to the Pitzer cluster, I would use:\nssh jelmer@pitzer.osc.edu\nIf you’ve never connected to this particular server before, you’ll encounter a message similar to this:\nThe authenticity of host 'pitzer.osc.edu' can't be established.\nRSA key fingerprint is 2a:b6:f6:8d:9d:c2:f8:2b:8c:c5:03:06:a0:f8:59:12.\nAre you sure you want to continue connecting (yes/no)?\nThis is your computer warning you that you’re about to connect to a computer you haven’t connected to before: type yes to proceed. This will add the HPC to your “known hosts”, and you shouldn’t see the message again in the future.\nWarning: Permanently added 'pitzer.osc.edu' (RSA) to the list of known hosts.\nYou should now be prompted for your password. Type it in carefully (no characters will appear on the screen), then press Enter.\njelmer@pitzer.osc.edu's password:\nIf you entered your password correctly, your shell is now connected to OSC rather than operating on your own computer. That is, you’ll have shell access very much in the same way as when using the “Pitzer Shell Access” button on OSC OnDemand. The key difference is that the terminal doesn’t run inside your browser, which can be convenient."
  },
  {
    "objectID": "info/osc_ssh.html#basic-ssh-connection",
    "href": "info/osc_ssh.html#basic-ssh-connection",
    "title": "Connecting to OSC through SSH",
    "section": "",
    "text": "To connect to OSC or other remote computers without using a webportal like OnDemand, you can use SSH. You can do so via the ssh command if you have a Linux or, more likely, a Mac computer, since these two operating systems are both Unix-based and have built-in terminals with Unix shells.\n\n\n\n\n\n\nSSH on Windows\n\n\n\nIf you have a Windows computer, you can instead use a GUI-based SSH client like PuTTY. Alternatively, for an experience more similar to that if you did have a Unix-based operating system, you can install Windows Subsystem for Linux (WSL) or Git Bash — these will allow you to open a terminal program that does run a Unix shell.\n\n\nHere, I’ll briefly demonstrate how to use the ssh command — again, you’ll need a Unix shell to do so.\nOpen a terminal application on your own computer, and input the command ssh &lt;username&gt;@&lt;hostname&gt;, where:\n\n&lt;username&gt; should be replaced by your OSC username, and\n&lt;hostname&gt; should be replaced by the name of the computer you want to connect to:\n\npitzer.osc.edu to connect to the Pitzer cluster\nowens.osc.edu to connect to the Owens cluster\n\n\nFor example, if I (username jelmer) wanted to log in to the Pitzer cluster, I would use:\nssh jelmer@pitzer.osc.edu\nIf you’ve never connected to this particular server before, you’ll encounter a message similar to this:\nThe authenticity of host 'pitzer.osc.edu' can't be established.\nRSA key fingerprint is 2a:b6:f6:8d:9d:c2:f8:2b:8c:c5:03:06:a0:f8:59:12.\nAre you sure you want to continue connecting (yes/no)?\nThis is your computer warning you that you’re about to connect to a computer you haven’t connected to before: type yes to proceed. This will add the HPC to your “known hosts”, and you shouldn’t see the message again in the future.\nWarning: Permanently added 'pitzer.osc.edu' (RSA) to the list of known hosts.\nYou should now be prompted for your password. Type it in carefully (no characters will appear on the screen), then press Enter.\njelmer@pitzer.osc.edu's password:\nIf you entered your password correctly, your shell is now connected to OSC rather than operating on your own computer. That is, you’ll have shell access very much in the same way as when using the “Pitzer Shell Access” button on OSC OnDemand. The key difference is that the terminal doesn’t run inside your browser, which can be convenient."
  },
  {
    "objectID": "info/osc_ssh.html#basic-ssh-connection-wu",
    "href": "info/osc_ssh.html#basic-ssh-connection-wu",
    "title": "Connecting to OSC through SSH",
    "section": "",
    "text": "To connect to OSC or other remote computers without using a webportal like OnDemand, you can use SSH. You can do so via the ssh command if you have a Linux or, more likely, a Mac computer, since these two operating systems are both Unix-based and have built-in terminals with Unix shells.\n\n\n\n\n\n\nSSH on Windows\n\n\n\nIf you have a Windows computer, you can instead use a GUI-based SSH client like PuTTY. Alternatively, for an experience more similar to that if you did have a Unix-based operating system, you can install Windows Subsystem for Linux (WSL) or Git Bash — these will allow you to open a terminal program that does run a Unix shell.\n\n\nHere, I’ll briefly demonstrate how to use the ssh command — again, you’ll need a Unix shell to do so.\nOpen a terminal application on your own computer, and input the command ssh &lt;username&gt;@&lt;hostname&gt;, where:\n\n&lt;username&gt; should be replaced by your OSC username, and\n&lt;hostname&gt; should be replaced by the name of the computer you want to connect to:\n\npitzer.osc.edu to connect to the Pitzer cluster\nowens.osc.edu to connect to the Owens cluster\n\n\nFor example, if I (username jelmer) wanted to log in to the Pitzer cluster, I would use:\nssh jelmer@pitzer.osc.edu\nIf you’ve never connected to this particular server before, you’ll encounter a message similar to this:\nThe authenticity of host 'pitzer.osc.edu' can't be established.\nRSA key fingerprint is 2a:b6:f6:8d:9d:c2:f8:2b:8c:c5:03:06:a0:f8:59:12.\nAre you sure you want to continue connecting (yes/no)?\nThis is your computer warning you that you’re about to connect to a computer you haven’t connected to before: type yes to proceed. This will add the HPC to your “known hosts”, and you shouldn’t see the message again in the future.\nWarning: Permanently added 'pitzer.osc.edu' (RSA) to the list of known hosts.\nYou should now be prompted for your password. Type it in carefully (no characters will appear on the screen), then press Enter.\njelmer@pitzer.osc.edu's password:\nIf you entered your password correctly, your shell is now connected to OSC rather than operating on your own computer. That is, you’ll have shell access very much in the same way as when using the “Pitzer Shell Access” button on OSC OnDemand. The key difference is that the terminal doesn’t run inside your browser, which can be convenient."
  },
  {
    "objectID": "info/osc_ssh.html#basic-ssh-connection-in-a-terminal",
    "href": "info/osc_ssh.html#basic-ssh-connection-in-a-terminal",
    "title": "Connecting to OSC through SSH",
    "section": "2 Basic SSH connection in a terminal",
    "text": "2 Basic SSH connection in a terminal\nTo connect to OSC or other remote computers without using a web portal like OnDemand, you can use SSH. You can do so via the ssh command if you have a Linux or a Mac computer, since these two operating systems are both Unix-based and have built-in terminals with Unix shells.\nHere, I’ll briefly demonstrate how to use the ssh command. On your own computer, open a terminal application and input the command ssh &lt;username&gt;@&lt;hostname&gt;, where:\n\n&lt;username&gt; should be replaced by your OSC username, and\n&lt;hostname&gt; should be replaced by the name of the computer you want to connect to:\n\npitzer.osc.edu to connect to the Pitzer cluster\nowens.osc.edu to connect to the Owens cluster\n\n\nFor example, if I (username jelmer) wanted to log in to the Pitzer cluster, I would use:\nssh jelmer@pitzer.osc.edu\nThe authenticity of host 'pitzer.osc.edu' can't be established.\nRSA key fingerprint is 2a:b6:f6:8d:9d:c2:f8:2b:8c:c5:03:06:a0:f8:59:12.\nAre you sure you want to continue connecting (yes/no)?\nIf this is the first time you are connecting to Pitzer via SSH, you’ll encounter a message similar to the one above. While the phrase “The authenticity of host ‘pitzer.osc.edu’ can’t be established.” sounds ominous, you will always get this warning when you attempt to connect to a remote computer for the first time, and you should type yes to proceed (you then won’t see this message again).\nYou should now be prompted for your password. Type it in carefully because no characters or even *s will appear on the screen, and then press Enter.\njelmer@pitzer.osc.edu's password:\nIf you entered your password correctly, your shell is now connected to OSC rather than operating on your own computer. That is, you’ll have shell access very much in the same way as when using the “Pitzer Shell Access” button on OSC OnDemand. (The key difference between SSH-ing in this way rather than using OnDemand is that the terminal is not running inside your browser, which can be convenient.)\n\n\n\n\n\n\nSSH shortcuts\n\n\n\nIf you use SSH a lot to connect to OSC, typing ssh &lt;username&gt;@pitzer.osc.edu every time and then providing your password can get pretty tedious. The next two sections will show you how to make this go faster."
  },
  {
    "objectID": "info/osc_transfer.html#remote-transfer-commands",
    "href": "info/osc_transfer.html#remote-transfer-commands",
    "title": "Transferring files to and from OSC",
    "section": "3 Remote transfer commands",
    "text": "3 Remote transfer commands\nFor small transfers, you can also use a remote transfer command like scp, or a more advanced one like rsync or rclone. Such commands can provide a more convenient transfer method than OnDemand if you want to keep certain directories synced between OSC and your computer.\n\n\n\n\n\n\nNote\n\n\n\nThe reason you shouldn’t use this for very large transfers is that the transfer will happen using a login node.\n\n\n\n3.1 scp\nOne option is scp (secure copy), which works much like the regular cp command, including that you’ll need -r for recursive transfers.\nThe key difference is that we have to somehow refer to a path on a remote computer, and we do so by starting with the remote computer’s address, followed by :, and then the path:\n# Copy from remote (OSC) to local (your computer):\nscp &lt;user&gt;@pitzer.osc.edu:&lt;remote-path&gt; &lt;local-path&gt;\n\n# Copy from local (your computer) to remote (OSC)\nscp &lt;local-path&gt; &lt;user&gt;@pitzer.osc.edu:&lt;remote-path&gt;\nSome nuances for remote copying:\n\nAs the above code implies, in both cases (remote-to-local and local-to-remote), you will issue the copying commands from your local computer.\nFor the remote computer (OSC), the path should always be absolute, whereas that for your local computer can be either relative or absolute.\nSince all files can be accessed at the same paths at Pitzer and at Owens, it doesn’t matter whether you use @pitzer.osc.edu or @owens.osc.edu in the scp command.\n\nHere are some actual examples:\n# Copy a file from OSC to a local computer - namely, to your current working dir ('.'):\nscp jelmer@pitzer.osc.edu:/fs/ess/PAS0471/jelmer/mcic-scripts/misc/fastqc.sh .\n\n# Copy a directory from OSC to a local computer - namely, to your home dir ('~'):\nscp -r jelmer@pitzer.osc.edu:/fs/ess/PAS0471/jelmer/mcic-scripts ~\n\n# Copy a file from your computer to OSC --\n# namely, a file in from your current working dir to your home dir at OSC:\nscp fastqc.sh jelmer@pitzer.osc.edu:~\n\n# Copy a file from my local computer's Desktop to the Scratch dir for PAS0471:\nscp /Users/poelstra.1/Desktop/fastqc.sh jelmer@pitzer.osc.edu:/fs/scratch/PAS0471\n\n\n\n\n\n\nTransferring directly to and from OneDrive\n\n\n\nIf your OneDrive is mounted on or synced to your local computer (i.e., if you can see it in your computer’s file brower), you can also transfer directly between OSC and OneDrive.\nFor example, the path to my OneDrive files on my laptop is:\n/Users/poelstra.1/Library/CloudStorage/OneDrive-TheOhioStateUniversity.\nSo if I had a file called fastqc.sh in my top-level OneDrive dir, I could transfer it to my Home dir at OSC as follows:\nscp /Users/poelstra.1/Library/CloudStorage/OneDrive-TheOhioStateUniversity jelmer@pitzer.osc.edu:~\n\n\n\n\n\n3.2 rsync\nAnother option, which I can recommend, is the rsync command, especially when you have directories that you repeatedly want to sync: rsync won’t copy any files that are identical in source and destination.\nA useful combination of options is -avz --progress:\n\n-a enables archival mode (among other things, this makes it work recursively).\n-v increases verbosity — tells you what is being copied.\n-z enables compressed file transfer (=&gt; generally faster).\n--progress to show transfer progress for individual files.\n\nThe way to refer to remote paths is the same as with scp. For example, I could copy a dir_with_results in my local Home dir to my OSC Home dir as follows:\nrsync -avz --progress ~/dir_with_results jelmer@owens.osc.edu:~\nOne tricky aspect of using rsync is that the presence/absence of a trailing slash for source directories makes a difference for its behavior. The following commands work as intended — to create a backup copy of a scripts dir inside a dir called backup2:\n# With trailing slash: copy the *contents* of source \"scripts\" into target \"scripts\":\nrsync -avz scripts/ backup/scripts\n\n# Without trailing slash: copy the source dir \"scripts\" into target dir \"backup\"\nrsync -avz scripts backup\nBut these commands don’t:\n# This would result in a dir 'backup/scripts/scripts':\nrsync -avz scripts backup/scripts\n\n# This would copy the files in \"scripts\" straight into \"backup\":\nrsync -avz scripts/ backup"
  },
  {
    "objectID": "info/osc_transfer.html#ondemand",
    "href": "info/osc_transfer.html#ondemand",
    "title": "Transferring files to and from OSC",
    "section": "1 OnDemand",
    "text": "1 OnDemand\nFor small transfers (below roughly 1 GB), you might find it easiest to use the Upload and Download buttons in the OSC OnDemand “Files” menu."
  },
  {
    "objectID": "info/osc_transfer.html#osc-ondemand",
    "href": "info/osc_transfer.html#osc-ondemand",
    "title": "Transferring files to and from OSC",
    "section": "1 OSC OnDemand",
    "text": "1 OSC OnDemand\nFor small transfers (below roughly 1 GB), you might find it easiest to use the Upload and Download buttons in the OSC OnDemand “Files” menu."
  },
  {
    "objectID": "info/osc_transfer.html#sftp",
    "href": "info/osc_transfer.html#sftp",
    "title": "Transferring files to and from OSC",
    "section": "4 SFTP",
    "text": "4 SFTP\nThe first of two options for larger transfers is SFTP. You can use the sftp command when you have access to a Unix shell on your computer, and this what I’ll cover below.\n\n\n\n\n\n\nSFTP with a GUI\n\n\n\nIf you have Windows without e.g. WSL or Git Bash (see the top of the SSH page on this site for more details), you can use a GUI-based SFTP client instead like WinSCP, Cyberduck, or FileZilla. CyberDuck also works on Mac, and FileZilla works on all operating systems, if you prefer to do SFTP transfers with a GUI, but I won’t cover their usage here.\n\n\n\n4.1 Logging in\nTo log in to OSC’s SFTP server, issue the following command in your local computer’s terminal, substituting &lt;user&gt; by your OSC username:\nsftp &lt;user&gt;@sftp.osc.edu   # E.g., 'jelmer@sftp.osc.edu'\nThe authenticity of host 'sftp.osc.edu (192.148.247.136)' can't be established.\nED25519 key fingerprint is SHA256:kMeb1PVZ1XVDEe2QiSumbM33w0SkvBJ4xeD18a/L0eQ.\nThis key is not known by any other names\nAre you sure you want to continue connecting (yes/no/[fingerprint])?\nIf this is your first time connecting to OSC SFTP server, you’ll get a message like the one shown above: you should type yes to confirm.\nThen, you may be asked for your OSC password, and after that, you should see a “welcome” message like this:\n******************************************************************************\n\nThis system is for the use of authorized users only.  Individuals using\nthis computer system without authority, or in excess of their authority,\nare subject to having all of their activities on this system monitored\nand recorded by system personnel.  In the course of monitoring individuals\nimproperly using this system, or in the course of system maintenance,\nthe activities of authorized users may also be monitored.  Anyone using\nthis system expressly consents to such monitoring and is advised that if\nsuch monitoring reveals possible evidence of criminal activity, system\npersonnel may provide the evidence of such monitoring to law enforcement\nofficials.\n\n******************************************************************************\nConnected to sftp.osc.edu.\nNow, you will have an sftp prompt (sftp&gt;) instead of a regular shell prompt.\nFamiliar commands like ls, cd, and pwd will operate on the remote computer (OSC, in this case), and there are local counterparts for them: lls, lcd, lpwd — for example:\nsftp&gt; pwd\nRemote working directory: /users/PAS0471/jelmer\nsftp&gt; lpwd\nLocal working directory: /Users/poelstra.1/Desktop\n\n\n4.2 Uploading files to OSC\nTo upload files to OSC, use the put command. The syntax is put &lt;local-path&gt; &lt;remote-path&gt;, and unlike with scp etc., you don’t need to designate the remote with its address and :. Like with cp and scp, you’ll need the -r flag for recursive transfers, i.e. transferring a directory and its contents.\n# Upload fastqc.sh in a dir 'scripts' on your local computer to the PAS0471 Scratch dir:\nsftp&gt; put scripts/fastqc.sh /fs/scratch/PAS0471/sandbox\n\n# Use -r to transfer directories:\nsftp&gt; put -r scripts /fs/scratch/PAS0471/sandbox\n\n# You can use wildcards to upload multiple files:\nsftp&gt; put scripts/*sh /fs/scratch/PAS0471/sandbox\n\n\n\n\n\n\nsftp is primitive\n\n\n\nThe ~ shortcut to your Home directory does not work in sftp!\nsftp is generally quite primitive and you also cannot use, for example, tab completion or the recalling of previous commands with the up arrow.\n\n\n\n\n4.3 Downloading files from OSC\nTo download files from OSC, use the get command, which has the syntax get &lt;remote-path&gt; &lt;local-path&gt; (note: this is the other way around from put in that the remote path comes first, but the same in that both use the order &lt;source&gt; &lt;target&gt;).\nFor example:\nsftp&gt; get /fs/scratch/PAS0471/mcic-scripts/misc/fastqc.sh .\n\nsftp&gt; get -r /fs/scratch/PAS0471/sandbox/ .\n\n\n4.4 Exiting\nWhen you’re done, you can type exit or press Ctrl+D to exit the sftp prompt."
  },
  {
    "objectID": "info/osc_transfer.html#globus",
    "href": "info/osc_transfer.html#globus",
    "title": "Transferring files to and from OSC",
    "section": "5 Globus",
    "text": "5 Globus\nThe second option for large transfers is Globus, which is especially your best bet for very large transfers. Globus has a browser-based GUI. Some advantages of using Globus are that:\n\nIt checks whether all files were transferred correctly and completely\nIt can pause and resume automatically when you e.g. turn off your computer\nIt can be used to share files from OSC directly with collaborators even at different institutions.\n\nGlobus does need some setup including the installation of a piece of software that will run in the background on your computer.\n\nGlobus installation and configuration instructions: Windows / Mac / Linux\nGlobus transfer instructions\nOSC’s page on Globus"
  },
  {
    "objectID": "info/osc_ssh.html#introduction",
    "href": "info/osc_ssh.html#introduction",
    "title": "Connecting to OSC through SSH",
    "section": "1 Introduction",
    "text": "1 Introduction\nThis page will first go through the basics of connecting to OSC with SSH, using the ssh command.\nIf you use ssh frequently, or plan to do so, the next two sections will show you two shortcuts:\n\nAvoid being prompted for your password\nSet up a shortcut for your SSH connection name.\n\nFinally, something more specific but incredibly useful if you like VS Code, and have it installed locally, is to SSH-tunnel VS Code to OSC*.\n\n\n\n\n\n\nSSH and Unix shells on Windows\n\n\n\n\n\nIf you have a Windows computer, you can instead use a GUI-based SSH client like PuTTY.\nAlternatively, for an experience more similar to that if you did have a Unix-based operating system, you can install either of the following, which will enable you to get a terminal program that does run a Unix shell:\n\nWindows Subsystem for Linux (WSL) — the more involved option, this will basically run a Linux Virtual Machine on your computer.\nGit for Windows, which comes with a Unix (Bash) shell. To install this, download it from the link above and install it using all the default settings for the installation, except:\n\nIn “Adjusting Your PATH Environment”, select “Use Git from Git Bash Only”.\nIn the prompt “Configuring the Line Ending Conversions”, choose “Checkout as-is, commit as-is”."
  },
  {
    "objectID": "info/osc_ssh.html#avoid-being-prompted-for-password",
    "href": "info/osc_ssh.html#avoid-being-prompted-for-password",
    "title": "Connecting to OSC through SSH",
    "section": "Avoid being prompted for password",
    "text": "Avoid being prompted for password\nThe regular way to do this is typing ssh &lt;username&gt;@pitzer.osc.edu and then providing your password, which can get tedious. There are two setup steps you can take to make this quicker:\n\nAvoid being prompted for your password.\nSet up a shortcut for your SSH connection name.\n\nA third thing you can do below, assuming you have VS Code installed locally, is to get it to SSH tunnel to OSC: this will be as if you have VS Code open in OnDemand, but then not in your browser!\nThese steps are similar to what you did for your SSH Github authentication.\n\nOn your own computer, generate a public-private SSH key-pair:\n\n$ ssh-keygen -t rsa\nWhen you’re prompted for a passphrase, you can just press enter if you are okay with not having a passphrase.\n\nIf you do want a passphrase, you have to take an extra step to not be prompted, after step 3 below:\n$ ssh-add\n# (Then here, don't enter a passphrase in any case!)\n\n\nFrom your own computer, transfer the public key to the remote computer:\n\n# Replace &lt;user&gt; by your username, e.g. \"jelmer@owens.osc.edu\"\n$ cat ~/.ssh/id_rsa.pub | ssh &lt;user&gt;@owens.osc.edu 'mkdir -p .ssh && cat &gt;&gt; .ssh/authorized_keys'\n\nLog in to the remote computer (OSC) and once there, set appropriate permissions:\n\n$ chmod 700 .ssh; chmod 640 .ssh/authorized_keys\n\nSee also this Tecmint post in case you’re struggling, and Buffalo Chapter 4 page 59-60."
  },
  {
    "objectID": "info/osc_ssh.html#use-a-shortcut-for-your-ssh-connection",
    "href": "info/osc_ssh.html#use-a-shortcut-for-your-ssh-connection",
    "title": "Connecting to OSC through SSH",
    "section": "Use a shortcut for your SSH connection",
    "text": "Use a shortcut for your SSH connection\nThese two steps should both be done on your local machine.\n\nCreate a file called ~/.ssh/config:\n\n$ touch ~/.ssh/config\n\nOpen the file in a text editor and add your alias(es) in the following format:\n\nHost &lt;arbitrary-alias-name&gt;    \n     HostName &lt;remote-name&gt;\n     User &lt;user-name&gt;\nFor instance, I have something along these lines for Pitzer and Owens:\nHost op\n    HostName pitzer.osc.edu\n    User jelmer\n\nHost oo\n    HostName owens.osc.edu\n    User jelmer\nNow, you just need to use your, preferably very short, alias to log in:\n$ ssh op\nThis shortcut will also work with scp and rsync!\n$ rsync ~/scripts op:/fs/ess/PAS1855/scripts"
  },
  {
    "objectID": "info/osc_ssh.html#set-up-your-local-vs-code-to-ssh-tunnel-into-osc",
    "href": "info/osc_ssh.html#set-up-your-local-vs-code-to-ssh-tunnel-into-osc",
    "title": "Connecting to OSC through SSH",
    "section": "5 Set up your local VS Code to SSH tunnel into OSC",
    "text": "5 Set up your local VS Code to SSH tunnel into OSC\nIf you want to use VS Code to write code, have a shell, and interact with files at OSC directly, you don’t necessarily need to use the VS Code Server in OSC OnDemand. You can also make your local VS Code installation “SSH tunnel” into OSC.\nThis is a more convenient way of working because it’s quicker to start, will never run out of alotted time, and because you are not working inside a browser, you have more screen space and no keyboard shortcut interferences.\nThe set-up is pretty simple (see also these instructions if you get stuck):\n\nIf necessary, install VS Code (instructions for Windows / Mac / Linux) on your computer, and open it.\nInstall the VS Code “Remote Development extension pack”: open the Extensions side bar (click the icon with the four squared in the far left), search for “Remote Development extension pack”, and click “Install”.\nOpen the Command Palette (F1 or Ctrl+ShiftP) and start typing “Remote SSH”.\nThen, select Remote-SSH: Connect to Host… and specify your SSH connection: e.g. ssh jelmer@pitzer.osc.edu (you’ll have to do this separately for Pitzer and Owens if you want to be able to connect to both).\nIf you did the no-password setup described above (recommended!), you shouldn’t be prompted for a password and VS Code will connect to OSC!\nIf you’re asked about the operating system of the host, select Linux, which is the operating system of the OSC clusters.\n\n\n\n\n\n\n\nWarning\n\n\n\nJust be aware that you’ll now be on a Login node (and not on a Compute node like when you use VS Code through OnDemand), so avoid running analyses directly in the terminal, and so on."
  },
  {
    "objectID": "info/osc_ssh.html#avoid-being-prompted-for-your-osc-password",
    "href": "info/osc_ssh.html#avoid-being-prompted-for-your-osc-password",
    "title": "Connecting to OSC through SSH",
    "section": "3 Avoid being prompted for your OSC password",
    "text": "3 Avoid being prompted for your OSC password\n\nOn your own computer, generate a public-private SSH key-pair:\nssh-keygen -t rsa\nYou’ll get some output and will then be asked several questions, but in each case, you can just press Enter to select the default answer.\nOn your own computer, transfer the public key to OSC’s clusters:\n# Replace &lt;user&gt; by your username, e.g. \"ssh-copy-id jelmer@owens.osc.edu\"\nssh-copy-id &lt;user&gt;@owens.osc.edu\nssh-copy-id &lt;user&gt;@pitzer.osc.edu\n\nTest if it works by runnning:\n# Try connecting to Owens (once again, replace '&lt;user&gt;' by your username):\nssh &lt;user&gt;@owens.osc.edu\n\n# Try connecting to Pitzer (once again, replace '&lt;user&gt;' by your username):\nssh &lt;user&gt;@owens.osc.edu\n\n\n\n\n\n\nNote\n\n\n\nSee also this Tecmint post in case you’re struggling."
  },
  {
    "objectID": "info/osc_ssh.html#use-a-shorter-name-for-your-ssh-connection",
    "href": "info/osc_ssh.html#use-a-shorter-name-for-your-ssh-connection",
    "title": "Connecting to OSC through SSH",
    "section": "4 Use a shorter name for your SSH connection",
    "text": "4 Use a shorter name for your SSH connection\nYou can easily set up alternative ways of referring to you SSH connection (i.e., “aliases”), such as shortening jelmer@pitzer.osc.edu to jp, by saving these aliases in a text file ~/.ssh/config, as shown below.\nThese two steps should both be done on your local machine:\n\nCreate a file called ~/.ssh/config:\ntouch ~/.ssh/config\nOpen the file in a text editor and add your alias(es) in the following format:\nHost &lt;arbitrary-alias-name&gt;    \n    HostName &lt;remote-address&gt;\n    User &lt;username&gt;\nFor instance, my file contains the following so as to connect to Pizer with jp and to Owens with jo:\nHost jp\n    HostName pitzer.osc.edu\n    User jelmer\n\nHost jo\n    HostName owens.osc.edu\n    User jelmer\n\n\nNow, you just need to use your, preferably very short, alias to log in — and if you did the previous no-password setup, you won’t even be prompted for your password!\nssh jp\nPerhaps even more conveniently, this shortcut will also work with scp and rsync! For example:\nrsync ~/scripts op:/fs/scratch/PAS0471"
  },
  {
    "objectID": "info/osc_transfer.html#footnotes",
    "href": "info/osc_transfer.html#footnotes",
    "title": "Transferring files to and from OSC",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nBut the initial setup for Globus is quite involved and a bit counterintuitive.↩︎\nFor simplicity, these commands are copying between local dirs, which is also possible with rsync.↩︎"
  },
  {
    "objectID": "info/osc_ssh.html#section",
    "href": "info/osc_ssh.html#section",
    "title": "Connecting to OSC through SSH",
    "section": "2 ",
    "text": "2"
  },
  {
    "objectID": "info/osc_ssh.html#connecting-to-s",
    "href": "info/osc_ssh.html#connecting-to-s",
    "title": "Connecting to OSC through SSH",
    "section": "2 Connecting to S",
    "text": "2 Connecting to S\nIf you use SSH a lot to connect to OSC, typing ssh &lt;username&gt;@pitzer.osc.edu every time and then providing your password can get pretty tedious. There are two one-time setup steps you can take to make this quicker:\n\nAvoid being prompted for your password.\nSet up a shortcut for your SSH connection name.\n\nA third thing you can do below, assuming you have VS Code installed locally, is to get it to SSH tunnel to OSC: this will be as if you have VS Code open in OnDemand, but then not in your browser!"
  },
  {
    "objectID": "info/osc_ssh.html#connecting-to",
    "href": "info/osc_ssh.html#connecting-to",
    "title": "Connecting to OSC through SSH",
    "section": "2 Connecting to",
    "text": "2 Connecting to\nIf you use SSH a lot to connect to OSC, typing ssh &lt;username&gt;@pitzer.osc.edu every time and then providing your password can get pretty tedious. There are two one-time setup steps you can take to make this quicker:\n\nAvoid being prompted for your password.\nSet up a shortcut for your SSH connection name.\n\nA third thing you can do below, assuming you have VS Code installed locally, is to get it to SSH tunnel to OSC: this will be as if you have VS Code open in OnDemand, but then not in your browser!"
  },
  {
    "objectID": "info/osc_ssh.html#making-it-easier-to-connect",
    "href": "info/osc_ssh.html#making-it-easier-to-connect",
    "title": "Connecting to OSC through SSH",
    "section": "2 Making it easier to connect",
    "text": "2 Making it easier to connect\nIf you use SSH a lot to connect to OSC, typing ssh &lt;username&gt;@pitzer.osc.edu every time and then providing your password can get pretty tedious. There are two one-time setup steps you can take to make this quicker:\n\nAvoid being prompted for your password.\nSet up a shortcut for your SSH connection name.\n\nA third thing you can do below, assuming you have VS Code installed locally, is to get it to SSH tunnel to OSC: this will be as if you have VS Code open in OnDemand, but then not in your browser!"
  },
  {
    "objectID": "info/osc_ssh.html#making-it-easier-to-connect-with-ssh-introduction",
    "href": "info/osc_ssh.html#making-it-easier-to-connect-with-ssh-introduction",
    "title": "Connecting to OSC through SSH",
    "section": "2 Making it easier to connect with SSH: introduction",
    "text": "2 Making it easier to connect with SSH: introduction"
  },
  {
    "objectID": "info/osc_ssh.html#introdction",
    "href": "info/osc_ssh.html#introdction",
    "title": "Connecting to OSC through SSH",
    "section": "1 Introdction",
    "text": "1 Introdction\nThis page will first go through the basics of connecting to OSC with SSH, using the ssh command.\nIf you use ssh frequently, or plan to do so, the next two sections will show you two shortcuts:\n\nAvoid being prompted for your password\nSet up a shortcut for your SSH connection name.\n\nFinally, something more specific but incredibly useful if you like VS Code, and have it installed locally, is to SSH-tunnel VS Code to OSC*.\n\n\n\n\n\n\nSSH on Windows\n\n\n\nIf you have a Windows computer, you can instead use a GUI-based SSH client like PuTTY. Alternatively, for an experience more similar to that if you did have a Unix-based operating system, you can install Windows Subsystem for Linux (WSL) or Git Bash — these will allow you to open a terminal program that does run a Unix shell.\n\n\nHints (click here)\n\nDownload Git for Windows from here and install it using all the default settings for the installation, except:\n\nIn “Adjusting Your PATH Environment”, select “Use Git from Git Bash Only”.\nIn the prompt “Configuring the Line Ending Conversions”, choose “Checkout as-is, commit as-is”."
  },
  {
    "objectID": "info/osc_transfer.html#ondemand-files-menu",
    "href": "info/osc_transfer.html#ondemand-files-menu",
    "title": "Transferring files to and from OSC",
    "section": "2 OnDemand Files menu",
    "text": "2 OnDemand Files menu\nFor small transfers (below roughly 1 GB), you might find it easiest to use the Upload and Download buttons in the OSC OnDemand “Files” menu — their usage should be pretty intuitive."
  },
  {
    "objectID": "info/osc_transfer.html#introduction",
    "href": "info/osc_transfer.html#introduction",
    "title": "Transferring files to and from OSC",
    "section": "1 Introduction",
    "text": "1 Introduction\nThere are several ways of transferring files between your computer and OSC:\n\n\n\n\n\n\n\n\n\n\nMethod\nTransfer size\nCLI or GUI\nEase of use\nFlexibility/options\n\n\n\n\nOnDemand Files menu\nsmaller (&lt;1GB)\nGUI\nEasy\nLimited\n\n\nRemote transfer commands\nsmaller (&lt;1GB)\nCLI\nModerate\nExtensive\n\n\nSFTP\nlarger (&gt;1GB)\nEither\nModerate\nLimited\n\n\nGlobus\nlarger (&gt;1GB)\nGUI\nModerate 1\nExtensive\n\n\n\nThis page will cover each of those in more detail below.\n\n\n\n\n\n\nDownload directly from the web using commands at OSC\n\n\n\nIf you need files that are at a publicly accessible location on the internet (for example, NCBI reference genome data), you don’t need to download these to your computer and then upload them to OSC.\nInstead, you can use commands for downloading files directly to OSC, like wget or curl. This will be covered in one of the main sessions."
  },
  {
    "objectID": "modules/01_intro.html",
    "href": "modules/01_intro.html",
    "title": "RNAseq data analysis: introduction",
    "section": "",
    "text": "## Workflow overview"
  },
  {
    "objectID": "modules/01_intro.html#data-type-and-workflow-variations",
    "href": "modules/01_intro.html#data-type-and-workflow-variations",
    "title": "RNAseq data analysis: introduction",
    "section": "Data type and workflow variations",
    "text": "Data type and workflow variations\n\nReference-based versus de novo workflows\nWe will cover a “reference-based” RNAseq workflow: one where your focal organism has a reference genome assembly and annotation. “De novo” RNAseq workflows are necessary when you don’t have a reference genome. They are overall similar, but more time-consuming and bioinformatics-heavy, since you will first have to assemble a transcriptome from the RNAseq data itself.\n\n\nGene-level versus transcript-level counts, and short versus long reads\nWe will focus on generating and analyzing gene-level counts rather than transcript-level counts: that is, for each sample, we will obtain a single count for each gene even if that gene has multiple transcripts (isoforms). However, the program which we’ll use for counting (Salmon) can also generate transcript-level counts, and downstream transcript-level analysis is fairly similar too, though this certainly adds a level of complexity.\nAdditionally, we will use short-read (Illumina) sequencing data, for which transcript-level counts have much greater levels of uncertainty, since most reads cannot directly be assigned to a specific transcript. Consider using long reads, such as PacBio IsoSeq, if you’re interested in transcript-level inferences.\n\n\n“Bulk” versus single-cell RNAseq\nWe will focus on “bulk” RNAseq, where RNA was extracted from a large mixture of cells and possibly cell types. Single-cell RNAseq analysis is similar for the first part (generating counts), but differs more in the second part (count analysis)."
  },
  {
    "objectID": "modules/01_intro.html#variatdata-type-and-workflow-variations",
    "href": "modules/01_intro.html#variatdata-type-and-workflow-variations",
    "title": "RNAseq data analysis: introduction",
    "section": "VariatData type and workflow variations",
    "text": "VariatData type and workflow variations\n\nReference-based versus de novo workflows\nWe will cover a “reference-based” RNAseq workflow: one where your focal organism has a reference genome assembly and annotation. “De novo” RNAseq workflows are necessary when you don’t have a reference genome. They are overall similar, but more time-consuming and bioinformatics-heavy, since you will first have to assemble a transcriptome from the RNAseq data itself.\n\n\nGene-level versus transcript-level counts, and short versus long reads\nWe will focus on generating and analyzing gene-level counts rather than transcript-level counts: that is, for each sample, we will obtain a single count for each gene even if that gene has multiple transcripts (isoforms). However, the program which we’ll use for counting (Salmon) can also generate transcript-level counts, and downstream transcript-level analysis is fairly similar too, though this certainly adds a level of complexity.\nAdditionally, we will use short-read (Illumina) sequencing data, for which transcript-level counts have much greater levels of uncertainty, since most reads cannot directly be assigned to a specific transcript. Consider using long reads, such as PacBio IsoSeq, if you’re interested in transcript-level inferences.\n\n\n“Bulk” versus single-cell RNAseq\nWe will focus on “bulk” RNAseq, where RNA was extracted from a large mixture of cells and possibly cell types. Single-cell RNAseq analysis is similar for the first part (generating counts), but differs more in the second part (count analysis)."
  },
  {
    "objectID": "modules/01_intro.html#variatiodata-type-and-workflow-variations",
    "href": "modules/01_intro.html#variatiodata-type-and-workflow-variations",
    "title": "RNAseq data analysis: introduction",
    "section": "VariatioData type and workflow variations",
    "text": "VariatioData type and workflow variations\n\nReference-based versus de novo workflows\nWe will cover a “reference-based” RNAseq workflow: one where your focal organism has a reference genome assembly and annotation. “De novo” RNAseq workflows are necessary when you don’t have a reference genome. They are overall similar, but more time-consuming and bioinformatics-heavy, since you will first have to assemble a transcriptome from the RNAseq data itself.\n\n\nGene-level versus transcript-level counts, and short versus long reads\nWe will focus on generating and analyzing gene-level counts rather than transcript-level counts: that is, for each sample, we will obtain a single count for each gene even if that gene has multiple transcripts (isoforms). However, the program which we’ll use for counting (Salmon) can also generate transcript-level counts, and downstream transcript-level analysis is fairly similar too, though this certainly adds a level of complexity.\nAdditionally, we will use short-read (Illumina) sequencing data, for which transcript-level counts have much greater levels of uncertainty, since most reads cannot directly be assigned to a specific transcript. Consider using long reads, such as PacBio IsoSeq, if you’re interested in transcript-level inferences.\n\n\n“Bulk” versus single-cell RNAseq\nWe will focus on “bulk” RNAseq, where RNA was extracted from a large mixture of cells and possibly cell types. Single-cell RNAseq analysis is similar for the first part (generating counts), but differs more in the second part (count analysis)."
  }
]