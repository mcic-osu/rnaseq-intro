---
title: "Using Software at OSC"
subtitle: "Loading existing modules and installing and using software with _Conda_" 
pagetitle: "Software at OSC"
highlight-style: github
number-sections: true
engine: knitr
author: Jelmer Poelstra
date: 2023-09-08
---

```{r knitr_options, echo=FALSE}
knitr::opts_chunk$set(eval = FALSE, class.output = "bash-out")
```

-------

<br>

::: {.callout-important}
## Under construction 
This page is nearly finished, only the Container section needs to be completed.
:::

## Overview & setting up {-}

To analyze RNAseq data and other genomics data sets,
a typical workflow includes using a sequence of specialized bioinformatics software.

At OSC, there are system-wide installations of a number of bioinformatics programs.
As we briefly [saw earlier for FastQC](./A07_overview.qmd#running-a-cli-program-interactively),
and will talk about more here, we do need to "load" such programs.

Unfortunately,
the collection of bioinformatics programs at OSC is not very comprehensive,
and some of the available programs only come in relatively old versions.
We therefore also need a way to make other programs available to ourselves
at OSC.

#### Start VS Code and open your folder {-}

As always, we'll be working in VS Code &mdash;
if you don't already have a session open, see below how to do so.

**Make sure to open your `/fs/ess/PAS0471/<user>/rnaseq_intro` dir**,
either by using the `Open Folder` menu item,
or by clicking on this dir when it appears in the `Welcome` tab.

:::{.callout-tip collapse="true"}
## Starting VS Code at OSC - with a Terminal (Click to expand)
1. Log in to OSC's OnDemand portal at <https://ondemand.osc.edu>.

2. In the blue top bar, select `Interactive Apps`
   and then near the bottom of the dropdown menu, click `Code Server`.

3. In the form that appears on a new page:
   - Select an appropriate OSC project (here: `PAS0471`)
   - For this session, select `/fs/ess/PAS0471` as the starting directory
   - Make sure that `Number of hours` is at least `2`
   - Click `Launch`.

4. On the next page, once the top bar of the box has turned green
   and says `Runnning`, click `Connect to VS Code`.

<figure><p align="center"><img src=img/osc-code-launch_ed.png width="80%"></p></figure>

5. Open a Terminal by clicking
   &nbsp; {{< fa bars >}} &nbsp; => `Terminal` => `New Terminal`.
   (Or use one of the keyboard shortcuts:
   <kbd>Ctrl</kbd>+<kbd>\`</kbd> (backtick) or
   <kbd>Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>C</kbd>.)

6. In the `Welcome` tab under `Recent`,
   you should see your `/fs/ess/PAS0471/<user>/rnaseq_intro` dir listed:
   click on that to open it.
   Alternatively, use
   &nbsp; {{< fa bars >}} &nbsp; => &nbsp; `File` &nbsp; => &nbsp; `Open Folder`
   to open that dir in VS Code.
:::

:::{.callout-warning collapse="true"}
#### Don't have your own dir with the data? (Click to expand)
If you missed the last session, or deleted your `rnaseq_intro` dir entirely,
run these commands to get a (fresh) copy of all files you should have so far:

```bash
mkdir -p /fs/ess/PAS0471/$USER/rnaseq_intro
cp -r /fs/ess/PAS0471/demo/202307_rnaseq /fs/ess/PAS0471/$USER/rnaseq_intro
```

And if you do have an `rnaseq_intro` dir,
but you want to start over because you moved or removed some of the files
while practicing, then delete the dir before your run the commands above:

```bash
rm -r /fs/ess/PAS0471/$USER/rnaseq_intro
```

You should have at least the following files in this dir:

```{.bash-out}
/fs/ess/PAS0471/demo/202307_rnaseq
├── data
│   └── fastq
│       ├── ASPC1_A178V_R1.fastq.gz
│       ├── ASPC1_A178V_R2.fastq.gz
│       ├── ASPC1_G31V_R1.fastq.gz
│       ├── ASPC1_G31V_R2.fastq.gz
│       ├── md5sums.txt
│       ├── Miapaca2_A178V_R1.fastq.gz
│       ├── Miapaca2_A178V_R2.fastq.gz
│       ├── Miapaca2_G31V_R1.fastq.gz
│       └── Miapaca2_G31V_R2.fastq.gz
├── metadata
│   └── meta.tsv
└── README.md
│   └── ref
│       ├── GCF_000001405.40.fna
│       ├── GCF_000001405.40.gtf
```
:::

<br>

## Loading software at OSC with _Lmod_ modules

OSC administrators manage software with the _Lmod_ system of software modules.
For us users, this means that even though a lot of software is installed,
**most of it can only be used after we explicitly load it.**  
(That may seem like a drag, but on the upside,
this practice enables the use of different versions of the same software,
and of mutually incompatible software on a single system.)

We can load, unload, and search for available software modules using the
**`module` command** and its various subcommands.

### Checking whether a program is available

The OSC website has a
[list of installed software](<https://www.osc.edu/resources/available_software/software_list>).
You can also search for available software in the shell
using two subtly different commands:
  
  - `module spider` lists modules that are installed.
  - `module avail` lists modules that *can be directly loaded*,
    given the current environment
    (i.e., depending on which other software has been loaded).

Simply running `module spider` or `module avail` would spit out the full lists
of installed/available programs &mdash;
it is more useful to add a **search term** as an argument to these commands:

```bash
module spider miniconda
```
``` {.bash-out}
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  miniconda3:
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
     Versions:
        miniconda3/4.10.3-py37
        miniconda3/4.12.0-py38
        miniconda3/4.12.0-py39
        miniconda3/23.3.1-py310

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  For detailed information about a specific "miniconda3" module (including how to load the modules) use the module's full name.
  For example:

     $ module spider miniconda3/4.12.0-py39
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
```

```bash
module avail miniconda
```
```{.bash-out}
------------------------------------------------------------------------------------------------------ /apps/lmodfiles/Core -------------------------------------------------------------------------------------------------------
   miniconda3/4.10.3-py37 (D)    miniconda3/4.12.0-py38    miniconda3/4.12.0-py39    miniconda3/23.3.1-py310

  Where:
   D:  Default Module
```

As stated at the bottom of the output below,
the `(D)` in the `module avail` output above marks the default version of the program:
this is the version of the program that will be loaded if we don't specify
a version ourselves (see examples below).
The `module spider` command does not provide this information.

<br>

### Loading software

All other _Lmod_ software functionality is also accessed using `module`
"subcommands" (we call `module` the command and e.g. `spider` the subcommand).
For instance, to make a program available to us we need to **_load_ a module**:
  
```bash
# Load a module:
module load miniconda3               # Load the default version
module load miniconda3/23.3.1-py310  # Load a specific version
```

::: {.callout-tip}
#### Modules do not remain loaded across separate shell sessions 
Module loading does _not_ persist across shell sessions.
Whenever you get a fresh shell session
(including but not limited to after logging into OSC again),
you will have to (re)load any modules you want to use!
:::

To check which modules have been loaded, we use `module list` &mdash;
note that the output includes several _automatically_ loaded modules:

```bash
module list
```
```{.bash-out}
Currently Loaded Modules:
  1) xalt/latest   2) gcc-compatibility/8.4.0   3) intel/19.0.5   4) mvapich2/2.3.3   5) modules/sp2020
```

:::{.callout-note collapse="true"}
## Unloading modules (Click to expand)

Occasionally, when you run into conflicting (mutually incompatible) modules,
it can be useful to unload modules,
which you can do as follows:

```bash
module unload python        # Unload a module
module purge                # Unload all modules
```
:::

<br>

### A practical example: _FastQC_ again

First, let's test that we indeed _cannot_ currently use _FastQC_
by running `fastqc` with the `--help` flag:

```bash
fastqc --help
```
``` {.bash-out}
bash: fastqc: command not found
```

:::{.callout-tip}
##### Help!
A solid majority of command-line programs can be run with with a `--help`
(and/or `-h`) flag, and this is often a good thing to try first,
since it will tell use whether we can use the program &mdash;
and if we can, we immediately get some usage information.
:::

Next, let's check whether _FastQC_ is available at OSC,
and if so, in which versions:

```bash
module avail fastqc
```
```{.bash-out}
fastqc/0.11.8
```

There is only one version available (`0.11.8`),
which means that `module load fastqc` and `module load fastqc/0.11.8` would 
each load that same version.

:::{.callout-caution collapse="true"}
## What might still be a reason to specify the version when we load FastQC?

When we use the `module load` command inside a script:

- This would ensure that when we run the same script a year later,
  the same version would be used (assuming it hasn't been removed) &mdash;
  otherwise, it's possible a newer version would has been installed in the
  meantime, which might produce different results.

- It will make it easy to see which version we used,
  which is something we typically report in papers. 
:::

Let's load the _FastQC_ module:

```bash
module load fastqc/0.11.8
```

Now, we can retry our `--help` attempt: 

```bash
fastqc --help
```
``` {.bash-out}
            FastQC - A high throughput sequence QC analysis tool

SYNOPSIS

        fastqc seqfile1 seqfile2 .. seqfileN

    fastqc [-o output dir] [--(no)extract] [-f fastq|bam|sam] 
           [-c contaminant file] seqfile1 .. seqfileN  
# [...truncated...]
```

::: {.exercise}
#### On your own: load `miniconda3`

- Load the default version of `miniconda3`, and then check which version was loaded.

:::{.callout-tip collapse="true"}
##### Solution (Click here)

```bash
module load miniconda3

module list
```
```{.bash-out}
Currently Loaded Modules:
  1) xalt/latest   2) gcc-compatibility/8.4.0   3) intel/19.0.5   4) mvapich2/2.3.3   5) modules/sp2020   6) miniconda3/4.10.3-py37
```

The version `4.10.3-py37` was loaded.
:::

- Now load the _latest_ version of `miniconda3` without unloading the earlier version
  first. What output do you get?

:::{.callout-tip collapse="true"}
##### Solution (Click to expand)

Lmod detected that you tried to load a different version of a software that was
already loaded, so it _changes_ the version and tells you about it:

```bash
module load miniconda3/23.3.1-py310
```
```{.bash-out}
The following have been reloaded with a version change:
  1) miniconda3/4.10.3-py37 => miniconda3/23.3.1-py310
```
:::
:::

<br>

## When software isn't installed at OSC

It's not too uncommon that software you need for your project
is not installed at OSC,
or that you need a more recent version of the software than is available.
In that case, the following two are generally your best options:

- **_Conda_**, which creates software environments that you can activate
  much like the _Lmod_ modules.

- **Containers**, which are self-contained software environments that include
  operating systems, akin to mini virtual machines.
  While _Docker_ containers are most well-known,
  OSC uses **_Apptainer_** (formerly known as _Singularity_) containers.
  
::: {.callout-note}
#### Other options to install software / get it installed

- Send an **email to [OSC Help](mailto:oschelp@osc.edu)**.
  They might be able to help you with your installation,
  or in case of commonly used software, might be willing to perform a
  system-wide installation (that is, making it available through _Lmod_).

- **"Manually" install the software**, which in the best case involves
  downloading a directly functioning binary (executable),
  but more commonly requires you to "compile" (build) the program.
  This is sometimes straightforward but can also become extremely tricky,
  especially at OSC where you don't have "administrator privileges"[^1]
  and will often have difficulties with "dependencies"[^2].
:::

_Conda_ and containers are useful not only at OSC,
where they bypass issues with dependencies and administrator privileges,
but more generally, for **reproducible and portable software environments**.
They also allow you to easily maintain distinct "environments",
each with a different version of the same software,
or with mutually incompatible software.

Below, you'll learn how you can use Conda and/or containers to use bioinformatics
programs that aren't installed system-wide at OSC.

[^1]: When your personal computer asks you to "authenticate" while you are
      installing something, you are authenticating yourself as a user with
      administrator privileges.
      At OSC, you don't have such privileges.

[^2]: Other software upon which the software that you are trying to install
      depends.

<br>

## Intro to *Conda* & using MCIC's _Conda_ environments

The _Conda_ software can create so-called **environments**
in which one can install one or more software packages.

As we'll see below, as long as a program is available in one of the online
_Conda_ repositories, installing it is quite straightforward,
doesn't require admin privileges,
and the process is basically identical regardless of the program.

However, at OSC, you might not even have to install anything yourself,
since I maintain an "MCIC collection" of _Conda_ environments that anyone can use.
A _Conda_ environment is just a directory, and since all the environments in this
collection are in the same place at OSC, you can list them as follows:

```bash
ls /fs/ess/PAS0471/jelmer/conda
```
```{.bash-out}
abricate-1.0.1  bedops-2.4.39  checkm-1.2.0   entrez-direct    htseq-2.0.2          longstitch-1.0.3  nanopolish-0.13.2    prokka            repeatmasker-4.1.2.p1         samtools                star
agat-0.9.1      bedtools       clinker        evigene          inspector-1.2.0      mafft             ncbi-datasets        pseudofinder      repeatmodeler-2.0.3           scoary                  subread-2.0.1
alv             bioawk         clonalframeml  fastp            interproscan-5.55    maskrc-svg        nextdenovo-env       purge_dups-1.2.6  resfinder                     seqkit                  tgsgapcloser
amrfinderplus   biopython      codan-1.2      fastqc           iqtree               medaka-1.7.2      nextflow             pycoqc-2.5.2      resistomeanalyzer-2018.09.06  seqtk                   tracy-0.7.1
antismash       bit            cogclassifier  fastq-dl         justorthologs-0.0.2  metaxa-2.2.3      orna-2.0             qiime2-2022.8     rgi-5.2.1                     signalp-6.0             transabyss-2.0.1
ariba-2.14.6    blast          cutadapt       fasttree-2.1.11  kallisto-0.48.0      minibusco         orthofinder          qualimap-env      r-metabar                     sistr-1.1.1             transdecoder-5.5.0
astral-5.7.8    bowtie2-2.5.0  deeploc        filtlong-env     kat-2.4.2            minimap2-2.24     orthofisher          quast-5.0.2       rnaquast-2.2.1                smartdenovo-env         treetime
aswcli          bracken-2.6.1  deeptmhmm      flye-2.9.1       knsp-3.1             mlst              panaroo              quickmerge-env    roary-3.13                    snippy-4.6.0            trimgalore
bactopia        braker2-env    deeptmhmm2     fmlrc2-0.1.7     kofamscan            mlst_check        phylofisher          racon-1.5.0       r-rnaseq                      snp-sites-2.5.1         trimmomatic-0.39
bactopia-dev    busco          diamond        gcta             kraken2-2.1.2        mobsuite          pilon-1.24           ragtag-2.1.0      rsem-1.3.3                    soapdenovo-trans-1.0.4  trinity-2.13.2
bakta           bwa-0.7.17     dwgsim         gffread-0.12.7   krakentools-1.2      multiqc           pkgs                 rascaf            rseqc-env                     sortmerna-env           unicycler
base            bwa-mem-2.2.1  eggnogmapper   gubbins          krona                mummer4           plasmidfinder-2.1.6  rcorrector-1.0.5  r_tree                        sourmash                virulencefinder
bbmap           cactus         emboss         hisat2           liftoff-1.6.3        nanolyse-1.2.1    plink2               r-deseq           sabre-1.0                     spades-3.15.5           wtdbg-2.5
bcftools        cgmlst         entap-0.10.8   hmmer            links-2.0.1          nanoplot          porechop             recognizer-1.8.3  salmon                        sra-tools
```

This is organized similarly to the _Lmod_ modules in that there's generally
**one separate environment for one program** (and all its dependencies),
and the environment is named after that program.

The naming of the environments is unfortunately not entirely consistent:
many environments include the version number of the program,
but many others do not.
(Generally speaking, for environments without version numbers,
you should expect the version of the program to be very recent,
as I try to keep these up-to-date[^3]).

[^3]: It isn't feasible to keep separate environments around for many different
      versions of a program, mostly because _Conda_ environments contain a very
      large number of files, and OSC has file number quotas.
      This is why I have in many cases chosen the strategy of just updating
      the version within the same environment.

This collection includes _Conda_ environments for several programs we need during
RNAseq analysis that are not installed at OSC, such as _MultiQC_,
_TrimGalore_, and _SortMeRNA_.

<br>

### Activating _Conda_ environments

_Conda_ itself is already installed at OSC as _Miniconda_,
but we always need to load its module before we can use it:
      
```bash
module load miniconda3
```

As mentioned above, these environments are activated and deactivated
in a similar manner as with the _Lmod_ system.
(But whereas we use the term "load" for _Lmod_ modules,
we use **"activate"** for _Conda_ environments &mdash; it means the same thing.)

Also like _Lmod_, there is a main command (`conda`) and several subcommands
(`deactivate`, `create`, `install`, `update`) for different functionality.
However, for historical reasons,
the most foolproof way to activate a _Conda_ environment is to use **`source activate`**
rather than the expected `conda activate` &mdash; for instance:

```bash
source activate /fs/ess/PAS0471/jelmer/conda/multiqc
```
```{.bash-out}
(multiqc) [jelmer@p0085 rnaseq-intro]$
```

:::{.callout-tip}
##### _Conda_ environment indicator
When we have an active _Conda_ environment,
its name is conveniently displayed in our prompt, as depicted above.
:::

After we have activated the `multiqc` environment, 
we should be able to actually use the program.
To test this, we'll again simply run it with a `--help` option:

```{bash, eval=FALSE}
multiqc --help
```

``` {.bash-out}                                                                                                                                                                                                                               
 /// MultiQC 🔍 | v1.15                                                                                                                                                                                                            
                                                                                                                                                                                                                                   
 Usage: multiqc [OPTIONS] [ANALYSIS DIRECTORY]                                                                                                                                                                                     
                                                                                                                                                                                                                                   
 MultiQC aggregates results from bioinformatics analyses across many samples into a single report.                                                                                                                                 
 It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.                                                       
 To run, supply with one or more directory to scan for analysis results. For example, to run in the current working directory, use 'multiqc .'                                                                                     
                                                                                                                                                                                                                                   
╭─ Main options ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ --force            -f  Overwrite any existing reports                                                                                                                                                                           │
│ --config           -c  Specific config file to load, after those in MultiQC dir / home dir / working dir. (PATH)                                                                                                                │
│ --cl-config            Specify MultiQC config YAML on the command line (TEXT)                                                                                                                                                   │
│ --filename         -n  Report filename. Use 'stdout' to print to standard out. (TEXT)                                                                                                                                           │
│ --outdir           -o  Create report in the specified output directory. (TEXT)                                                                                                                                                  │
│ --ignore           -x  Ignore analysis files (GLOB EXPRESSION)                                                                                                                                                                  │
│ --ignore-samples       Ignore sample names (GLOB EXPRESSION)                                                                                                                                                                    │
│ --ignore-symlinks      Ignore symlinked directories and files                                                                                                                                                                   │
│ --file-list        -l  Supply a file containing a list of file paths to be searched, one per row                                                                                                                                │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
[...truncated...]
```

<br>

### Lines to add to your shell script

As mentioned above for _Lmod_ modules,
you need to load them in every shell session you want to use them &mdash;
and the same is true for _Conda_ environments.
Therefore, you should also always
_include the necessary code to load/activate programs in your shell scripts._

**When your program is in an _Lmod_ module**,
this only involves a `module load` call &mdash; e.g., for _FastQC_:

```bash
#!/bin/bash
set -euo pipefail

# Load software
module load fastqc
```

**When your program is in a _Conda_ environment**,
this entails a `module load` command to load _Conda_ itself,
followed by a `source activate` command to load the relevant _Conda_ environment:

```bash
#!/bin/bash

# Load software
module load miniconda3
source activate /fs/ess/PAS0471/jelmer/conda/multiqc

# Strict/safe Bash settings 
set -euo pipefail
```

:::{.callout-warning}
I've moved the `set -euo pipefail` line _below_ the `source activate` command,
because the _Conda_ activation procedure can otherwise result in "unbound variable"
errors.
:::

::: {.callout-note}
#### A few other useful _Conda_ commands

- Deactivate the currently active _Conda_ environment:

  ```{bash, eval=FALSE}
  conda deactivate   
  ```

- Activate one environment and then "stack" an _additional_ environment
  (a regular `source activate` command would _switch_ environments):

  ```{bash, eval=FALSE}
  # Load one environment the regular way:
  source activate /fs/ess/PAS0471/jelmer/conda/multiqc
  # This will _also_ activate the TrimGalore environment (yes, use 'conda'!):
  conda activate --stack /fs/ess/PAS0471/jelmer/conda/trimgalore
  ```

- List all packages (programs) installed in an environment &mdash;
  due to dependencies, this can be a long list,
  even if you only actively installed one program:

  ```{bash, eval=FALSE}
  conda list -n /fs/ess/PAS0471/jelmer/conda/multiqc
  ```

:::

<br>

## Using _Apptainer_ containers

::: {.callout-caution}
#### TODO
:::

- Docker vs. Singularity & Apptainer
- Downloading a container
- Running a program inside a container
- Building your own containers outside of the scope of this intro

<br>

## At-home reading: Creating your own _Conda_ environments

When you want to create your own _Conda_ environments and install programs,
make sure to load the most recent `miniconda3` module,
which is currently not the default one.
This is because installation has become much quicker and less likely to fail than
in earlier versions
(just for _loading_ environments, like we did above, the version doesn't matter).

As of August 2023, the most recent version is `23.3.1-py310`
(and recall that you can check all available versions with `module spider`):

```bash
module load miniconda3/23.3.1-py310
```

### One-time _Conda_ configuration

We first have to do some _one-time_ configuration[^4],
which will set the **_Conda_ "channels"** (basically, software repositories)
that we want to use when we install programs.
This config also includes setting relative _priorities_ among channels,
since one program may be available from multiple channels.

[^4]: That is, these settings will be saved somewhere in your OSC home directory,
      and you never have to set them again unless you need to make changes.

We can do this with the `config` subcommand:

```bash
conda config --add channels defaults     # Added first => lowest priority
conda config --add channels bioconda
conda config --add channels conda-forge  # Added last => highest priority
```

Let's check whether the configuration was successfully saved:

```bash
conda config --get channels
```
``` {.bash-out}
--add channels 'defaults'   # lowest priority
--add channels 'bioconda'
--add channels 'conda-forge'   # highest priority
```

<br>

### Example: Creating an environment for _Trim Galore!_

To practice using _Conda_,
we will now create a Conda environment with the program _Trim Galore!_ installed.

_Trim Galore!_ is a commonly used program to do quality trimming and adapter trimming
for `FASTQ` files &mdash;
we'll learn more about it in a later session, as we will use it on our RNAseq data.

Here is the command to all at once create a new _Conda_ environment
and install _Trim Galore!_ into that environment:

```{bash, eval=FALSE}
# (Don't run this)
conda create -y -n trim-galore -c bioconda trim-galore
```

Let's break the above command down:

- **`create`** is the _Conda_ subcommand to create a new environment.

- **`-y`** is a flag that prevents us from being asked to confirm installation.

- Following the **`-n`** option, we can specify the name of the environment,
  so **`-n trim-galore`** means that we want our environment to be called
  `trim-galore`.
  We can use whatever name we like for the environment,
  but of course a descriptive yet concise name is a good idea.
  Since we are making a single-program environment,
  it makes sense to simply name it after the program.
  
- Following the **`-c`** option,
  we can specify a channel from which we want to install,
  so **`-c bioconda`** indicates we want to use the `bioconda` channel.
  (Given that we've done some config above, this is not always necessary,
  but it can be good to be explicit.)
  
- The **`trim-galore`** at the end of the line
  simply tells _Conda_ to install the package of that name.
  This is a "_positional_" argument to the command
  (note that there's no option like `-s` before it):
  we put any software package(s) we want to install at the end of the command.

#### Specifying a version {-}

If we want to be explicit about the version we want to install,
we can add the version after `=` following the package name,
and may also want to include that version number in the _Conda_
environment's name &mdash;
try running the command below:

```bash
conda create -y -n trim-galore-0.6.10 -c bioconda trim-galore=0.6.10
```
```{.bash-out}
Collecting package metadata (current_repodata.json): done  
Solving environment: done
# [...truncated...]
```

:::{.callout-tip collapse="true"}
## See the full output when I ran this command (Click to expand)

<br>

```{bash, eval=TRUE, echo=FALSE}
cat misc/trimgalore_install.txt
```

:::

Now, you should be able to activate the enviroment
(using just it's name -- see the box below):

```bash
source activate trim-galore

trim_galore --help
```
```{.bash-out}
 USAGE:

trim_galore [options] <filename(s)>

-h/--help               Print this help message and exits.
# [...truncated...]
```

:::{.callout-note}
#### Specifying the full path to the environment dir

You may have noticed above that we merely gave the enviroment a _name_
(`trim-galore` or `trim-galore-0.6.10`),
and did not tell it _where_ to put this environment.
Similarly, we were able to activate the environment with just its name.
Conda assigns a **personal default directory for its environments**,
somewhere in your Home directory.

You can install environments in a different location
with the `-p` (instead of `-n`) option, for example:

```bash
mkdir -p /fs/scratch/PAS0471/$USER/conda
conda create -y -p /fs/scratch/PAS0471/$USER/conda/trim-galore -c bioconda trim-galore
```

And when you want to load someone else's _Conda_ environments,
you'll always have to specify the full path to environment's dir,
like you did when loading a _Conda_ environment of mine above.
:::

<br>

### Finding the _Conda_ installation info online

Minor variations on the `conda create` command above can be used to install
almost any program for which a _Conda_ package is available,
which is the vast majority of open-source bioinformatics programs!

However, you may be wondering how we would know:

- Whether the program is available and what its _Conda_ package's name is
- Which _Conda_ channel we should use
- Which versions are available

My strategy to finding these things out is to simply Google the program name
together with "conda", e.g. "cutadapt conda" if I wanted to install the 
_CutAdapt_ program. Let's see that in action:

<p align="center"><img src=img/conda_google.png width="85%"></p>

<br>

We click on that first link (it should always be the first Google hit):

<p align="center"><img src=img/conda_website.png width="85%"></p>

<br>

#### Build the installation command {-}

I always take the top of the two example installation commands as a template,
which is here: `conda install -c bioconda cutadapt`.

You may notice the `install` subcommand, which we haven't yet seen.
This would install Cutadapt into _the currently activated Conda environment_.
Since our strategy here --and my general strategy-- is to create a new
environment each time you're installing a program,
just installing in whatever environment is currently active is not a great idea.
You could first create an "empty" environment, and _then_ run the install command,
but we saw above that we can do all of this in a single command.

To build this create-plus-install command, all we need to do is replace `install`
in the example command on the _Conda_ website by `create -y -n <env-name>`.
Then, our full command (without version specification) again will be:

```bash
conda create -y -n cutadapt -c bioconda cutadapt
```

To see which **version** will be installed by default,
and to see which older versions are available:

<p align="center">
<img src=img/conda_website_version.png width="70%">
</p>

For almost any other program, you can use the exact same procedure to find
the _Conda_ package and install it!

::: {.callout-note}
#### A few more _Conda_ commands to manage your environments

- Remove an environment entirely:

  ```{bash, eval=FALSE}
  conda env remove -n cutadapt
  ```

- List all your conda environments:

  ```{bash, eval=FALSE}
  conda env list
  ```

:::

:::{.callout-note}
## Use one environment per program (as here) or one per research project

Below are two reasonable ways to organize your _Conda_ environments,
and their advantages:

- **Have one environment per program** (my preference)
  - Easier to keep an overview of what you have installed
  - No need to reinstall the same program across different projects
  - Less risk of running into problems with your environment due to mutually
    incompatible software and complicated dependency situations

- _Have one environment per research project_
  - You just need to activate that one environment when you're working on
    your project.
  - Easier when you need to share your entire project with someone else
    (or yourself) on a different (super)computer.

Even though it might seem easier,
it's _not_ recommended to simply install all programs across all projects in
one single environment.
This doesn't benefit reproducibility and your environment is likely to
sooner or later stop functioning properly.

A side note is that even when you want to install a single program,
multiple programs _are_ in fact nearly always installed:
the programs that your target program depends on ("dependencies").
:::
