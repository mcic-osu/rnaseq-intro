{
  "hash": "491ad195a59e42df60ca93c68e89e3ce",
  "result": {
    "markdown": "---\ntitle: \"Read QC with _FastQC_\"\nsubtitle: \"And the distinction between program-specific scripts and an overarching runner/master script\"\npagetitle: \"FastQC\"\nhighlight-style: github\nnumber-sections: true\nengine: knitr\nauthor: Jelmer Poelstra\ndate: 2023-09-22\n---\n\n::: {.cell}\n\n:::\n\n\n::: {.callout-important}\n## Under construction \nThis page is still under construction.\n:::\n\n-------\n\n<br>\n\n## Overview & setting up {-}\n\nSo far,\nwe have covered all the building blocks to be able to run command-line programs\nat OSC:\n\n- Basics of a supercomputer and of **OSC** specifically\n- Unix (Bash) **shell** basics to work at a supercomputer,\n  and learn the language used in our scripts\n- The bells and whistles needed to turn our commands into a **shell script**\n- Loading and installing the **software** (command-line programs) that we want to run\n- Working with the **Slurm** job scheduler, so we can submit scripts as batch jobs\n- The ability to **loop** over commands, so that we can submit many scripts at once\n\nWith these skills,\nit's relatively straightforward to create and submit scripts that run command-line\nprograms to analyze our genomics data.\nIn this session,\nwe'll apply these skills for the first time to run **_FastQC_**.\n\n<br>\n\n#### _FastQC_: A program for quality control of FASTQ files {-}\n\n_FastQC_ is one the most ubiquitous pieces of genomics software.\nIt allows you to assess the overall quality of, and potential problems with,\nthe reads in your FASTQ files.\nIt produces visualizations and assessments of FASTQ files for statistics\nsuch as per-base quality (below) and adapter content.\nRunning FastQC or an equivalent program should always be the first analysis step\nafter you receive your sequences.  \n\nFor each FASTQ file, FastQC outputs an **HTML file** that you can open in your\nbrowser and which has about a dozen graphs showing different QC metrics.\nThe most important one is the **per-base quality score graph** shown below.\n\n::: {#fig-elephants layout-ncol=2 layout-nrow=1}\n\n![](img/fastqc_good.png)\n\n![](img/fastqc_bad.png)\n\nA FastQC per-base quality score graph for files with fairly good (left) and\npoor (right) quality reads.\n:::\n\n#### Start VS Code and open your folder {-}\n\nAs always, we'll be working in VS Code &mdash;\nif you don't already have a session open, see below how to do so.\n\n**Make sure to open your `/fs/ess/PAS0471/<user>/rnaseq_intro` dir**,\neither by using the `Open Folder` menu item,\nor by clicking on this dir when it appears in the `Welcome` tab.\n\n:::{.callout-tip collapse=\"true\"}\n## Starting VS Code at OSC - with a Terminal (Click to expand)\n1. Log in to OSC's OnDemand portal at <https://ondemand.osc.edu>.\n\n2. In the blue top bar, select `Interactive Apps`\n   and then near the bottom of the dropdown menu, click `Code Server`.\n\n3. In the form that appears on a new page:\n   - Select an appropriate OSC project (here: `PAS0471`)\n   - For this session, select `/fs/ess/PAS0471` as the starting directory\n   - Make sure that `Number of hours` is at least `2`\n   - Click `Launch`.\n\n4. On the next page, once the top bar of the box has turned green\n   and says `Runnning`, click `Connect to VS Code`.\n\n<figure><p align=\"center\"><img src=img/osc-code-launch_ed.png width=\"80%\"></p></figure>\n\n5. Open a Terminal by clicking\n   &nbsp; {{< fa bars >}} &nbsp; => `Terminal` => `New Terminal`.\n   (Or use one of the keyboard shortcuts:\n   <kbd>Ctrl</kbd>+<kbd>\\`</kbd> (backtick) or\n   <kbd>Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>C</kbd>.)\n\n6. In the `Welcome` tab under `Recent`,\n   you should see your `/fs/ess/PAS0471/<user>/rnaseq_intro` dir listed:\n   click on that to open it.\n   Alternatively, use\n   &nbsp; {{< fa bars >}} &nbsp; => &nbsp; `File` &nbsp; => &nbsp; `Open Folder`\n   to open that dir in VS Code.\n:::\n\n:::{.callout-warning collapse=\"true\"}\n#### Don't have your own dir with the data? (Click to expand)\nIf you missed the last session, or deleted your `rnaseq_intro` dir entirely,\nrun these commands to get a (fresh) copy of all files you should have so far:\n\n```bash\nmkdir -p /fs/ess/PAS0471/$USER/rnaseq_intro\ncp -r /fs/ess/PAS0471/demo/202307_rnaseq /fs/ess/PAS0471/$USER/rnaseq_intro\n```\n\nAnd if you do have an `rnaseq_intro` dir,\nbut you want to start over because you moved or removed some of the files\nwhile practicing, then delete the dir before your run the commands above:\n\n```bash\nrm -r /fs/ess/PAS0471/$USER/rnaseq_intro\n```\n\nYou should have at least the following files in this dir:\n\n```{.bash-out}\n/fs/ess/PAS0471/demo/202307_rnaseq\n├── data\n│   └── fastq\n│       ├── ASPC1_A178V_R1.fastq.gz\n│       ├── ASPC1_A178V_R2.fastq.gz\n│       ├── ASPC1_G31V_R1.fastq.gz\n│       ├── ASPC1_G31V_R2.fastq.gz\n│       ├── md5sums.txt\n│       ├── Miapaca2_A178V_R1.fastq.gz\n│       ├── Miapaca2_A178V_R2.fastq.gz\n│       ├── Miapaca2_G31V_R1.fastq.gz\n│       └── Miapaca2_G31V_R2.fastq.gz\n├── metadata\n│   └── meta.tsv\n└── README.md\n│   └── ref\n│       ├── GCF_000001405.40.fna\n│       ├── GCF_000001405.40.gtf\n```\n:::\n\n<br>\n\n## A script to run _FastQC_\n\n### FastQC syntax\n\nTo analyze one (optionally gzipped) FASTQ file with FastQC,\nthe syntax can be as simple as:\n  \n\n::: {.cell}\n\n```{.bash .cell-code}\nfastqc <fastq-file>\n```\n:::\n\n\nThough in practice, we'll want to specify the output directory &mdash;\notherwise, output files would end up in the current working directory:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nfastqc --outdir=<output-dir> <fastq-file>\n```\n:::\n\n\nFor instance, if we wanted output files to go to the directory `results/fastqc`\nand wanted the program to analyze the file `data/fastq/ASPC1_A178V_R1.fastq.gz`,\na functional command would like like this:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nfastqc --outdir=results/fastqc data/fastq/ASPC1_A178V_R1.fastq.gz\n```\n:::\n\n\n:::{.callout-tip}\n## FastQC's output file names are automatically determined\nWe can specify the output _directory_, but not the actual file names,\nwhich will be automatically determined by FastQC based on the input file name.\n\nFor one FASTQ file, it will output one HTML file and one ZIP archive.\nThe latter contains files with the summary statistics that were computed and\non which the figures are based &mdash; we generally don't need to look at that.\n:::\n\n<br>\n\n### A basic script to run _FastQC_, and improvements\n\nHere is what a basic script to run _FastQC_ could look like:\n  \n```bash\n#!/bin/bash\n\n# Strict Bash settings\nset -euo pipefail\n\n# Copy the placeholder variables\ninput_file=$1\noutput_dir=$2\n\n# Run FastQC\nfastqc --outdir=\"$output_dir\" \"$input_file\"\n\n# (Don't run this in your terminal, but copy it into a .sh text file)\n```\n\nBut we'll add a few things to this script to run it smoothly as a batch job at OSC:\n\n- Add a line to the script to load the relevant OSC module:\n\n\n  ::: {.cell}\n  \n  ```{.bash .cell-code}\n  module load fastqc/0.11.8\n  ```\n  :::\n\n  \n- Add a few `sbatch` options to the top of the script:\n\n\n  ::: {.cell}\n  \n  ```{.bash .cell-code}\n  #SBATCH --account=PAS0471\n  #SBATCH --output=slurm-fastqc-%j.out\n  ```\n  :::\n\n\n- We'll add a few `echo` statements to report what's going on\n\n- We will create the output directory if it doesn't yet exist:\n\n  ```bash\n  mkdir -p \"$output_dir\"\n  ```\n\n:::{.callout-tip collapse=\"true\"}\n## Refresher: the `-p` option to `mkdir` (Click to expand)\n\nUsing the `-p` option does two things at once for us,\nboth of which are necessary for a foolproof inclusion of this command\nin a script:\n\n- It will enable `mkdir` to create multiple levels of directories at once:\n  by default, `mkdir` errors out if the _parent_ directory/directories of the\n  specified directory don't yet exist.\n\n\n  ::: {.cell}\n  \n  ```{.bash .cell-code}\n  mkdir newdir1/newdir2\n  #> mkdir: cannot create directory ‘newdir1/newdir2’: No such file or directory\n  ```\n  :::\n\n  ::: {.cell}\n  \n  ```{.bash .cell-code}\n  mkdir -p newdir1/newdir2    # This successfully creates both directories\n  ```\n  :::\n\n\n- If the directory already exists, it won't do anything and won't return an error\n  (which would lead the script to abort at that point with our `set` settings).\n  \n\n  ::: {.cell}\n  \n  ```{.bash .cell-code}\n  mkdir newdir1/newdir2\n  #> mkdir: cannot create directory ‘newdir1/newdir2’: File exists\n  ```\n  :::\n\n  ::: {.cell}\n  \n  ```{.bash .cell-code}\n  mkdir -p newdir1/newdir2   # This does nothing since the dirs already exist\n  ```\n  :::\n\n:::\n\n<br>\n\n### A more well-developed _FastQC_ script\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n#!/bin/bash\n#SBATCH --account=PAS2250\n#SBATCH --output=slurm-fastqc-%j.out\n  \n# Strict Bash settings\nset -euo pipefail\n\n# Load the OSC module for FastQC\nmodule load fastqc\n\n# Copy the placeholder variables\ninput_file=\"$1\"\noutput_dir=\"$2\" \n\n# Initial reporting\necho \"# Starting script fastqc.ch\"\ndate\necho \"# Input FASTQ file:   $input_file\"\necho \"# Output dir:         $output_dir\"\necho\n\n# Create the output dir if needed\nmkdir -p \"$output_dir\"\n\n# Run FastQC\nfastqc --outdir=\"$output_dir\" \"$input_file\"\n\n# Final reporting\necho\necho \"# Listing the output files:\"\nls -lh \"$output_dir\"\n\necho\necho \"# Done with script fastqc.sh\"\ndate\n\n# (Don't run this in your terminal, but copy it into a .sh text file)\n```\n:::\n\n\nNotice that this script is very similar to our toy scripts from the previous\nsessions:\nmostly standard (\"boilerplate\") code with\n**just a single command to run our program of interest.**\nTherefore, you can adopt this script as a template for scripts that run other\ncommand-line programs, and will generally only need minor modifications!\n\n<br>\n\n## A master / runner \"script\"\n\nAbove, we created a `fastqc.sh` script,\nwhich we'll eventually want to submit using a `for` loop.\nThe code with that loop and the `sbatch` command _could_ be typed directly in the terminal.\n**But it's better to save these sorts of commands in a file/script as well.**\n\nTherefore, we will now create a new file for the purpose of documenting the\nsteps that we are taking, and the scripts that we are submitting.\n_You can think of this file as your analysis lab notebook,_\n_or perhaps more accurately,_\n_your notebook entry that contains **the final protocol** you followed._\n\nThese kinds of scripts are sometimes called \"master\" or \"runner\" scripts.\nBecause they will mostly contain shell code,\nwe will save them as a shell script (`.sh`),\neven though it is not at all like the other scripts we've made,\nwhich are meant to be run/submitted in their entirety.\n\n::: {.callout-warning}\n#### The runner script can't itself be run at once\nOnce we've added multiple batch job steps,\nand the input of say step 2 depends on the output of step 1,\nwe won't be able to just _run_ the script as is.\nThis is because all the jobs would then be submitted at the same time,\nand step 2 would likely start running before step 1 is finished.\n\nThere are some possibilities with `sbatch` to make batch jobs wait on each\nother (e.g. the `--dependency` option), but this gets tricky quickly.\nIf you want a fully automatically rerunnable workflow /\npipeline, you should consider using a workflow management system\nlike [Snakemake](https://snakemake.readthedocs.io/en/stable/) or\n[NextFlow](https://www.nextflow.io/).\n\n**TODO include an example**\n:::\n\nSo, we'll have two types of scripts that we **separate** our code into:\n\n- The scripts that run individual steps of your analysis (again, typically individual programs)\n- A \"master\" or \"runner\" script that orchestrates the running of these individual\n  steps.\n  The code in this script is not run all at once,\n  unless you turn it into a formal workflow,\n  which is beyond the scope of this material.\n\nSo let's go ahead and open a new text file, and save it as `run.sh`.\n\n::: {.callout-tip}\n#### Keep the individual scripts simple\nIt is a good idea to keep the shell scripts you will submit (e.g., `fastqc.sh`) simple\n_in the sense that they should generally just run one program_,\nand not a sequence of programs.\n\nOnce you get the hang of writing these scripts,\nit may seem appealing to string a number of programs together in a single script,\nso that it's easier to rerun everything at once &mdash;\nbut in practice, that will often end up leading to more difficulties than convenience. \n:::\n\n<br>\n\n## Running FastQC using batch jobs\n\n### Submitting the script for one FASTQ file\n\nOpen a new file in VS Code\n(&nbsp; {{< fa bars >}} &nbsp; => &nbsp; `File` &nbsp; => &nbsp; `New File`)\nand save it as `fastqc.sh` within your `scripts/` directory.\nPaste in the code above and save the file.\n\nThen, submit the script:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsbatch scripts/fastqc.sh data/fastq/ASPC1_A178V_R1.fastq.gz results/fastqc\n```\n:::\n\n\n:::{.bash-out}\nSubmitted batch job 12521308\n:::\n\n:::{.callout-caution collapse=\"true\"}\n### Once again: Where does our output go?\n\n- Output that would have been printed to screen if we had run the script directly:\n  in the Slurm log file `slurm-fastqc-<job-nr>.out`\n  \n- FastQC's main output files (HTML and zip): to the output directory we specified.\n:::\n\nLet's take a look at the queue &mdash; you may catch the job while it's still pending\n(note below that the `NAME` will be the name of the script, by default):\n\n```{.bash-out}\nFri Aug 25 12:07:48 2023\n    JOBID PARTITION     NAME     USER    STATE       TIME TIME_LIMI  NODES NODELIST(REASON)\n  23666218 serial-40 fastqc.s   jelmer  PENDING       0:00   1:00:00      1 (None)\n```\n\n...and then it should start running:\n\n```{.bash-out}\nFri Aug 25 12:07:54 2023\n    JOBID PARTITION     NAME     USER    STATE       TIME TIME_LIMI  NODES NODELIST(REASON)\n  23666218 condo-osu fastqc.s   jelmer  RUNNING       0:06   1:00:00      1 p0133\n```\n\nThe job will be finished within 10 seconds, though,\nand you might miss its listing in the `squeue` output entirely:\nas soon as it's done, it will be removed from the list.\n\nOf course, we have to always check whether it ran _successfully_ &mdash;\nto do so, let start by checking the Slurm log file:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ncat slurm-fastqc-23666218.out    # You'll have a different number in the file name\n```\n:::\n\n\n:::{.callout-note collapse=\"true\"}\n## Click to see the contents of the Slurm log file\n\n```{.bash-out}\n# Starting script fastqc.ch\nFri Aug 25 12:07:50 EDT 2023\n# Input FASTQ file:   data/fastq/ASPC1_A178V_R1.fastq.gz\n# Output dir:         results/fastqc\n\nStarted analysis of ASPC1_A178V_R1.fastq.gz\nApprox 5% complete for ASPC1_A178V_R1.fastq.gz\nApprox 10% complete for ASPC1_A178V_R1.fastq.gz\nApprox 15% complete for ASPC1_A178V_R1.fastq.gz\nApprox 20% complete for ASPC1_A178V_R1.fastq.gz\nApprox 25% complete for ASPC1_A178V_R1.fastq.gz\nApprox 30% complete for ASPC1_A178V_R1.fastq.gz\nApprox 35% complete for ASPC1_A178V_R1.fastq.gz\nApprox 40% complete for ASPC1_A178V_R1.fastq.gz\nApprox 45% complete for ASPC1_A178V_R1.fastq.gz\nApprox 50% complete for ASPC1_A178V_R1.fastq.gz\nApprox 55% complete for ASPC1_A178V_R1.fastq.gz\nApprox 60% complete for ASPC1_A178V_R1.fastq.gz\nApprox 65% complete for ASPC1_A178V_R1.fastq.gz\nApprox 70% complete for ASPC1_A178V_R1.fastq.gz\nApprox 75% complete for ASPC1_A178V_R1.fastq.gz\nApprox 80% complete for ASPC1_A178V_R1.fastq.gz\nApprox 85% complete for ASPC1_A178V_R1.fastq.gz\nApprox 90% complete for ASPC1_A178V_R1.fastq.gz\nApprox 95% complete for ASPC1_A178V_R1.fastq.gz\nApprox 100% complete for ASPC1_A178V_R1.fastq.gz\nAnalysis complete for ASPC1_A178V_R1.fastq.gz\n\n# Listing the output files:\ntotal 5.1M\n-rw-r--r-- 1 jelmer PAS0471 266K Aug 25 12:07 ASPC1_A178V_R1_fastqc.html\n-rw-r--r-- 1 jelmer PAS0471 456K Aug 25 12:07 ASPC1_A178V_R1_fastqc.zip\n\n# Done with script fastqc.sh\nFri Aug 25 12:07:56 EDT 2023\n```\n:::\n\nOur script already listed the output files,\nbut let's take a look at those too, and do so in the VS Code file browser in the\nside bar.\n**To actually view FastQC's HTML output file**,\nwe unfortunately need to download it with this older version of VS Code\nthat's installed at OSC &mdash;\nbut the ability to download files from here is a nice one!\n\n<p align=\"center\"><img src=img/vscode_download.png width=\"50%\"></p>\n\n<br>\n\n::: {.callout-note}\n#### Add keyboard shortcut to run shell commands from the editor:\n\n- Click the <i class=\"fa fa-cog\"></i> (bottom-left) => `Keyboard Shortcuts`.\n\n- Find `Terminal: Run Selected Text in Active Terminal`, click on it,\n  then add a shortcut, e.g. <kbd>Ctrl</kbd>+<kbd>Enter</kbd>.\n:::\n\n<br>\n\n### Submitting the script many times with a loop\n\nThe script that we wrote above will run FastQC for a single FASTQ file.\nNow, we will write a loop that iterates over all of our FASTQ files\n(only 8 in this case, but could be 100s just the same),\nand **submits a batch job for each of them.**\n\nLet's type the following into our `run.sh` script,\nand then copy-and-paste it into the terminal to run the loop:\n\n```bash\nfor fastq_file in data/fastq/*fastq.gz; do\n    sbatch scripts/fastqc.sh \"$fastq_file\" results/fastqc\ndone\n```\n``` {.bash-out}\nSubmitted batch job 2451089  \nSubmitted batch job 2451090  \nSubmitted batch job 2451091  \nSubmitted batch job 2451092   \nSubmitted batch job 2451093  \nSubmitted batch job 2451094  \nSubmitted batch job 2451095  \nSubmitted batch job 2451096\n```\n\n:::{.exercise}\n### On Your Own: Check if everything went well {-}\n\n- Use `squeue` to monitor your jobs.\n\n- Take a look at the Slurm log files while the jobs are running and/or after the\n  jobs are finished.\n  \n  A nice trick when you have many log files to check using `tail` with a wildcard:\n  \n  ```\n  tail slurm-fastqc*\n  ```\n\n- Take a look at the FastQC output files: are you seeing 8 HTML files?  \n\n:::\n\n<br>\n\n## Interpreting the FastQC output\n\n**TODO**\n\nFor now see, <https://biodash.github.io/tutorials/2021-01_rnaseq/03-fastqc-output.html>\n\n<br>\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}