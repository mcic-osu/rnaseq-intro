{
  "hash": "f0a54645dee9ee22497318634c2ded15",
  "result": {
    "markdown": "---\ntitle: \"Compute Jobs with Slurm\"\nsubtitle: 'With a focus on submitting shell scripts as \"batch jobs\"'\npagetitle: \"Slurm\"\nhighlight-style: github\nnumber-sections: true\nengine: knitr\nauthor: Jelmer Poelstra\ndate: 2023-09-15\n---\n\n::: {.cell}\n\n:::\n\n\n----\n\n::: {.callout-important}\n## Under construction \nThis page is still under construction.\n:::\n\n::: {.callout-note}\n#### Add keyboard shortcut to run shell commands from the editor:\n\n- Click the <i class=\"fa fa-cog\"></i> (bottom-left) => `Keyboard Shortcuts`.\n\n- Find `Terminal: Run Selected Text in Active Terminal`, click on it,\n  then add a shortcut, e.g. <kbd>Ctrl</kbd>+<kbd>Enter</kbd>.\n:::\n\nWe have so far been working on _login nodes_ at OSC,\nbut in order to run some actual analyses,\nyou will need access to _compute nodes_.\n  \nAutomated scheduling software allows hundreds of people with different\nrequirements to access compute nodes effectively and fairly.\nFor this purpose, OSC uses the **Slurm** scheduler\n(**S**imple **l**inux **u**tility for **r**esource **m**anagement).\n\nA temporary reservation of resources on compute nodes is called a **compute job**.\nWhat are the options to start a compute job at OSC?\n\n1. \"**Interactive Apps**\" &mdash; We can start programs with GUIs,\n   such as RStudio or Jupyter Notebook on OnDemand,\n   and they will run in a browser window.\n2. **Interactive shell jobs** &mdash; Start a Bash shell on a compute node.\n3. **Batch (non-interactive) jobs** &mdash; Run a _script_ on a compute node.\n\nWhen running command-line programs for genomics analyses,\n_batch jobs_ are the most useful and will be the focus of this module.\nWe'll also touch on _interactive shell jobs_,\nwhich can occasionally be handy\nand are requested and managed in a very similar way to batch jobs.\n\n## Setup\n\n:::{.callout-note collapse=\"true\"}\n## Starting a VS Code session with an active terminal (click here)\n\n1. Log in to OSC at <https://ondemand.osc.edu>.\n2. In the blue top bar, select `Interactive Apps` and then `Code Server`.\n3. In the form that appears:\n   - Enter `4` or more in the box `Number of hours`\n   - **To avoid having to switch folders within VS Code**,\n     enter `/fs/ess/scratch/PAS2250/participants/<your-folder>` in the box `Working Directory`\n     (replace `<your-folder>` by the actual name of your folder).\n   - Click `Launch`.\n4. On the next page,\n   once the top bar of the box is green and says `Runnning`,\n   click `Connect to VS Code`.\n5. Open a terminal: {{< fa bars >}} &nbsp; => `Terminal` => `New Terminal`.\n6. In the terminal, type `bash` and press <kbd>Enter</kbd>.\n7. Type `pwd` in the termain to check you are in `/fs/ess/scratch/PAS2250`.\n   \n   If not, click\n   {{< fa bars >}} &nbsp; => &nbsp; `File` &nbsp; => &nbsp; `Open Folder`\n   and enter `/fs/ess/scratch/PAS2250/<your-folder>`.\n\n:::\n\n<br>\n\n## Interactive shell jobs\n\nInteractive shell jobs will grant you interactive shell access on a compute node.\nWorking in an interactive shell job is operationally identical to working on\na login node as we've been doing so far, but\n**the difference is that it's now okay to use significant computing resources**.\n(How much and for how long depends on what you reserve.)\n\n### Using `srun`\n\nA couple of different commands can be used to start an interactive shell job.\nI prefer the general `srun` command[^1],\nwhich we can use with `--pty /bin/bash` added to get an interactive Bash shell.\n\n[^1]: Other options: `salloc` works almost identically to `srun`,\n      whereas `sinteractive` is an OSC convenience wrapper but with more\n      limited options.\n     \nHowever, if we run that command without additional options, we get an error:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsrun --pty /bin/bash\n```\n:::\n\n\n:::{.bash-out}\nsrun: error: ERROR: Job invalid: Must specify account for job  \nsrun: error: Unable to allocate resources: Unspecified error\n:::\n\nAs the error message `Must specify account for job` tries to tell us,\n**we need to indicate which _OSC project_ (or as SLURM puts it, \"_account_\")**\n**we want to use** for this compute job.\nThis is because an OSC project always has to be charged for the computing\nresources used during a compute job.\n\nTo specify the project/account,\nwe can use the `--account=` option followed by the project number:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsrun --account=PAS2250 --pty /bin/bash\n```\n:::\n\n\n:::{.bash-out}\nsrun: job 12431932 queued and waiting for resources  \nsrun: job 12431932 has been allocated resources\n\n[...regular login info, such as quota, not shown...]\n\n[jelmer@p0133 PAS2250]$\n:::\n\nThere we go! First some Slurm scheduling info was printed to screen:\n\n- Initially, the job is \"queued\": that is, waiting to start.\n- Very soon (usually!), the job is \"allocated resources\":\n  that is,\n  computing resources such as a compute node are reserved for the job.\n\nThen:\n\n- The job starts and because we've reserved an _interactive_ shell job,\n  a new Bash shell is initiated:\n  for that reason, we get to see our regular login info once again.\n\n- Most importantly, we are no longer on a login node but on a **compute node**,\n  as our prompt hints at:\n  we switched from something like `[jelmer@pitzer-login04 PAS2250]$` to\n  the `[jelmer@p0133 PAS2250]$` shown above.\n\n- Note also that the job has a number (above: `job 12431932`):\n  every compute job has such a **unique identifier** among all jobs by all users\n  at OSC, and we can use this number to monitor and manage it.\n  All of us will therefore see a different job number pop up.\n\n:::{.callout-tip}\n## The working directory stays the same\nBatch jobs start in the directory that they were submitted\nfrom: that is, your working directory remains the same.\n:::\n\n<br>\n\n### Compute job options\n\nThe `--account=` option is just one of out of _many_ options we can use\nwhen reserving a compute job,\nbut is the only one that _always_ has to be specified\n(including for batch jobs and for Interactive Apps).\n\nDefaults exist for all other options,\nsuch as the amount of time (1 hour) and the number of cores (1).\nThese options are all specified in the same way for interactive and\nbatch jobs, and we'll dive into them below.\n\n:::{.callout-note}\n## Queueing times\nThe \"bigger\" (more time, more cores, more memory) our job is,\nthe more likely it is that our job will be pending for an appreciable amount \nof time.\n\nSmaller jobs (requesting up to a few hours and cores) will\n**almost always start running nearly instantly**.\nEven big jobs (requesting a day or more, 10 or more cores) will often do so,\nbut during busy times, you might have to wait for a while.\nThat said, the only times I've had to wait for more than an hour or so\nwas when I was requesting jobs with _very_ large memory requirements\n(100s of GBs), which have to be submitted to a separate queue/\"partition\".\n:::\n\n<br>\n\n## Intro to batch jobs\n\nWhen requesting _batch jobs_,\nwe are asking the Slurm scheduler to **run a script on a compute node**.\n\nIn contrast to interactive shell jobs,\nwe **stay in our current shell when submitting a script**,\nand the script will run on a compute node \"out of sight\".\nAlso, as we'll discuss in more detail below:\n\n- Output from the script that would normally be printed to screen ends up in\n  a file (!).\n  \n- Despite not being on the same node as our job,\n  we can do things like _monitoring_ whether the job is already/still running,\n  and _cancelling_ the job.\n\n:::{.callout-tip}\n## Scripts in other languages\nThe script that we submit can be in different languages but typically,\nincluding in all examples in this workshop, they are shell (Bash) scripts.\n:::\n\n<br>\n\n### The `sbatch` command\n\nWhereas we used Slurm's `srun` command to start an interactive shell job,\nwe use its **`sbatch` command to submit a batch job**.\nRecall from the Bash scripting module that we can run a Bash script as follows:\n\n```bash\nbash scripts/printname.sh Jane Doe\n```\n```{.bash-out}\nTODO\n```\n\n:::{.callout-caution collapse=\"true\"}\n## Can't find yesterday's `printname.sh` script?\n\n- Open a new file in the `VS Code` editor\n  (&nbsp; {{< fa bars >}} &nbsp; => &nbsp; `File` &nbsp; => &nbsp; `New File`)\n  and save it as `printname.sh`\n- Copy the code below into the script:\n  \n\n::: {.cell}\n\n```{.bash .cell-code}\n#!/bin/bash\nset -ueo pipefail\n\nfirst_name=$1\nlast_name=$2\n  \necho \"First name: $first_name\"\necho \"Last name: $last_name\"\n```\n:::\n\n\n:::\n\nThe above command ran the script on our current node, a login node.\nTo instead submit the script to the Slurm queue,\nwe would start by simply **replacing `bash` by `sbatch`**:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsbatch scripts/printname.sh Jane Doe\n```\n:::\n\n\n:::{.bash-out}\nsrun: error: ERROR: Job invalid: Must specify account for job  \nsrun: error: Unable to allocate resources: Unspecified error\n:::\n\nAs we've learned,\nwe always have to specify the OSC account when submitting a compute job.\nConveniently, we can also specify Slurm/`sbatch` options inside our script,\nbut first, let's add the `--account` option on the command line:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsbatch --account=PAS2250 scripts/printname.sh Jane Doe\n```\n:::\n\n\n:::{.bash-out}\nSubmitted batch job 12431935\n:::\n\n:::{.callout-tip collapse=\"true\"}\n## `sbatch` options _and_ script arguments\n\nNote that we can use `sbatch` options _and_ script arguments in one command,\nin the following order:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsbatch [sbatch-options] myscript.sh [script-arguments]\n```\n:::\n\n\nBut both of these are optional:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsbatch printname.sh                             # No options/arguments for either\nsbatch printname.sh Jane Doe                    # Script arguments but no sbatch option\nsbatch --account=PAS2250 printname.sh           # sbatch option but no script arguments\nsbatch --account=PAS2250 printname.sh Jane Doe  # Both sbatch option and script arguments\n```\n:::\n\n\n:::\n\n<br>\n\n### Adding `sbatch` options in scripts\n\nInstead of specifying Slurm/`sbatch` options on the command-line when we submit\nthe script, we can also **add these options inside the script**.\n\nThis is handy because\neven though we have so far only seen the `account=` option,\nyou often want to specify several options.\nThat would lead to very long `sbatch` commands.\nAdditionally, it can be practical to store a script's typical Slurm options\nalong with the script itself.\n\nWe add the options in the script using another type of special comment line\nakin to the shebang line, marked by `#SBATCH`.\nThe equivalent of adding `--account=PAS2250` after `sbatch` on the command line\nis a line in  a script that reads `#SBATCH --account=PAS2250`.\n\nJust like the shebang line,\nthe `#SBATCH` line(s) should be at the top of the script.\nLet's add one such line to the `printname.sh` script,\nsuch that the first few lines read:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n#!/bin/bash\n#SBATCH --account=PAS2250\n\nset -ueo pipefail\n```\n:::\n\n\nAfter having added this to the script,\nwe _can_ run our earlier `sbatch` command without options:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsbatch printname.sh Jane Doe\n```\n:::\n\n\n:::{.bash-out}\nSubmitted batch job 12431942\n:::\n\nAfter we submit the batch job, we **immediately get our prompt back**.\nEverything else (job queuing and running) will happen out of our immediate view.\nThis allows us to submit many jobs at the same time &mdash;\nwe don't have to wait for other jobs to finish (or even to start).\n\n:::{.callout-note}\n## `sbatch` option precedence\nAny `sbatch` option provided on the command line will override the equivalent\noption provided inside the script.\nThis is sensible: we can provide \"defaults\" inside the script,\nand change one or more of those when needed on the command line.\n:::\n\n:::{.callout-note}\n## Running a script with `#SBATCH` in other contexts\nBecause `#SBATCH` lines are special _comment_ lines,\nthey will simply be ignored and not throw any errors when you run a script that\ncontains them in other contexts: when not running them as a batch job at OSC,\nor even when running them on a computer without Slurm installed.\n:::\n\n<br>\n\n### Where does the output go?\n\nAbove, we saw that when we ran the `printname.sh` script directly,\nits output was printed to the screen,\nwhereas when we submitted it as a batch job,\nall that was sprinted to screen was `Submitted batch job 12431942`.\nSo where did our output go?\n\n**Our output ended up in a file** called `slurm-12431942.out`:\nthat is, `slurm-<job-number>.out`.\nSince each job number is unique to a given job,\nyour file would have a different number in its name.\nWe might call this type of file a **Slurm log file**.\n\n:::{.callout-caution collapse=\"true\"}\n## Any idea why we might not want batch job output printed to screen, even if we could?\n\nThe power of submitting batch jobs is that you can submit many at once &mdash;\ne.g. one per sample, running the same script.\nIf the output from all those scripts ends up on your screen,\nthings become a big mess, and you have no lasting record of what happened.\n:::\n\nLet's take a look at the contents of the Slurm log file with the `cat` command:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ncat slurm-12431942.out\n```\n:::\n\n\n:::{.bash-out}\nFirst name: Jane  \nLast name: Doe\n:::\n\nThis file simply contains the output that we saw printed to screen before\n&mdash; nothing more and nothing less.\n\nIt's important to conceptually distinguish two broad types of output\nthat a script may have:\n\n- Output that is **printed to screen** when we directly run a script,\n  such as what was produced by our `echo` statements,\n  by any errors that may occur,\n  and possibly by a program that we run in the script.[^2]\n  As we saw, this output ends up in the **Slurm log file** when we submit\n  the script as a batch job.\n\n- Output that we redirect to a file (`> myfile.txt`) or output that a program\n  we run in the script writes to file(s).\n  This type of output **will always end up in those very same files**\n  regardless of whether we run the script directly or as a batch job. \n\n[^2]: Technically, these are two different types of output,\n      as we briefly touch on below: \"standard output\" and \"standard error\".\n\n<br>\n\n## Monitoring batch (and other compute) jobs\n\n### A sleepy script for practice\n\nLet's use the following short script to practice monitoring and managing batch\nand other compute jobs.\n\nOpen a new file in the `VS Code` editor\n(&nbsp; {{< fa bars >}} &nbsp; => &nbsp; `File` &nbsp; => &nbsp; `New File`)\nand save it as `scripts/sleep.sh`, then copy the following into it:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n#!/bin/bash\n#SBATCH --account=PAS2250\n\necho \"I will sleep for 30 seconds\" > sleep.txt\nsleep 30s\necho \"I'm awake!\"\n```\n:::\n\n\n:::{.exercise}\n\n### On Your Own: Batch job output recap {-}\n\nIf you submit the script as a batch job using `sbatch scripts/sleep.sh`:\n\n1. How many output files will this batch job produce?\n2. What will be in it/them?\n3. In which directory will the file(s) appear?\n4. In terms of output,\n   what would have been different if we had run the script directly,\n   i.e. using the command `bash scripts/sleep.sh`?\n\nYou can test your predictions by running the script, if you want.\n\n:::{.callout-tip collapse=\"true\"}\n## Solutions\n\n1. The script will produce 2 files\n\n2. They will contain:\n    - `sleep.txt`: `I will sleep for 30 seconds`\n    - `slurm-<job-number>.out`: `I'm awake!`\n\n3. Both files will end up in your current working directory.\n\n4.  If we had run the script directly,\n    `slept.txt` would have been the same,\n    but `All done!` would have been printed to screen.\n:::\n:::\n\n<br>\n\n### Checking the status of our batch job\n\nAfter we submit a job, it may be initially be queued (or _pending_),\nbefore the Slurm scheduler finds a \"slot\" for our job.\nThen, the job will start _running_, and at some point it will _stop running_,\neither because the script ran into and error or because it ran to completion.\n\nHow can we check the status of our batch job?\nWe can do so using the Slurm command `squeue`:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsqueue -u $USER -l\n```\n:::\n\n\nIn the command above:\n\n- Our user name is specified with the `-u` option\n  (otherwise we would see _everyone's jobs_) &mdash;\n- We use the _environment variable_ `$USER`,\n  which is a variable that's always available and contains your user name,\n  so that the very same code will work for everyone\n  (you can also simply type your user name if that's shorter or easier).\n- We've added the `-l` option to get more verbose output.\n\nLet's try that &mdash; first we submit the script:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsbatch scripts/sleep.sh\n```\n:::\n\n\n:::{.bash-out}\nSubmitted batch job 12431945\n:::\n\nWe may be able to catch the `STATE` being `PENDING` before the job starts:\n\n```sh\nsqueue -u $USER -l\n# Fri Aug 19 07:23:19 2022\n#              JOBID PARTITION     NAME     USER    STATE       TIME TIME_LIMI  NODES NODELIST(REASON)\n#           12520046 serial-40 sleep.sh   jelmer  PENDING       0:00   1:00:00      1 (None)\n```\n\nBut soon enough it should say `RUNNING` in the `STATE` column:\n\n```sh\nsqueue -u $USER -l\n# Fri Aug 19 07:23:45 2022\n#              JOBID PARTITION     NAME     USER    STATE       TIME TIME_LIMI  NODES NODELIST(REASON)\n#           12520046 condo-osu sleep.sh   jelmer  RUNNING       0:12   1:00:00      1 p0133\n```\n\nThe script should finish after 30 seconds (`sleep 30s`...),\nand after that, the `squeue` output will only show the header line with column\nnames:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsqueue -u $USER -l\n# Fri Aug 19 07:24:18 2022\n#              JOBID PARTITION     NAME     USER    STATE       TIME TIME_LIMI  NODES NODELIST(REASON) \n```\n:::\n\n\nOnce a job has finished running, it disappears from the `squeue` listing.\nSo, the output above means that we have _no running (or pending) jobs_.\n\nBut we need to check our output file(s) to see if our script ran successfully!\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ncat sleep.txt\n```\n:::\n\n\n:::{.bash-out}\nI will sleep for 30 seconds\n:::\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ncat slurm-12520046.out\n```\n:::\n\n\n:::{.bash-out}\nI'm awake!\n:::\n\n<br>\n\n### Cancelling jobs (and other monitoring/managing commands)\n\nSometimes, you want to cancel one or more jobs,\nbecause you realize you made a mistake\nin the script or you used the wrong input files.\nYou can do so using `scancel`:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nscancel 2979968        # Cancel job number 2979968\nscancel -u $USER       # Cancel all your jobs\n```\n:::\n\n\n:::{.callout-note collapse=\"true\"}\n## At-home reading: Other commands and options\n\n- Check only a specific job by specifying the job ID, e.g `2979968`:\n\n\n  ::: {.cell}\n  \n  ```{.bash .cell-code}\n  squeue -j 2979968\n  ```\n  :::\n\n\n- Only show running (not pending) jobs:\n  \n\n  ::: {.cell}\n  \n  ```{.bash .cell-code}\n  squeue -u $USER -t RUNNING\n  ```\n  :::\n\n\n- Update Slurm directives for a job that has already been submitted:\n\n\n  ::: {.cell}\n  \n  ```{.bash .cell-code}\n  scontrol update job=<jobID> timeLimit=5:00:00\n  ```\n  :::\n\n  \n- Hold and release a pending (queued) job,\n  e.g. when needing to update input file before it starts running:\n\n\n  ::: {.cell}\n  \n  ```{.bash .cell-code}\n  scontrol hold <jobID>        # Job won't start running until released\n  scontrol release <jobID>     # Job is free to start\n  ```\n  :::\n\n\n- You can see more details about any running or finished jobs,\n  *including the amount of time it ran for*:\n  \n\n  ::: {.cell}\n  \n  ```{.bash .cell-code}\n  scontrol show job 2526085   # For job 2526085\n  \n  # UserId=jelmer(33227) GroupId=PAS0471(3773) MCS_label=N/A\n  # Priority=200005206 Nice=0 Account=pas0471 QOS=pitzer-default\n  # JobState=RUNNING Reason=None Dependency=(null)\n  # Requeue=1 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0\n  # RunTime=00:02:00 TimeLimit=01:00:00 TimeMin=N/A\n  # SubmitTime=2020-12-14T14:32:44 EligibleTime=2020-12-14T14:32:44\n  # AccrueTime=2020-12-14T14:32:44\n  # StartTime=2020-12-14T14:32:47 EndTime=2020-12-14T15:32:47 Deadline=N/A\n  # SuspendTime=None SecsPreSuspend=0 LastSchedEval=2020-12-14T14:32:47\n  # Partition=serial-40core AllocNode:Sid=pitzer-login01:57954\n  # [...]\n  ```\n  :::\n\n:::\n\n<br>\n\n## Common `sbatch` options\n\n:::{.callout-tip}\n## Long and and short option format\nMany SLURM options have a long format (`--account=PAS2250`) and a short\nformat (`-A PAS2250`), which can generally be used interchangeably.\nFor clarity, we'll stick to long format options during this workshop.\n:::\n\n### `--account`: The OSC project\n\nAs seen above. _Always_ specify the project when submitting a batch job.\n\n### `--time`: Time limit (\"wall time\")\n\nSpecify the maximum amount of time your job will run for.\nWall time is a term meant to distinguish it from, say \"core hours\":\nif a job runs for 2 hour and used 8 cores,\nthe wall time was 2 hours and the number of core hours was 2 x 8 = 16.\n  \n- Your job gets killed as soon as it hits the specified time limit!\n- You will only be charged for the time your job *actually used*.\n- The default time limit is 1 hour. Acceptable time formats include:\n  - `minutes`\n  - `hours:minutes:seconds`\n  - `days-hours`\n- For single-node jobs, up to 168 hours (7 days) can be requested.\n  If that's not enough, you can request access to the `longserial` queue\n  for jobs of up to 336 hours (14 days).\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n#!/bin/bash\n#SBATCH --time=1:00:00\n```\n:::\n\n\n:::{.callout-note}\n## Ask for more time\nIf you are uncertain about the time your job will take,\nask for (much) more time than you think you will need.\nThis is because queuing times are generally good at OSC _and_\nyou won't be charged for reserved-but-not-used time.\n:::\n\n### `--mem`: RAM memory\n\nSpecify a maximum amount of RAM (Random Access Memory) that your job can use.\n\n- The default unit is MB (MegaBytes) &mdash; append `G` for GB.\n- The default amount is 4 GB per core that you reserve\n- Like with the time limit, your job gets killed when it hits the memory limit.\n\n```sh\n#!/bin/bash\n#SBATCH --mem=20G\n```\n\n:::{.callout-note}\n## Default memory limits usually work\nIt is not that common to hit the memory limit,\nso I usually don't specify it &mdash;\nunless the program reports needing lots of memory,\nor I got \"out-of-memory\" errors when trying to run the script before.\n:::\n\n### Cores (& nodes and tasks)\n\nSpecify the number of nodes (≈ computers), cores, or \"tasks\" (processes). \nThese are separate but related options,\nand this is where things can get confusing!\n\n- Slurm for the most part uses \"**core**\" and \"**CPU**\" interchangeably[^3].\n  More generally, \"**thread**\" is *also* commonly used interchangeably \n  with core/CPU[^4].\n\n[^3]: Even though technically, one CPU often contains multiple cores.\n[^4]: Even though technically, one core often contains multiple threads.\n\n- Running a program that uses multiple threads/cores/CPUs (\"multi-threading\")\n  is common.\n  In such cases, specify the number of threads/cores/CPUs `n` with\n  `--cpus-per-task=n`\n  (and keep `--nodes` and `--ntasks` at their defaults of 1).\n  \n  The program you're running may have an argument like `--cores` or `--threads`,\n  which you should then set to `n` as well.\n  \n:::{.callout-note}\n## Uncommon cases\n\n- Only ask for **>1 node** when a program is parallelized with\n  e.g. \"MPI\", which is uncommon in bioinformatics.\n- For jobs with multiple processes (tasks),\n  use `--ntasks=n` or `--ntasks-per-node=n`.\n:::  \n\n| Resource/use                  | short    | long                    | default\n|-------------------------------|----------|-------------------------|:--------:| \n| **Nr. of cores/CPUs/threads (per task)**    | `-c 1`   | `--cpus-per-task=1`     | 1\n| Nr. of \"tasks\" (processes) | `-n 1`   | `--ntasks=1`            | 1\n| Nr. of tasks per node      | -        | `--ntasks-per-node=1`   | 1\n| Nr. of nodes               | `-N 1`   | `--nodes=1`             | 1\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n#!/bin/bash\n#SBATCH --cpus-per-task=2\n```\n:::\n\n\n### `--output`: Slurm log files\n\nAs we saw above, by default, all output from a script that would normally[^5]\nbe printed to screen will end up in a Slurm log file when we submit the script\nas a batch job.\nThis file will be created in the directory from which you submitted the script,\nand will be called `slurm-<job-number>.out`, e.g. `slurm-12431942.out`.\n\nBut it is possible to change the name of this file.\nFor instance, it can be useful to include the name of the program that the\nscript runs,\nso that it's easier to recognize this file later.\n\nWe can do this with the `--output` option,\ne.g. `--output=slurm-fastqc.out` if we were running FastQC.\n\nHowever,\nyou'll generally want to keep the batch job number in the file name too[^6].\nSince we won't know the batch job number in advance,\nwe need a trick here and that is to use\n**`%j`, which represents the batch job number**:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n#!/bin/bash\n#SBATCH --output=slurm-fastqc-%j.out\n```\n:::\n\n\n[^5]: That is, when we run the script directly, e.g. `bash myscript.sh`\n[^6]: For instance, we might be running the FastQC script multiple times,\n      and otherwise those would all have the same name and be overwritten.\n      \n:::{.callout-note collapse=\"true\"}\n## At-home reading: `stdout` and `stderr`\n\nBy default, two output streams \"standard output\" (`stdout`) and\n\"standard error\" (`stderr`) are printed to screen and therefore also\nboth end up in the same Slurm log file,\nbut it is possible to separate them into different files.\n\nBecause `stderr`, as you might have guessed, often contains error messages,\nit could be useful to have those in a separate file.\nYou can make that happen with the `--error` option,\ne.g. `--error=slurm-fastqc-%j.err`.\n\nHowever, reality is more messy:\nsome programs print their main output not to a file but to standard out,\nand their logging output, errors and regular messages alike, to standard error.\nYet other programs use `stdout` or `stderr` for _all_ messages.\n\n**I therefore usually only specify `--output`, such that both streams**\n**end up in that file.**\n:::\n\n<br>\n\n## Addendum: Table with `sbatch` options\n\nThis includes all the discussed options, and a couple more useful ones:\n\n| Resource/use                  | short      | long                 | default\n|-------------------------------|------------|----------------------|:---------:|\n| Project to be billed          | `-A PAS0471` | `--account=PAS0471`    | _N/A_\n| Time limit                    | `-t 4:00:00` | `--time=4:00:00`      | 1:00:00\n| Nr of nodes                   | `-N 1`       | `--nodes=1`            | 1\n| Nr of cores                   | `-c 1`       | `--cpus-per-task=1`    | 1\n| Nr of \"tasks\" (processes)     | `-n 1`      | `--ntasks=1`           | 1\n| Nr of tasks per node          | -          | `--ntasks-per-node`   | 1\n| Memory limit per node         | -          | `--mem=4G`             | *(4G)*\n| Log output file (%j = job number)    | `-o`       |  `--output=slurm-fastqc-%j.out`\n| Error output (*stderr*)              | `-e`       | `--error=slurm-fastqc-%j.err`\n| Job name (displayed in the queue)    | -        | `--job-name=fastqc`\n| Partition (=queue type)              | -        | `--partition=longserial` <br> `--partition=hugemem`\n| Get email when job starts, ends, fails, <br> or all of the above | -        | `--mail-type=START` <br> `--mail-type=END` <br> `--mail-type=FAIL` <br> `--mail-type=ALL`\n| Let job begin at/after specific time | -        | `--begin=2021-02-01T12:00:00`\n| Let job begin after other job is done | -      | `--dependency=afterany:123456`\n\n<br>\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}